{"task_id": 16, "completion_id": 0, "solution": "from typing import Any, Iterable, List, Tuple\ndef ngrams(sequence: Iterable[Any], N: int) -> List[Tuple[Any, ...]]:\n    if N == 0:\n        return []\n    L = len(sequence)\n    if N > L:\n        return []\n    ngrams = []\n    for i in range(L - N + 1):\n        window = sequence[i:i + N]\n        ngrams.append(tuple(window))\n    return ngrams"}
{"task_id": 18, "completion_id": 0, "solution": ""}
{"task_id": 71, "completion_id": 0, "solution": "def label_uniq_cnt(data: list[list]) -> dict:\n    if not data:\n        return {}\n    counts = {}\n    for sample in data:\n        label = sample[-1]\n        if label in counts:\n            counts[label] += 1\n        else:\n            counts[label] = 1\n    return counts"}
{"task_id": 87, "completion_id": 0, "solution": "import numpy as np\ndef layer_sizes(X: np.ndarray, Y: np.ndarray) -> tuple[int, int, int]:\n    n_x = X.shape[0]\n    n_y = Y.shape[0]\n    n_h = 10\n    return (n_x, n_h, n_y)"}
{"task_id": 91, "completion_id": 0, "solution": ""}
{"task_id": 92, "completion_id": 0, "solution": "import numbers\ndef is_number(a) -> bool:\n    return isinstance(a, numbers.Number) and (not isinstance(a, bool))"}
{"task_id": 94, "completion_id": 0, "solution": "from collections import Counter\ndef knn_majority_vote(neighbors_targets: list[str | int]) -> str | int:\n    counts = Counter(neighbors_targets)\n    sorted_items = sorted(counts.items(), key=lambda x: (-x[1], x[0]))\n    return sorted_items[0][0]"}
{"task_id": 113, "completion_id": 0, "solution": "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=None):\n    if examples is None:\n        examples = globalConstant\n    predictions = []\n    for example in examples:\n        output = run_example(model, input_vocabulary, inv_output_vocabulary, example)\n        predictions.append(''.join(output))\n        print(f'Input: {example}, Output: {output}')\n    return predictions"}
{"task_id": 119, "completion_id": 0, "solution": "import numpy as np\ndef sgd_update(params: list, grads: list, alpha: float=0.01) -> list:\n    if len(params) == 0 or len(grads) == 0 or len(params) != len(grads):\n        return []\n    new_params = [np.round(p - alpha * g, 4) for (p, g) in zip(params, grads)]\n    return [list(p) for p in new_params]"}
{"task_id": 129, "completion_id": 0, "solution": "from itertools import cycle\ndef cycle_sequence(sequence: list, samples: int) -> list:\n    \"\"\"Return the first `samples` items from an infinite cycle over `sequence`.\n\n    Args:\n        sequence (list | tuple): Finite input sequence.\n        samples (int): Number of items to return from the infinite cycle.\n\n    Returns:\n        list: A list containing `samples` items collected by looping over\n              `sequence` repeatedly. If `sequence` is empty or `samples`\n              is not positive, an empty list is returned.\n    \"\"\"\n    if not sequence or samples <= 0:\n        return []\n    iterator = cycle(sequence)\n    return list(islice(iterator, samples))"}
{"task_id": 134, "completion_id": 0, "solution": ""}
{"task_id": 173, "completion_id": 0, "solution": "def alphabetical_distance(candidate: str, target: str) -> int:\n    if len(candidate) != len(target):\n        return -1\n    total = 0\n    for (c1, c2) in zip(candidate, target):\n        total += abs(ord(c1) - ord(c2))\n    return total"}
{"task_id": 199, "completion_id": 0, "solution": "import numpy as np\ndef split(X: np.ndarray, y: np.ndarray, value: float) -> tuple[list[int | float], list[int | float]]:\n    y_left = []\n    y_right = []\n    for i in range(len(y)):\n        if X[i] < value:\n            y_left.append(y[i])\n        else:\n            y_right.append(y[i])\n    return (y_left, y_right)"}
{"task_id": 205, "completion_id": 0, "solution": "def get_gym_environs(registry: list) -> list:\n    result = []\n    seen = set()\n    for item in registry:\n        if isinstance(item, dict) and 'id' in item:\n            id = item['id']\n            if id not in seen:\n                result.append(id)\n                seen.add(id)\n    return result"}
{"task_id": 231, "completion_id": 0, "solution": ""}
{"task_id": 269, "completion_id": 0, "solution": "def count_trainable_params(state_dimensions: int, action_dimensions: int) -> int:\n    return 164 * (state_dimensions + 1) + 165 * action_dimensions"}
{"task_id": 274, "completion_id": 0, "solution": "import numpy as np\ndef small_norm_clip(values):\n    if isinstance(values, list):\n        values = np.array(values)\n    clipped = np.clip(values, -5, 5)\n    return clipped.tolist()"}
{"task_id": 277, "completion_id": 0, "solution": "def is_tuple(env: dict) -> tuple:\n    action_space = env['action_space']\n    obs_space = env['observation_space']\n    tuple_action = isinstance(action_space, (tuple, dict))\n    tuple_obs = isinstance(obs_space, (tuple, dict))\n    return (tuple_action, tuple_obs)"}
{"task_id": 289, "completion_id": 0, "solution": "def format_entries(entries: list[tuple[str, str]]) -> str:\n    if not entries:\n        return ''\n    lines = []\n    for i in range(0, len(entries), 2):\n        field = entries[i][0]\n        value = entries[i + 1][1]\n        lines.append(f'{field}: {value}')\n    return '\\n'.join(lines)"}
{"task_id": 293, "completion_id": 0, "solution": ""}
{"task_id": 307, "completion_id": 0, "solution": ""}
{"task_id": 328, "completion_id": 0, "solution": "from typing import List\ndef first_capitalized_word(corpus: List[str]) -> List[str]:\n    for word in corpus:\n        if not word:\n            continue\n        if word[0].isupper():\n            return word\n    return []"}
{"task_id": 342, "completion_id": 0, "solution": "import numpy as np\ndef manhattan(x: list[float | int], y: list[float | int]) -> float:\n    if len(x) != len(y):\n        return -1\n    total = 0.0\n    for i in range(len(x)):\n        total += abs(x[i] - y[i])\n    return round(total, 4)"}
{"task_id": 356, "completion_id": 0, "solution": "import numpy as np\ndef leaf_predict(leaf: 'Leaf', classifier: bool):\n    \"\"\"Return the prediction stored in a decision-tree leaf.\n\n    Args:\n        leaf: A Leaf object whose `value` attribute is either a sequence of\n               class probabilities (classification) or a single number\n               (regression).\n        classifier: When True, treat the leaf as a classification tree.\n\n    Returns:\n        int | float: Predicted class index for classification; otherwise the\n                     raw scalar stored in the leaf.\n    \"\"\"\n    if isinstance(leaf.value, (list, tuple)):\n        return np.argmax(leaf.value)\n    else:\n        return leaf.value"}
{"task_id": 364, "completion_id": 0, "solution": "def sign(x: int | float) -> int:\n    if x > 0:\n        return 1\n    elif x < 0:\n        return -1\n    else:\n        return 0"}
{"task_id": 378, "completion_id": 0, "solution": "def indicator(flag: int) -> int:\n    if flag == 1:\n        return 1\n    else:\n        return 0"}
{"task_id": 379, "completion_id": 0, "solution": "def sort_priority_nodes(nodes: list[dict]) -> list[str]:\n    if not nodes:\n        return []\n    sorted_nodes = sorted(nodes, key=lambda x: (x['priority'], x['entry_id']))\n    return [node['key'] for node in sorted_nodes]"}
{"task_id": 415, "completion_id": 0, "solution": ""}
{"task_id": 420, "completion_id": 0, "solution": ""}
{"task_id": 427, "completion_id": 0, "solution": "import numpy as np\ndef identity_activation(z):\n    if not isinstance(z, np.ndarray):\n        z = np.array(z)\n    activation = z\n    derivative = np.ones_like(z)\n    return (activation.tolist(), derivative.tolist())"}
{"task_id": 448, "completion_id": 0, "solution": ""}
{"task_id": 454, "completion_id": 0, "solution": ""}
{"task_id": 466, "completion_id": 0, "solution": "import string\ndef strip_punctuation(line: str) -> str:\n    translation_table = str.maketrans('', '', string.punctuation)\n    translated_line = line.translate(translation_table)\n    stripped_line = translated_line.strip()\n    return stripped_line"}
{"task_id": 467, "completion_id": 0, "solution": ""}
{"task_id": 501, "completion_id": 0, "solution": "def constant_scheduler(initial_lr: float, step: int) -> float:\n    \"\"\"Constant learning-rate scheduler.\n\n    Parameters\n    ----------\n    initial_lr : float\n        The fixed learning rate that should be returned on every call.\n    step : int\n        The current training step (ignored).\n\n    Returns\n    -------\n    float\n        The same value as `initial_lr`.\n    \"\"\"\n    return initial_lr"}
{"task_id": 503, "completion_id": 0, "solution": "from copy import deepcopy\ndef selective_update(hparams: dict | None, updates: dict | None) -> dict | int:\n    if hparams is None:\n        return -1\n    copied = deepcopy(hparams)\n    if updates is not None:\n        for (key, value) in updates.items():\n            if key in copied:\n                copied[key] = value\n    return copied"}
{"task_id": 508, "completion_id": 0, "solution": "from typing import Any, Dict, List\ndef params_with_name(params: Dict[str, Any], name: str) -> List[Any]:\n    result = []\n    for (key, value) in params.items():\n        if name in key:\n            result.append(value)\n    return result"}
{"task_id": 511, "completion_id": 0, "solution": "import numpy as np\ndef random_bernoulli_mab(n_arms: int=10) -> list[float]:\n    if n_arms < 1:\n        return []\n    samples = np.random.uniform(0, 1, size=n_arms)\n    total = np.sum(samples)\n    probabilities = samples / total\n    rounded = [round(x, 4) for x in probabilities]\n    return rounded"}
{"task_id": 515, "completion_id": 0, "solution": ""}
{"task_id": 530, "completion_id": 0, "solution": "import numpy as np\ndef binary_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"Calculates the mean Binary Cross-Entropy loss.\n    \n    Parameters\n    ----------\n    y_true : np.ndarray\n        Ground-truth binary labels (0 or 1).\n    y_pred : np.ndarray\n        Predicted probabilities for the positive class. Must have the same shape\n        as *y_true.\n    \n    Returns\n    -------\n    float\n        Mean BCE loss rounded to 4 decimal places.\n    \"\"\"\n    y_pred_clipped = np.clip(y_pred, 1e-07, 1 - 1e-07)\n    loss = -(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n    return np.mean(loss)"}
{"task_id": 532, "completion_id": 0, "solution": "def count_fc_parameters(layers: list[int]) -> int:\n    if len(layers) < 2:\n        return 0\n    total = 0\n    for i in range(len(layers) - 1):\n        n_in = layers[i]\n        n_out = layers[i + 1]\n        total += n_in * n_out + n_out\n    return total"}
{"task_id": 539, "completion_id": 0, "solution": "import numpy as np"}
{"task_id": 540, "completion_id": 0, "solution": ""}
{"task_id": 541, "completion_id": 0, "solution": "import numpy as np\ndef return_input_grads(y, y_hat):\n    gradient = y_hat - y\n    gradient_rounded = np.round(gradient, 4)\n    return gradient_rounded.tolist()"}
{"task_id": 543, "completion_id": 0, "solution": "from collections import Counter\ndef cal_gini_index(data: list) -> float:\n    if not data:\n        return"}
{"task_id": 544, "completion_id": 0, "solution": "def split_tree(data: list, fea: int, value: float):\n    set1 = []\n    set2 = []\n    for (i, s) in enumerate(data):\n        if s[fea] >= value:\n            set1.append(s)\n        else:\n            set2.append(s)\n    return (set1, set2)"}
{"task_id": 559, "completion_id": 0, "solution": ""}
{"task_id": 578, "completion_id": 0, "solution": "from typing import List, Tuple\ndef make_pairs(corpus: list) -> list[tuple]:\n    if len(corpus) < 2:\n        return []\n    result = []\n    for i in range(len(corpus) - 1):\n        result.append((corpus[i], corpus[i + 1]))\n    return result"}
{"task_id": 585, "completion_id": 0, "solution": "def cmp(a, b):\n    if a > b:\n        return 1\n    elif a < b:\n        return -1\n    else:\n        return 0"}
{"task_id": 588, "completion_id": 0, "solution": "from typing import Optional\nfrom typing import Optional\nclass Node:\n    \"\"\"A simple binary tree node.\"\"\"\n\n    def __init__(self, data=None, split_variable=None, split_variable_value=None, left: Optional['Node']=None, right: Optional['Node']=None, depth: int=0, criterion_value=None):\n        self.data = data\n        self.split_variable = split_variable\n        self.split_variable_value = split_variable_value\n        self.left = left\n        self.right = right\n        self.depth = depth\n        self.criterion_value = criterion_value\ndef tree_max_depth(root: Optional[Node]) -> int:\n    \"\"\"Computes the maximum depth of a binary tree.\n\n    The depth of the root node is defined to be 0.  The depth of an empty\n    tree is defined to be -1.\n\n    Args:\n        root: The root of the binary tree (Node or None).\n\n    Returns:\n        The maximum depth as an integer.\n    \"\"\"\n    if root is None:\n        return -1\n    else:\n        left_depth = tree_max_depth(root.left)\n        right_depth = tree_max_depth(root.right)\n        return 1 + max(left_depth, right_depth)"}
