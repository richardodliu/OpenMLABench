{"task_id": 1, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the dot product of a matrix and a vector. The dot product of a matrix and a vector results in a new vector where each element is the dot product of the corresponding row in the matrix with the vector. If the matrix and vector dimensions are incompatible, the function should return -1.\n\n### Approach\n1. **Check for Empty Matrices or Vectors**: If either the matrix or the vector is empty, return -1 as they are invalid for dot product computation.\n2. **Check Matrix and Vector Compatibility**: The number of columns in the matrix must match the length of the vector. If they do not match, return -1.\n3. **Validate Matrix Structure**: Ensure all rows in the matrix have the same number of columns. If any row has a different number of columns, return -1.\n4. **Compute the Dot Product**: For each row in the matrix, compute the dot product with the vector and store the result in a new list.\n\n### Solution Code\n```python\ndef matrix_dot_vector(a: list[list[int|float]], b: list[int|float]) -> list[int|float]:\n    # Check if the matrix or vector is empty\n    if not a or not b:\n        return -1\n    # Get the number of columns in the matrix\n    n_cols = len(a[0])\n    # Check if the number of columns matches the length of the vector\n    if n_cols != len(b):\n        return -1\n    # Check if all rows in the matrix have the same number of columns\n    for row in a:\n        if len(row) != n_cols:\n            return -1\n    # Compute the dot product\n    result = []\n    for row in a:\n        dot_product = 0.0\n        for i in range(n_cols):\n            dot_product += row[i] * b[i]\n        result.append(dot_product)\n    return result\n```\n\n### Explanation\n1. **Empty Check**: The function first checks if either the matrix `a` or the vector `b` is empty. If either is empty, it returns -1.\n2. **Column Check**: The function then checks if the number of columns in the matrix matches the length of the vector. If not, it returns -1.\n3. **Row Validation**: The function ensures that each row in the matrix has the same number of columns. If any row does not meet this criterion, it returns -1.\n4. **Dot Product Calculation**: For each row in the matrix, the function computes the dot product with the vector by summing the products of corresponding elements. The results are stored in a list and returned.\n\nThis approach ensures that all edge cases are handled, including empty matrices, incompatible dimensions, and invalid matrix structures, providing a robust solution to the problem."}
{"task_id": 2, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the transpose of a given matrix. The transpose of a matrix is obtained by converting its rows into columns and its columns into rows. This means that the element at the i-th row and j-th column of the original matrix will move to the j-th row and i-th column in the transposed matrix.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n1. **Understand the Matrix Transpose**: The transpose of a matrix is a new matrix where the rows become columns and columns become rows.\n2. **Use Python's `zip` Function**: The `zip` function in Python can help transpose the rows and columns efficiently. By using `zip(*a)`, where `a` is the input matrix, we can convert the rows of the matrix into tuples, which represent the columns of the transposed matrix.\n3. **Convert Tuples to Lists**: Since the `zip` function returns tuples, we need to convert these tuples into lists to match the required output format.\n4. **Return the Result**: The transposed matrix, now as a list of lists, is returned as the result.\n\nThis approach is efficient and concise, leveraging Python's built-in functions to handle the transposition with minimal code.\n\n### Solution Code\n```python\ndef transpose_matrix(a: list[list[int|float]]) -> list[list[int|float]]:\n    return [list(row) for row in zip(*a)]\n```\n\n### Explanation\n- **Matrix Transpose**: The transpose operation is performed by converting each row of the original matrix into a column in the transposed matrix.\n- **Efficiency**: Using `zip` and list comprehensions ensures that the solution is both concise and efficient, handling all edge cases such as empty matrices or single-row matrices.\n- **Conversion from Tuples to Lists**: The `list()` function is used to convert each tuple returned by `zip` into a list, ensuring the output format matches the expected type.\n\nThis solution is optimal for matrices of any size, including edge cases, and provides the correct transposed matrix efficiently."}
{"task_id": 3, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a function that reshapes a given matrix into a specified shape. If the matrix cannot be reshaped to the specified dimensions, the function should return an empty list.\n\n### Approach\n1. **Convert the Input Matrix to a Numpy Array**: The input matrix is a list of lists, so we first convert it into a numpy array to leverage numpy's reshaping capabilities.\n2. **Calculate Total Elements**: Determine the total number of elements in the input matrix. This is done by multiplying the number of rows by the number of columns.\n3. **Check Feasibility of Reshaping**: Calculate the total number of elements required by the new shape. If this number does not match the total number of elements in the input matrix, return an empty list.\n4. **Reshape the Matrix**: If the reshaping is feasible, use numpy's reshape method to reshape the matrix into the desired dimensions.\n5. **Convert Back to List of Lists**: Convert the reshaped numpy array back into a list of lists for the final output.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef reshape_matrix(a: list[list[int|float]], new_shape: tuple[int, int]) -> list[list[int|float]]:\n    # Convert the input list to a numpy array\n    a_np = np.array(a)\n    \n    # Calculate the total number of elements in the original matrix\n    if not a or not a[0]:\n        total = 0\n    else:\n        total = len(a) * len(a[0])\n    \n    # Calculate the total number of elements required by the new shape\n    new_total = new_shape[0] * new_shape[1]\n    \n    # Check if the total number of elements matches\n    if total != new_total:\n        return []\n    \n    # Attempt to reshape the matrix\n    try:\n        a_reshaped = a_np.reshape(new_shape)\n    except:\n        return []\n    \n    # Convert the reshaped numpy array back to a list of lists\n    result = a_reshaped.tolist()\n    \n    return result\n```\n\n### Explanation\n- **Conversion to Numpy Array**: The input matrix is converted to a numpy array to utilize numpy's efficient reshaping functionality.\n- **Total Elements Calculation**: The total number of elements in the input matrix is calculated to ensure it matches the product of the new shape dimensions.\n- **Feasibility Check**: If the total number of elements does not match, the function returns an empty list as reshaping is not possible.\n- **Reshaping**: The matrix is reshaped using numpy's `reshape` method, which efficiently changes the matrix dimensions.\n- **Conversion to List of Lists**: The reshaped numpy array is converted back to a list of lists to meet the problem's output requirements.\n\nThis approach ensures that the function handles various edge cases, such as empty matrices or matrices with empty rows, and efficiently reshapes the matrix when possible."}
{"task_id": 4, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a Python function that calculates the mean of a matrix either by row or by column based on a given mode. The function will take a matrix (a list of lists) and a mode ('row' or 'column') as inputs and return a list of means according to the specified mode.\n\n### Approach\n1. **Understand the Input and Output**: The function takes a matrix and a mode. The matrix is a 2D list where each sublist represents a row. The mode can be either 'row' or 'column'. The output is a list of means, where each element corresponds to the mean of a row or column based on the mode.\n\n2. **Mode Handling**:\n   - **Row Mode**: For each row, compute the mean by summing all elements in the row and dividing by the number of elements in that row.\n   - **Column Mode**: For each column, compute the mean by summing all elements in the column across all rows and dividing by the number of rows.\n\n3. **Algorithm**:\n   - If the mode is 'row', iterate over each row, compute the mean, and collect these means in a result list.\n   - If the mode is 'column', determine the number of columns and iterate over each column. For each column, sum all elements across all rows, compute the mean, and collect these means in a result list.\n\n4. **Edge Cases**: Handle cases where the matrix might be empty or have varying row lengths, though the problem assumes a valid matrix structure.\n\n### Solution Code\n```python\ndef calculate_matrix_mean(matrix: list[list[float]], mode: str) -> list[float]:\n    if mode == 'row':\n        means = []\n        for row in matrix:\n            mean = sum(row) / len(row)\n            means.append(mean)\n        return means\n    elif mode == 'column':\n        if not matrix:\n            return []\n        num_rows = len(matrix)\n        num_cols = len(matrix[0]) if num_rows > 0 else 0\n        means = []\n        for col in range(num_cols):\n            total = 0.0\n            for row in matrix:\n                total += row[col]\n            mean = total / num_rows\n            means.append(mean)\n        return means\n    else:\n        raise ValueError(\"Invalid mode provided.\")\n```\n\n### Explanation\n- **Row Mode Calculation**: For each row in the matrix, the sum of the row elements is divided by the number of elements in the row to compute the mean. This mean is then added to the result list.\n- **Column Mode Calculation**: For each column, the sum of all elements in that column across all rows is computed. This sum is then divided by the number of rows to get the mean for that column, which is added to the result list.\n- The function efficiently handles both modes by iterating through the matrix in a structured manner, ensuring accurate computation of means for both rows and columns."}
{"task_id": 5, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a function that multiplies a given matrix by a scalar and returns the resulting matrix. The matrix is represented as a list of lists, where each element is either an integer or a float. The scalar can also be an integer or a float.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n1. **Iterate through each row of the matrix**: We need to process each row individually to apply the scalar multiplication.\n2. **Multiply each element by the scalar**: For each element in the row, multiply it by the given scalar.\n3. **Construct the resulting row**: Collect the multiplied elements into a new row.\n4. **Collect all resulting rows**: Append each new row to the resulting matrix.\n5. **Return the resulting matrix**: After processing all rows, return the constructed matrix.\n\nThis approach ensures that each element of the matrix is correctly multiplied by the scalar, and the structure of the matrix is preserved.\n\n### Solution Code\n```python\ndef scalar_multiply(matrix: list[list[int|float]], scalar: int|float) -> list[list[int|float]]:\n    result = []\n    for row in matrix:\n        new_row = [element * scalar for element in row]\n        result.append(new_row)\n    return result\n```\n\n### Explanation\n- **Matrix Structure**: The input matrix is a list of lists, where each inner list represents a row of the matrix.\n- **Scalar Multiplication**: Each element in the matrix is multiplied by the scalar. This is done using a list comprehension that iterates over each element in the row and applies the scalar multiplication.\n- **Result Construction**: Each new row, after applying the scalar multiplication, is appended to the result list. This constructs the resulting matrix row by row.\n- **Efficiency**: The solution efficiently processes each element exactly once, resulting in a time complexity of O(n*m), where n is the number of rows and m is the number of columns in the matrix. This ensures that the function performs well even for larger matrices.\n\nThis approach handles all edge cases, including empty matrices and matrices with empty rows, by gracefully returning an empty list in such cases."}
{"task_id": 6, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the eigenvalues of a 2x2 matrix. Eigenvalues are scalar values associated with a linear system of equations, and they are crucial in various applications such as solving systems of linear equations and analyzing the stability of a system.\n\n### Approach\nThe approach to find the eigenvalues of a 2x2 matrix involves the following steps:\n\n1. **Extract Elements**: Extract the elements of the 2x2 matrix.\n2. **Calculate Trace and Determinant**: Compute the trace (sum of the diagonal elements) and the determinant (product of the diagonal elements minus the product of the off-diagonal elements) of the matrix.\n3. **Compute Discriminant**: Use the trace and determinant to compute the discriminant, which is part of the characteristic equation used to find eigenvalues.\n4. **Calculate Eigenvalues**: Using the discriminant, compute the two eigenvalues. If the discriminant is non-negative, the eigenvalues will be real; otherwise, they will be complex.\n5. **Sort Eigenvalues**: Sort the eigenvalues in descending order and return them as a list.\n\n### Solution Code\n```python\nimport math\n\ndef calculate_eigenvalues(matrix: list[list[float|int]]) -> list[float]:\n    a = matrix[0][0]\n    b = matrix[0][1]\n    c = matrix[1][0]\n    d = matrix[1][1]\n    \n    trace = a + d\n    determinant = a * d - b * c\n    \n    discriminant = trace ** 2 - 4 * determinant\n    sqrt_discriminant = math.sqrt(discriminant)\n    \n    lambda1 = (trace + sqrt_discriminant) / 2\n    lambda2 = (trace - sqrt_discriminant) / 2\n    \n    eigenvalues = [lambda1, lambda2]\n    eigenvalues.sort(reverse=True)\n    \n    return eigenvalues\n```\n\n### Explanation\n1. **Extract Elements**: The elements of the 2x2 matrix are extracted into variables `a`, `b`, `c`, and `d`.\n2. **Calculate Trace and Determinant**: The trace is the sum of `a` and `d`, and the determinant is calculated as `ad - bc`.\n3. **Compute Discriminant**: The discriminant is given by the formula `trace^2 - 4 * determinant`.\n4. **Calculate Eigenvalues**: The eigenvalues are computed using the formula derived from the characteristic equation of a 2x2 matrix. The eigenvalues are `(trace + sqrt(discriminant)) / 2` and `(trace - sqrt(discriminant)) / 2`.\n5. **Sort Eigenvalues**: The eigenvalues are sorted in descending order to ensure the result is returned in the required format.\n\nThis approach efficiently computes the eigenvalues using basic matrix operations and mathematical formulas, ensuring accuracy and correctness for non-complex cases."}
{"task_id": 7, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to transform a given matrix \\( A \\) using the operation \\( T^{-1}AS \\), where \\( T \\) and \\( S \\) are invertible matrices. The function should first validate if the matrices \\( T \\) and \\( S \\) are invertible and then perform the transformation. If any matrix is not invertible or the transformation is not possible due to incompatible dimensions, the function should return -1.\n\n### Approach\n1. **Convert Matrices to Numpy Arrays**: Convert the input matrices \\( A \\), \\( T \\), and \\( S \\) into numpy arrays for easier manipulation.\n2. **Check Invertibility of \\( T \\)**: Determine if \\( T \\) is invertible by checking if its determinant is non-zero. If \\( T \\) is not invertible, return -1.\n3. **Compute Inverse of \\( T \\)**: If \\( T \\) is invertible, compute its inverse \\( T^{-1} \\).\n4. **Check Dimensions for Multiplication**: Ensure that the dimensions of \\( A \\) and \\( S \\) are compatible with the multiplication operations. Specifically, check if the number of rows of \\( A \\) matches the number of rows of \\( T \\) and if the number of columns of \\( A \\) matches the number of rows of \\( S \\).\n5. **Matrix Multiplication**: Perform the transformations \\( T^{-1}A \\) and \\( (T^{-1}A)S \\). If any multiplication step fails due to incompatible dimensions, return -1.\n6. **Reshape and Round Result**: Convert the resulting matrix to a list of lists and round each element to the nearest 4th decimal place.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef transform_matrix(A: list[list[int|float]], T: list[list[int|float]], S: list[list[int|float]]) -> list[list[int|float]]:\n    try:\n        t_matrix = np.array(T)\n        s_matrix = np.array(S)\n        a_matrix = np.array(A)\n    except:\n        return -1\n\n    # Check if T is square\n    if t_matrix.shape[0] != t_matrix.shape[1]:\n        return -1\n\n    # Check if T is invertible\n    try:\n        det_t = np.linalg.det(t_matrix)\n    except np.linalg.LinAlgError:\n        return -1\n\n    if abs(det_t) < 1e-6:  # Consider as non-invertible if determinant is near zero\n        return -1\n\n    try:\n        t_inv = np.linalg.inv(t_matrix)\n    except np.linalg.LinAlgError:\n        return -1\n\n    # Check dimensions for multiplication T_inv * A and result1 * S\n    if a_matrix.shape[0] != t_matrix.shape[0]:\n        return -1\n    if a_matrix.shape[1] != s_matrix.shape[0]:\n        return -1\n\n    try:\n        result1 = np.dot(t_inv, a_matrix)\n    except:\n        return -1\n\n    try:\n        result2 = np.dot(result1, s_matrix)\n    except:\n        return -1\n\n    # Convert to list of lists and round to 4 decimal places\n    result_list = result2.tolist()\n    rounded_result = []\n    for row in result_list:\n        rounded_row = [round(x, 4) for x in row]\n        rounded_result.append(rounded_row)\n\n    return rounded_result\n```\n\n### Explanation\n1. **Matrix Conversion**: The input matrices are converted from lists to numpy arrays to leverage numpy's matrix operations.\n2. **Invertibility Check**: The determinant of \\( T \\) is computed to check if it is invertible. If the determinant is zero (or near zero), \\( T \\) is not invertible.\n3. **Inverse Computation**: If \\( T \\) is invertible, its inverse is computed using numpy's `np.linalg.inv` function.\n4. **Dimension Check**: The function ensures that the dimensions of \\( A \\) and \\( S \\) are compatible with the transformation operations.\n5. **Matrix Multiplication**: The transformations \\( T^{-1}A \\) and \\( (T^{-1}A)S \\) are performed using numpy's `np.dot` function.\n6. **Result Conversion**: The resulting matrix is converted to a list of lists and each element is rounded to four decimal places for the final output.\n\nThis approach ensures that all edge cases, such as non-invertible matrices and incompatible dimensions, are handled appropriately, providing a robust solution to the matrix transformation problem."}
{"task_id": 8, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the inverse of a 2x2 matrix. The inverse of a matrix exists only if the determinant of the matrix is non-zero. If the determinant is zero, the matrix is not invertible, and we should return `None`.\n\n### Approach\n1. **Extract Elements**: Extract the elements of the 2x2 matrix. Let the elements be denoted as \\(a\\), \\(b\\), \\(c\\), and \\(d\\) such that the matrix is \\(\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\).\n2. **Calculate Determinant**: Compute the determinant of the matrix using the formula \\( \\text{det} = ad - bc \\).\n3. **Check Invertibility**: If the determinant is zero, return `None` as the matrix is not invertible.\n4. **Compute Inverse**: If the determinant is non-zero, compute the inverse using the formula:\n   \\[\n   \\text{Inverse} = \\frac{1}{\\text{det}} \\begin{bmatrix} d & -b \\\\ -c & a \\end{bmatrix}\n   \\]\n5. **Return Result**: Return the computed inverse matrix.\n\n### Solution Code\n```python\ndef inverse_2x2(matrix: list[list[float]]) -> list[list[float]]:\n    a = matrix[0][0]\n    b = matrix[0][1]\n    c = matrix[1][0]\n    d = matrix[1][1]\n    \n    det = a * d - b * c\n    if det == 0:\n        return None\n    else:\n        new_a = d / det\n        new_b = -b / det\n        new_c = -c / det\n        new_d = a / det\n        return [[new_a, new_b], [new_c, new_d]]\n```\n\n### Explanation\n1. **Extract Elements**: The elements \\(a\\), \\(b\\), \\(c\\), and \\(d\\) are extracted from the input matrix.\n2. **Calculate Determinant**: The determinant is calculated using the formula \\(ad - bc\\).\n3. **Check Invertibility**: If the determinant is zero, the function returns `None` because the matrix is not invertible.\n4. **Compute Inverse**: If the determinant is non-zero, the inverse matrix is computed using the formula for the inverse of a 2x2 matrix.\n5. **Return Result**: The computed inverse matrix is returned as a list of lists.\n\nThis approach ensures that we correctly handle both invertible and non-invertible 2x2 matrices, providing the correct inverse or indicating that the matrix is not invertible."}
{"task_id": 9, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a function that multiplies two matrices. If the matrices cannot be multiplied, the function should return -1. Matrix multiplication is only possible if the number of columns in the first matrix (a) is equal to the number of rows in the second matrix (b). Additionally, each row in a matrix must have the same number of elements as the first row of that matrix.\n\n### Approach\n1. **Check for Empty Matrices**: If either of the matrices is empty, return -1 as they cannot be multiplied.\n2. **Check Row Lengths**: Ensure all rows in each matrix have the same length as the first row. If any row does not meet this criterion, return -1.\n3. **Check Multiplication Compatibility**: Verify if the number of columns in the first matrix (a) is equal to the number of rows in the second matrix (b). If not, return -1.\n4. **Matrix Multiplication**: If all checks pass, compute the product matrix. The resulting matrix will have the same number of rows as the first matrix (a) and the same number of columns as the second matrix (b). Each element of the resulting matrix is computed as the dot product of the corresponding row from the first matrix and column from the second matrix.\n\n### Solution Code\n```python\ndef matrixmul(a: list[list[int|float]], b: list[list[int|float]]) -> list[list[int|float]]:\n    if not a or not b:\n        return -1\n    \n    # Check if all rows in a have the same length as the first row\n    n_cols_a = len(a[0])\n    for row in a:\n        if len(row) != n_cols_a:\n            return -1\n    \n    # Check if all rows in b have the same length as the first row\n    n_cols_b = len(b[0])\n    for row in b:\n        if len(row) != n_cols_b:\n            return -1\n    \n    # Check if multiplication is possible\n    if n_cols_a != len(b):\n        return -1\n    \n    # Compute the product matrix\n    result = []\n    for i in range(len(a)):\n        new_row = []\n        for j in range(len(b[0])):\n            sum_val = 0.0\n            for k in range(len(a[i])):\n                sum_val += a[i][k] * b[k][j]\n            new_row.append(sum_val)\n        result.append(new_row)\n    \n    return result\n```\n\n### Explanation\n1. **Empty Matrices Check**: The function first checks if either matrix is empty. If so, it returns -1.\n2. **Row Length Check**: It then ensures all rows in each matrix have consistent lengths. This is crucial for valid matrix operations.\n3. **Dimension Check**: The function verifies if the columns of the first matrix match the rows of the second matrix, a necessary condition for multiplication.\n4. **Matrix Multiplication**: If all checks are passed, the function computes each element of the resulting matrix by taking the dot product of the corresponding row and column from the input matrices. This involves nested loops to iterate through each element and compute the sum of products.\n\nThis approach ensures that all edge cases, such as empty matrices, inconsistent row lengths, and incompatible dimensions, are handled correctly, providing a robust solution for matrix multiplication."}
{"task_id": 10, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the covariance matrix for a given set of vectors. The covariance matrix is a square matrix where each element C_ij represents the covariance between the i-th and j-th features. The covariance between two features is a measure of how much they change together.\n\n### Approach\n1. **Input Handling**: Check if the input list of vectors is empty. If it is, return an empty matrix.\n2. **Compute Means**: For each feature, compute the mean of the observations.\n3. **Covariance Calculation**: For each pair of features (i, j), compute the covariance. If i equals j, compute the variance. Otherwise, compute the covariance using the formula:\n   - Covariance = (1/(n-1)) * sum((x_i - mean_i) * (x_j - mean_j)) for sample covariance.\n   - Population covariance would use n instead of n-1, but for this problem, we use sample covariance.\n\n### Solution Code\n```python\ndef calculate_covariance_matrix(vectors: list[list[float]]) -> list[list[float]]:\n    if not vectors:\n        return []\n    \n    n = len(vectors)\n    if n == 0:\n        return []\n    \n    n_features = len(vectors[0])\n    means = [sum(v[i] for v in vectors) / n for i in range(n_features)]\n    \n    cov_matrix = []\n    for i in range(n_features):\n        row = []\n        for j in range(n_features):\n            if i == j:\n                # Calculate variance for feature i\n                sum_sq_diff = sum((x - means[i]) ** 2 for x in vectors[i])\n                if n == 1:\n                    var = 0.0\n                else:\n                    var = sum_sq_diff / (n - 1)\n                row.append(var)\n            else:\n                # Calculate covariance between feature i and j\n                sum_product = 0.0\n                for k in range(n):\n                    x_i = vectors[k][i]\n                    x_j = vectors[k][j]\n                    sum_product += (x_i - means[i]) * (x_j - means[j])\n                if n == 1:\n                    cov = 0.0\n                else:\n                    cov = sum_product / (n - 1)\n                row.append(cov)\n        cov_matrix.append(row)\n    \n    return cov_matrix\n```\n\n### Explanation\n1. **Input Handling**: The function first checks if the input list of vectors is empty and returns an empty matrix if true.\n2. **Compute Means**: For each feature, the mean is calculated by summing all observations and dividing by the number of samples.\n3. **Covariance Calculation**: For each pair of features, the covariance is computed. If the features are the same (i.e., i == j), the variance is calculated. Otherwise, the covariance is calculated using the sum of the product of deviations from the mean, divided by (n-1) for sample covariance.\n\nThis approach ensures that we correctly compute the covariance matrix, which is essential for understanding the relationships between different features in a dataset."}
{"task_id": 11, "completion_id": 0, "completion": "\n\nTo solve the system of linear equations using the Jacobi method, we'll implement an iterative approach where each variable is updated based on the previous iteration's values. The solution is computed iteratively for a specified number of times, with each intermediate result rounded to four decimal places.\n\n### Approach\n1. **Initialization**: Start with an initial guess for the solution vector, typically set to zero.\n2. **Iteration**: For each iteration:\n   - Compute the residual vector by subtracting the product of matrix A and the current solution vector from vector b.\n   - Compute the inverse of the diagonal matrix D, where D is formed from the diagonal elements of A.\n   - Update the solution vector using the inverse of D multiplied by the residual vector.\n   - Round the updated solution vector to four decimal places.\n3. **Termination**: After the specified number of iterations, return the solution vector as a list.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef solve_jacobi(A: np.ndarray, b: np.ndarray, n: int) -> list:\n    x = np.zeros_like(b)\n    for _ in range(n):\n        residual = b - A @ x\n        D_inv = np.linalg.inv(np.diag(A))\n        new_x = np.dot(D_inv, residual)\n        x = np.round(new_x, 4)\n    return x.tolist()\n```\n\n### Explanation\n- **Initialization**: The solution vector `x` is initialized to zeros.\n- **Residual Calculation**: For each iteration, the residual vector is computed as `b - A @ x`.\n- **Diagonal Inverse**: The inverse of the diagonal matrix formed from the diagonal elements of A is calculated.\n- **Solution Update**: The new solution vector is obtained by multiplying the diagonal inverse with the residual vector.\n- **Rounding**: The solution vector is rounded to four decimal places to maintain precision and prevent rounding errors.\n- **Iteration**: This process repeats for the specified number of iterations, refining the solution each time.\n\nThis approach ensures that each variable is updated using the values from the previous iteration, providing an iterative method to approximate the solution of the system of linear equations."}
{"task_id": 12, "completion_id": 0, "completion": "To solve this problem, we need to perform a Singular Value Decomposition (SVD) on a 2x2 matrix using the Jacobian method. The SVD decomposes a matrix into three components: a column orthogonal matrix (U), a diagonal matrix (\u03a3), and a row orthogonal matrix (V^T), such that A = U \u03a3 V^T. The singular values are the non-zero eigenvalues of the matrix A^T A.\n\n### Approach\nThe approach involves the following steps:\n1. **Compute the transpose of the matrix A and multiply it by A to get A^T A**. This product helps in finding the eigenvalues which are used to determine the singular values.\n2. **Find the eigenvalues of A^T A**. These eigenvalues are the squares of the singular values of A.\n3. **Take the square roots of these eigenvalues** to get the singular values.\n4. **Compute the left and right singular vectors** using the eigenvectors of A^T A and A A^T, respectively. These vectors form the matrices U and V, which are orthogonal and normalized.\n5. **Return the singular values along with the matrices U and V**.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef svd_2x2_singular_values(A: np.ndarray) -> tuple:\n    # Compute A^T @ A\n    A_transpose_A = A.T @ A\n    # Find eigenvalues of A^T A\n    eigenvalues = np.linalg.eigvals(A_transpose_A)\n    # Compute singular values as the square roots of the absolute values of eigenvalues\n    singular_values = np.sqrt(np.abs(eigenvalues))\n    # Sort singular values in descending order\n    singular_values = sorted(singular_values, reverse=True)\n    \n    # Compute left singular vectors (U) from eigenvectors of A^T A\n    _, U_eigen = np.linalg.eig(A_transpose_A)\n    U = U_eigen.T\n    # Normalize U to make it orthogonal\n    U = U / (np.linalg.norm(U, axis=0, keepdims=True))\n    \n    # Compute right singular vectors (V) from eigenvectors of A @ A.T\n    _, V_eigen = np.linalg.eig(A @ A.T)\n    V = V_eigen.T\n    # Normalize V to make it orthogonal\n    V = V / (np.linalg.norm(V, axis=0, keepdims=True))\n    \n    return (singular_values[0], singular_values[1], U, V)\n```\n\n### Explanation\n1. **Eigenvalues Calculation**: The eigenvalues of A^T A are computed to find the singular values. These eigenvalues are the squares of the singular values of A.\n2. **Singular Values**: The square roots of these eigenvalues give the singular values.\n3. **Eigenvectors**: The eigenvectors of A^T A and A A^T are used to form the orthogonal matrices U and V, respectively. These matrices are normalized to ensure orthogonality.\n4. **Result**: The function returns the singular values along with the matrices U and V, providing a complete SVD decomposition of the input matrix A."}
{"task_id": 13, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the determinant of a 4x4 matrix using Laplace's Expansion (also known as cofactor expansion). This method involves expanding along a row or column, computing minors, and recursively calculating the determinants of those minors.\n\n### Approach\nThe approach involves the following steps:\n1. **Recursive Determinant Calculation**: We use a helper function to compute the determinant of an n x n matrix recursively. This function handles matrices of any size, including 2x2, 3x3, and 4x4 matrices.\n2. **Cofactor Expansion**: For a given matrix, we expand along the first row. For each element in this row, we compute the minor matrix by removing the first row and the current column. The minor's determinant is then calculated recursively.\n3. **Sign Calculation**: Each element in the expansion is multiplied by a sign, which alternates based on the position of the element. The sign is calculated as (-1)^(row+column).\n4. **Summation**: The contributions from each element in the row are summed to get the final determinant.\n\n### Solution Code\n```python\ndef determinant_4x4(matrix: list[list[int|float]]) -> float:\n    def determinant(matrix):\n        n = len(matrix)\n        if n == 1:\n            return matrix[0][0]\n        if n == 2:\n            return matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n        det = 0\n        for j in range(n):\n            minor = [row[:j] + row[j+1:] for row in matrix[1:]]\n            sign = (-1) ** (0 + j)\n            det += matrix[0][j] * sign * determinant(minor)\n        return det\n    return determinant(matrix)\n```\n\n### Explanation\n1. **Recursive Helper Function**: The helper function `determinant` is defined to handle matrices of any size. It checks the size of the matrix and computes the determinant accordingly.\n2. **Base Cases**: For 1x1 and 2x2 matrices, the determinant is computed directly using simple formulas.\n3. **Cofactor Expansion for Larger Matrices**: For matrices larger than 2x2, the function expands along the first row. Each element in this row is processed to form a minor matrix, which is then recursively passed to the determinant function.\n4. **Minor Construction**: For each element in the first row, the minor matrix is constructed by excluding the first row and the current column.\n5. **Sign and Contribution Calculation**: Each element's contribution to the determinant is calculated by multiplying the element with its sign and the determinant of its minor. These contributions are summed to get the final determinant.\n\nThis approach efficiently breaks down the problem into smaller subproblems, leveraging recursion to handle determinants of smaller matrices, ultimately providing the determinant of the original 4x4 matrix."}
{"task_id": 14, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to perform linear regression using the normal equation method. The normal equation is derived from the ordinary least squares method and provides a way to estimate the coefficients of a linear regression model. The formula for the coefficients using the normal equation is given by \\((X^T X)^{-1} X^T y\\), where \\(X\\) is the matrix of features and \\(y\\) is the vector of targets.\n\n### Approach\n1. **Convert Input to Numpy Arrays**: Convert the input lists of features \\(X\\) and targets \\(y\\) into numpy arrays for efficient matrix operations.\n2. **Compute \\(X^T X\\)**: Calculate the product of the transpose of \\(X\\) and \\(X\\) itself, which gives the covariance matrix.\n3. **Compute the Inverse of the Covariance Matrix**: Find the inverse of the covariance matrix \\(X^T X\\).\n4. **Compute \\(X^T y\\)**: Calculate the product of the transpose of \\(X\\) and the vector \\(y\\), which gives the vector of coefficients in a simplified form.\n5. **Multiply Inverse by \\(X^T y\\)**: Use the inverse covariance matrix to scale the simplified coefficients vector to get the final coefficients.\n6. **Round the Result**: Round the resulting coefficients to four decimal places and return them as a list of floats.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef linear_regression_normal_equation(X: list[list[float]], y: list[float]) -> list[float]:\n    X = np.array(X)\n    y = np.array(y)\n    X_transpose_X = np.dot(X.T, X)\n    X_transpose_y = np.dot(X.T, y)\n    inv_XTX = np.linalg.inv(X_transpose_X)\n    beta = np.dot(inv_XTX, X_transpose_y)\n    beta_rounded = round(beta, 4)\n    return beta_rounded.tolist()\n```\n\n### Explanation\n1. **Conversion to Numpy Arrays**: The input lists \\(X\\) and \\(y\\) are converted to numpy arrays to leverage efficient matrix operations.\n2. **Covariance Matrix Calculation**: The product of the transpose of \\(X\\) and \\(X\\) gives the covariance matrix, which is essential for the normal equation.\n3. **Inverse Calculation**: The inverse of the covariance matrix is computed, which is necessary for scaling the simplified coefficients vector.\n4. **Coefficient Calculation**: The product of the inverse covariance matrix and the vector \\(X^T y\\) gives the final coefficients of the linear regression model.\n5. **Rounding**: The coefficients are rounded to four decimal places to meet the problem's requirements, ensuring precision and correctness.\n\nThis approach efficiently computes the linear regression coefficients using the normal equation method, ensuring accurate and precise results."}
{"task_id": 15, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that performs linear regression using the gradient descent algorithm. The function will take NumPy arrays for features (X) and target values (y), along with learning rate (alpha) and the number of iterations, and return the coefficients of the linear regression model rounded to four decimal places.\n\n### Approach\n1. **Problem Analysis**: Linear regression is a statistical method used to find a linear relationship between variables. The goal is to minimize the mean squared error (MSE) between the predicted values and the actual values. The gradient descent algorithm is an iterative optimization algorithm that adjusts the model's coefficients to minimize this error.\n\n2. **Intuition**: The gradient descent algorithm works by updating the model's coefficients in the direction that reduces the error. This is done by computing the gradient of the cost function (MSE) with respect to each coefficient and adjusting the coefficients by a small step size (learning rate).\n\n3. **Algorithm Selection**: We use the gradient descent algorithm because it is simple and effective for finding the minimum of the MSE function. The algorithm iteratively updates the coefficients until the specified number of iterations is reached.\n\n4. **Complexity Analysis**: The time complexity of the algorithm is O(N * iterations), where N is the number of samples and iterations is the number of iterations specified. This is because each iteration involves computing the error for all samples and updating the coefficients.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> list:\n    N = X.shape[0]\n    K = X.shape[1] - 1  # Number of coefficients excluding the intercept\n    w = np.zeros(K, dtype=np.float64)\n    \n    for _ in range(iterations):\n        y_hat = np.dot(X, w)\n        error = y - y_hat\n        gradients = (X.T @ error) / N\n        w -= alpha * gradients\n    \n    # Round each coefficient to four decimal places\n    rounded_w = [round(coeff, 4) for coeff in w]\n    return rounded_w\n```\n\n### Explanation\n1. **Initialization**: The function starts by initializing the coefficients (weights) to zero. The number of coefficients is determined by the number of features in X, excluding the intercept term which is included in X.\n\n2. **Iteration Process**: For each iteration, the function computes the predicted values (y_hat) using the current coefficients. It then calculates the error between the predicted values and the actual values (y).\n\n3. **Gradient Calculation**: The gradient of the error with respect to the coefficients is computed using matrix multiplication. This gradient is then scaled by the learning rate and subtracted from the current coefficients to update them.\n\n4. **Rounding**: After completing the specified number of iterations, the coefficients are rounded to four decimal places and returned as a list.\n\nThis approach ensures that the model coefficients are adjusted iteratively to minimize the error, providing a good approximation of the linear relationship between the features and the target variable."}
{"task_id": 16, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that performs feature scaling on a dataset using both standardization and min-max normalization. The function will take a 2D NumPy array as input, where each row represents a data sample and each column represents a feature. It will return two 2D lists: one scaled by standardization and one by min-max normalization. Each result will be rounded to the nearest 4th decimal and converted into lists using the `tolist()` method.\n\n### Approach\n1. **Standardization (Z-score Normalization)**:\n   - For each feature, compute the mean and standard deviation.\n   - Subtract the mean from each data point and divide by the standard deviation to center the data around zero and scale it to unit variance.\n\n2. **Min-Max Normalization**:\n   - For each feature, find the minimum and maximum values.\n   - Subtract the minimum value from each data point and divide by the range (max value - min value) to scale the data to the interval [0, 1].\n\n3. **Conversion to Lists**:\n   - Convert the resulting NumPy arrays from both standardization and min-max normalization into lists of lists, with each element rounded to 4 decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef feature_scaling(data: np.ndarray) -> (list[list[float]], list[list[float]]):\n    # Compute standardized data\n    mean = data.mean(axis=0)\n    std = data.std(axis=0)\n    std_data = (data - mean) / std\n\n    # Compute min-max normalized data\n    min_val = data.min(axis=0)\n    max_val = data.max(axis=0)\n    range_ = max_val - min_val\n    min_max_data = (data - min_val) / range_\n\n    # Convert to lists with rounding\n    std_list = [[round(x, 4) for x in row] for row in std_data]\n    min_max_list = [[round(x, 4) for x in row] for row in min_max_data]\n\n    return std_list, min_max_list\n```\n\n### Explanation\n- **Standardization**: This process ensures that each feature is scaled to have a mean of 0 and a standard deviation of 1. This helps in making the data distribution more uniform, which is useful for many machine learning algorithms that perform poorly with varying scales of features.\n- **Min-Max Normalization**: This process scales each feature to the range [0, 1]. This is particularly useful when the input data is not centered and the range of values is large, making it harder for models to learn properly.\n- **Conversion to Lists**: The results from both normalization methods are converted into lists of lists to meet the problem requirements, ensuring each value is rounded to four decimal places for precision.\n\nThis approach efficiently handles the feature scaling using vectorized operations in NumPy, ensuring the solution is both optimal and easy to understand."}
{"task_id": 17, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the k-Means clustering algorithm using the normal equation approach. The goal is to partition a given set of points into k clusters, where each cluster is represented by its centroid. The centroids are updated iteratively until the maximum number of iterations is reached or the centroids stabilize.\n\n### Approach\nThe k-Means clustering algorithm works by iteratively finding the centroids of clusters and assigning each point to the nearest centroid. The process involves two main steps: assignment and update.\n\n1. **Assignment Step**: For each point, compute the distance to each centroid and assign the point to the cluster with the nearest centroid.\n2. **Update Step**: Compute the new centroid for each cluster by averaging the coordinates of the points assigned to that cluster.\n\nThe algorithm continues iterating until the centroids do not change significantly (based on a small tolerance) or the maximum number of iterations is reached.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef k_means_clustering(points: list[tuple[float, float]], k: int, initial_centroids: list[tuple[float, float]], max_iterations: int) -> list[tuple[float, float]]:\n    current_centroids = list(initial_centroids)\n    prev_assignment = None\n\n    for _ in range(max_iterations):\n        # Sort centroids to ensure consistent assignment\n        sorted_centroids = sorted(current_centroids, key=lambda c: (c[0], c[1]))\n        distances = []\n        for point in points:\n            dists = []\n            for centroid in sorted_centroids:\n                dx = point[0] - centroid[0]\n                dy = point[1] - centroid[1]\n                dist = np.sqrt(dx**2 + dy**2)\n                dists.append(dist)\n            distances.append(dists)\n        \n        # Assign each point to the nearest centroid\n        assignment = [0] * len(points)\n        for i, point in enumerate(points):\n            min_dist = float('inf')\n            cluster = 0\n            for j, dist in enumerate(distances[i]):\n                if dist < min_dist:\n                    min_dist = dist\n                    cluster = j\n            assignment[i] = cluster\n        \n        # Check if assignment has changed\n        if prev_assignment is not None and assignment == prev_assignment:\n            break\n        \n        # Update centroids\n        new_centroids = []\n        for cluster in range(k):\n            cluster_points = [points[i] for i in range(len(points)) if assignment[i] == cluster]\n            x = np.mean([p[0] for p in cluster_points])\n            y = np.mean([p[1] for p in cluster_points])\n            new_centroids.append((x, y))\n        \n        # Check if centroids have not changed\n        if all(np.abs(new_centroids[i] - current_centroids[i]) < 1e-6 for i in range(k)):\n            break\n        \n        # Update current centroids and sort them\n        current_centroids = new_centroids\n        current_centroids = sorted(current_centroids, key=lambda c: (c[0], c[1]))\n        prev_assignment = assignment\n\n    # Round the centroids to four decimal places\n    rounded_centroids = [(round(x, 4), round(y, 4)) for (x, y) in current_centroids]\n    return rounded_centroids\n```\n\n### Explanation\n1. **Initialization**: The function starts by initializing the current centroids with the provided initial centroids.\n2. **Sorting Centroids**: In each iteration, the centroids are sorted to ensure consistent assignment of points.\n3. **Distance Calculation**: For each point, the distances to all centroids are computed.\n4. **Assignment**: Each point is assigned to the nearest centroid based on the computed distances.\n5. **Update Check**: If the assignment is the same as the previous iteration, the loop breaks to avoid infinite loops.\n6. **Centroid Update**: New centroids are computed by averaging the coordinates of the points assigned to each cluster.\n7. **Convergence Check**: If the new centroids are close enough to the old ones, the loop breaks to indicate convergence.\n8. **Rounding**: The final centroids are rounded to four decimal places and returned.\n\nThis approach ensures that the k-Means clustering is performed efficiently and correctly, providing the final centroids as required."}
{"task_id": 18, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement K-Fold Cross-Validation, which involves dividing a dataset into K equal parts and then using each part as a test set while the remaining parts are used as training sets. This process is repeated for each fold, ensuring that each part of the dataset is used exactly once as a test set.\n\n### Approach\n1. **Determine the Number of Samples**: Calculate the length of the input data arrays X and y, which gives the total number of samples.\n2. **Set Random Seed**: If a random seed is provided, set it to ensure reproducibility of the results.\n3. **Generate Indices**: Create a list of indices representing the positions of the samples in the dataset.\n4. **Shuffle Indices**: If shuffling is required, shuffle the indices to ensure each fold is a random subset of the dataset.\n5. **Split Indices into Folds**: Divide the shuffled indices into K equal parts, each representing a fold.\n6. **Compute Training and Test Indices**: For each fold, determine the training indices as the union of all other folds and the test indices as the current fold.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef k_fold_cross_validation(X: np.ndarray, y: np.ndarray, k=5, shuffle=True, random_seed=None):\n    n = len(X)\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    all_indices = np.arange(n)\n    if shuffle:\n        all_indices = np.random.permutation(all_indices)\n    folds = np.split(all_indices, k)\n    result = []\n    for i, fold in enumerate(folds):\n        start = i * (n // k)\n        end = start + len(fold)\n        train = np.concatenate([all_indices[0:start], all_indices[end:]])\n        result.append((train, fold))\n    return result\n```\n\n### Explanation\n1. **Random Seed Handling**: The function starts by setting a random seed if provided, ensuring that the shuffling of indices is reproducible.\n2. **Index Generation and Shuffling**: The indices of the dataset are generated and shuffled if required, ensuring each fold is a random subset.\n3. **Folding the Dataset**: The shuffled indices are split into K equal parts, each representing a fold.\n4. **Training and Test Indices**: For each fold, the training indices are computed by concatenating the indices before and after the current fold. The test indices are simply the current fold itself.\n\nThis approach ensures that each fold is used exactly once as a test set, and the remaining parts are used as training sets, providing a standard method for evaluating models across different folds of the dataset."}
{"task_id": 19, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a Principal Component Analysis (PCA) from scratch. PCA is a dimensionality reduction technique that transforms data into a set of principal components, which capture the most variance in the data. This method is widely used in various applications such as feature engineering, dimensionality reduction, and visualization.\n\n### Approach\nThe approach to implement PCA involves the following steps:\n\n1. **Standardization**: Normalize the input data to have a mean of zero and a standard deviation of one. This step ensures that each feature contributes equally to the covariance matrix.\n2. **Covariance Matrix**: Compute the covariance matrix of the standardized data. This matrix captures the relationships between different features.\n3. **Eigenvalues and Eigenvectors**: Calculate the eigenvalues and eigenvectors of the covariance matrix. The eigenvectors corresponding to the largest eigenvalues are the principal components.\n4. **Select Top k Components**: Determine the top k principal components based on the eigenvalues. The eigenvalues are sorted in descending order, and the corresponding eigenvectors are selected.\n5. **Rounding**: Round each component of the principal components to the nearest 4th decimal for the final result.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef pca(data: np.ndarray, k: int) -> list[list[float]]:\n    # Standardize the data\n    n_samples, n_features = data.shape\n    mean = np.mean(data, axis=1)\n    std = np.std(data, axis=1)\n    std_data = (data - mean[:, np.newaxis]) / std[:, np.newaxis]\n    \n    # Compute covariance matrix\n    cov_matrix = np.cov(std_data, rowvar=False)\n    \n    # Compute eigenvalues and eigenvectors\n    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n    \n    # Determine the number of features and adjust k\n    n_features = data.shape[1]\n    k = min(k, n_features)\n    \n    # Sort eigenvalues in descending order and get the indices\n    sorted_indices = np.argsort(-eigenvalues)\n    top_k_indices = sorted_indices[:k]\n    \n    # Get the top k principal components\n    principal_components = eigenvectors[top_k_indices]\n    \n    # Round to the nearest 4th decimal\n    rounded_components = [[round(v, 4) for v in pc] for pc in principal_components]\n    \n    return rounded_components\n```\n\n### Explanation\n1. **Standardization**: The input data is centered by subtracting the mean and scaled by dividing by the standard deviation. This step ensures that each feature's scale does not affect the covariance matrix.\n2. **Covariance Matrix**: The covariance matrix is computed using `np.cov`, which provides the average of the outer product of columns, adjusted for the number of samples.\n3. **Eigenvalues and Eigenvectors**: The eigenvalues and eigenvectors are computed using `np.linalg.eig`. The eigenvalues represent the variance captured by each principal component, while the eigenvectors are the directions in which this variance is captured.\n4. **Top k Components**: The eigenvalues are sorted in descending order, and the top k eigenvectors are selected. These eigenvectors form the principal components.\n5. **Rounding**: Each component of the principal components is rounded to four decimal places to meet the problem's requirements.\n\nThis approach ensures that the principal components are computed accurately and efficiently, providing a reduced-dimensional representation of the input data."}
{"task_id": 20, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a decision tree learning algorithm that builds a classification model using recursive binary splitting based on entropy and information gain. The decision tree will be represented as a nested dictionary where each node is either an internal node (containing attributes as keys and child nodes as values) or a leaf node (containing the target class as the value).\n\n### Approach\n1. **Entropy Calculation**: Entropy measures the impurity of a dataset. It is calculated using the formula \\( H = -\\sum p \\log_2 p \\), where \\( p \\) is the probability of each outcome.\n2. **Information Gain**: Information gain is the reduction in entropy when a dataset is split based on an attribute. It is computed as the difference between the entropy of the current subset and the average entropy of the subsets obtained by splitting on each possible value of the attribute.\n3. **Recursive Splitting**: The algorithm recursively splits the dataset by selecting the attribute with the highest information gain. This attribute becomes the current node, and the dataset is split into subsets based on the attribute's values.\n4. **Base Cases**: The algorithm handles base cases where there are no examples, all examples have the same target value, or there are no attributes left to split on.\n\n### Solution Code\n```python\nimport math\nfrom collections import Counter\n\ndef learn_decision_tree(examples: list[dict], attributes: list[str], target_attr: str) -> dict:\n    if not examples:\n        return None  # Handle empty examples case\n    \n    target_values = list({example[target_attr] for example in examples})\n    if len(target_values) == 1:\n        return target_values[0]  # All examples have the same target value\n    \n    if not attributes:\n        return target_values[0]  # No attributes left, return the target value\n    \n    def compute_entropy(subset):\n        counts = Counter(subset[target_attr])\n        entropy = 0\n        for count in counts.values():\n            prob = count / len(subset)\n            entropy -= prob * math.log2(prob)\n        return entropy\n    \n    def compute_information_gain(subset, attribute):\n        current_entropy = compute_entropy(subset)\n        if current_entropy == 0:\n            return 0  # No information gain, skip this attribute\n        groups = group_by_attribute(subset, attribute)\n        group_entropies = [compute_entropy(group) for group in groups.values()]\n        avg_entropy = sum(group_entropies) / len(groups)\n        return current_entropy - avg_entropy\n    \n    def group_by_attribute(subset, attribute):\n        groups = {}\n        for example in subset:\n            value = example[attribute]\n            if value not in groups:\n                groups[value] = []\n            groups[value].append(example)\n        return groups\n    \n    best_attr = None\n    max_gain = -1\n    for attr in attributes:\n        gain = compute_information_gain(examples, attr)\n        if gain > max_gain:\n            max_gain = gain\n            best_attr = attr\n    \n    groups = group_by_attribute(examples, best_attr)\n    children = {}\n    for value, group in groups.items():\n        child = build_tree(group)\n        children[value] = child\n    return {best_attr: children}\n\ndef build_tree(subset, attributes, target_attr):\n    if not subset:\n        return None\n    target_values = list({example[target_attr] for example in subset})\n    if len(target_values) == 1:\n        return {'target': target_values[0]}\n    if not attributes:\n        return {'target': target_values[0]}\n    \n    current_entropy = compute_entropy(subset)\n    max_gain = -1\n    best_attr = None\n    for attr in attributes:\n        gain = compute_information_gain(subset, attr)\n        if gain > max_gain:\n            max_gain = gain\n            best_attr = attr\n    \n    groups = group_by_attribute(subset, best_attr)\n    children = {}\n    for value, group in groups.items():\n        child = build_tree(group, attributes, target_attr)\n        children[value] = child\n    return {best_attr: children}\n\ndef compute_information_gain(subset, attribute):\n    current_entropy = compute_entropy(subset)\n    if current_entropy == 0:\n        return 0\n    groups = group_by_attribute(subset, attribute)\n    group_entropies = [compute_entropy(group) for group in groups.values()]\n    avg_entropy = sum(group_entropies) / len(groups)\n    return current_entropy - avg_entropy\n\ndef group_by_attribute(subset, attribute):\n    groups = {}\n    for example in subset:\n        value = example[attribute]\n        if value not in groups:\n            groups[value] = []\n        groups[value].append(example)\n    return groups\n```\n\n### Explanation\n1. **Entropy Calculation**: The `compute_entropy` function calculates the entropy of a given subset of examples based on the target attribute.\n2. **Information Gain Calculation**: The `compute_information_gain` function calculates the information gain for each attribute by splitting the dataset and computing the average entropy of the resulting subsets.\n3. **Grouping by Attribute**: The `group_by_attribute` function groups examples based on the values of a specified attribute.\n4. **Building the Decision Tree**: The `build_tree` function recursively constructs the decision tree by selecting the attribute with the highest information gain, splitting the dataset, and building subtrees for each resulting subset.\n5. **Base Cases Handling**: The function handles cases where there are no examples, all examples have the same target value, or there are no attributes left to split on, ensuring the algorithm terminates correctly.\n\nThis approach ensures that the decision tree is built optimally, minimizing entropy and information gain at each step to create an effective classification model."}
{"task_id": 21, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a deterministic version of the Pegasos algorithm to train a kernel SVM classifier from scratch. The function should take a dataset, labels, and training parameters such as the choice of kernel, regularization parameter, and the number of iterations. The function should return the model's alpha coefficients and bias, rounded to four decimal places.\n\n### Approach\nThe Pegasos algorithm is an optimization method for Support Vector Machines (SVMs) that uses a deterministic approach by averaging gradients over all samples at each step. The algorithm is designed to handle both linear and Radial Basis Function (RBF) kernels.\n\n1. **Kernel Matrix Computation**: Depending on the kernel type, compute the kernel matrix. For a linear kernel, this is the inner product matrix of the data. For an RBF kernel, this is a matrix of Gaussian functions of the distances between data points.\n\n2. **Initialization**: Initialize the alpha coefficients (weights) and bias term of the SVM model to zero.\n\n3. **Iteration Process**: For each iteration, compute the decision function for each sample using the current model parameters. Update the model parameters by averaging the gradients of the loss function over all samples.\n\n4. **Gradient Computation**: Compute the gradients of the loss function with respect to the alpha coefficients and bias term. Update the model parameters by subtracting the averaged gradients scaled by the regularization parameter.\n\n5. **Result Preparation**: After completing the specified number of iterations, round the alpha coefficients and bias term to four decimal places and return them as a list.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef pegasos_kernel_svm(data: np.ndarray, labels: np.ndarray, kernel='linear', lambda_val=0.01, iterations=100, sigma=1.0):\n    n = data.shape[0]\n    y = labels\n    alpha = np.zeros(n, dtype=np.float64)\n    b = 0.0\n\n    # Precompute the kernel matrix\n    if kernel == 'linear':\n        K = data @ data.T\n    else:\n        # Compute RBF kernel\n        K = np.exp(-sigma**2 * np.linalg.norm(data[:, :] - data[:, :], axis=1)**2)\n    \n    for _ in range(iterations):\n        # Compute decision values for all samples\n        dec = np.dot(alpha.reshape(-1, 1), K) + b.reshape(-1, 1)\n        \n        # Compute gradients for all samples\n        g = (y * data) - lambda_val * (1 - y * dec) / (1 + np.linalg.norm(data, axis=1)**2)\n        \n        # Average gradients\n        avg_g = np.mean(g)\n        \n        # Update alpha\n        alpha -= lambda_val * avg_g\n        \n        # Compute gradients for bias\n        g_b = -y * (1 - y * dec) / (1 + np.linalg.norm(data, axis=1)**2)\n        avg_g_b = np.mean(g_b)\n        \n        # Update bias\n        b -= lambda_val * avg_g_b\n    \n    # Round the results to four decimal places\n    alpha_rounded = np.round(alpha, 4)\n    b_rounded = np.round(b, 4)\n    \n    # Return as a list\n    return alpha_rounded.tolist() + [b_rounded]\n```\n\n### Explanation\n1. **Kernel Matrix**: The kernel matrix is computed once before the iterations. For a linear kernel, it is the product of the data matrix with its transpose. For an RBF kernel, it is a matrix of Gaussian functions based on the distances between data points.\n\n2. **Decision Function**: For each sample, the decision function is computed using the current model parameters. This function determines the confidence of the model for each sample.\n\n3. **Gradients**: The gradients of the loss function with respect to the model parameters are computed. These gradients are then averaged over all samples to update the model parameters.\n\n4. **Parameter Update**: The model parameters (alpha coefficients and bias) are updated by subtracting the averaged gradients scaled by the regularization parameter. This process is repeated for the specified number of iterations.\n\n5. **Result**: After completing the iterations, the alpha coefficients and bias are rounded to four decimal places and returned as a list, providing the final model parameters."}
{"task_id": 22, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the output of the sigmoid activation function given an input value \\( z \\). The sigmoid function is a logistic function that maps any real number to a value between 0 and 1. This is a fundamental operation in neural networks and machine learning.\n\n### Approach\nThe sigmoid function is defined by the formula:\n\\[ \\text{sigmoid}(z) = \\frac{1}{1 + e^{-z}} \\]\nTo compute this, we follow these steps:\n1. Calculate \\( e^{-z} \\) using the exponential function.\n2. Add 1 to the result of the exponential calculation.\n3. Take the reciprocal of the sum obtained in the previous step.\n4. Round the result to four decimal places for precision.\n\nThis approach ensures that the output of the sigmoid function is always between 0 and 1, which is the desired behavior for an activation function.\n\n### Solution Code\n```python\nimport math\n\ndef sigmoid(z: float) -> float:\n    exp_term = math.exp(-z)\n    return round(1 / (1 + exp_term), 4)\n```\n\n### Explanation\n1. **Exponential Calculation**: The function first computes \\( e^{-z} \\) using `math.exp(-z)`. This step is crucial as it transforms the input \\( z \\) into a form that can be used to compute the sigmoid value.\n2. **Sum Calculation**: The result of the exponential function is added to 1, which forms the denominator of the sigmoid function.\n3. **Reciprocal Calculation**: The reciprocal of the sum is computed, which gives the value of the sigmoid function.\n4. **Rounding**: The result is rounded to four decimal places to ensure precision and meet the problem requirements.\n\nThis solution efficiently computes the sigmoid activation function and handles all possible input values correctly, ensuring the output is always within the range [0, 1]."}
{"task_id": 23, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the Softmax activation function for a given list of scores. The Softmax function is a common activation function used in neural networks to normalize the output of a layer, ensuring that the output values are within a bounded range.\n\n### Approach\nThe Softmax function is defined as follows:\n- For each score \\( s_i \\), compute the exponential of \\( s_i \\) (denoted as \\( e^{s_i} \\)).\n- Compute the sum of all these exponential values.\n- Divide each exponential value by this sum to get the Softmax value for that score.\n\nThe steps to implement this are:\n1. Compute the sum of the exponential values of each score.\n2. For each score, compute its exponential value and divide it by the sum of all exponential values.\n3. Round each resulting value to four decimal places.\n\n### Solution Code\n```python\nimport math\n\ndef softmax(scores: list[float]) -> list[float]:\n    sum_exp = sum(math.exp(s) for s in scores)\n    if sum_exp == 0:\n        return [0.0 for _ in scores]\n    # Compute each element\n    softmax_values = [math.exp(s) / sum_exp for s in scores]\n    # Round each to four decimals\n    return [round(val, 4) for val in softmax_values]\n```\n\n### Explanation\n1. **Compute Exponential Values**: For each score in the input list, compute the exponential value using `math.exp()`.\n2. **Sum of Exponentials**: Calculate the sum of all these exponential values. This sum is used as the denominator in the Softmax formula.\n3. **Softmax Calculation**: For each score, divide its exponential value by the sum of all exponential values to get the Softmax value.\n4. **Rounding**: Each Softmax value is rounded to four decimal places to ensure the output is formatted correctly.\n\nThis approach ensures that the output values are normalized and bounded between 0 and 1, which is the characteristic of the Softmax function. The use of the exponential function guarantees that all values are positive, and dividing by their sum ensures proper normalization."}
{"task_id": 24, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to simulate a single neuron with a sigmoid activation function for binary classification. The function will take feature vectors, true binary labels, and neuron parameters (weights and bias) as inputs and return predicted probabilities along with the mean squared error (MSE) between the predicted probabilities and the true labels.\n\n### Approach\n1. **Compute Weighted Sum**: For each feature vector, compute the weighted sum by multiplying each feature with its corresponding weight and summing these products.\n2. **Add Bias**: Add the bias to the weighted sum.\n3. **Apply Sigmoid Function**: Use the sigmoid function to convert the sum to a probability between 0 and 1.\n4. **Compute MSE**: Calculate the MSE between the predicted probabilities and the true labels. Convert the true labels to floats for the calculation.\n5. **Round Results**: Round both the predicted probabilities and the MSE to four decimal places.\n\n### Solution Code\n```python\nimport math\n\ndef single_neuron_model(features: list[list[float]], labels: list[int], weights: list[float], bias: float) -> (list[float], float):\n    predictions = []\n    for i in range(len(features)):\n        fv = features[i]\n        sum_weights = 0.0\n        for j in range(len(fv)):\n            sum_weights += fv[j] * weights[j]\n        sum_weights += bias\n        prediction = 1.0 / (1.0 + math.exp(-sum_weights))\n        predictions.append(prediction)\n    \n    mse = 0.0\n    for p, l in zip(predictions, labels):\n        mse += (p - float(l)) ** 2\n    mse /= len(labels)\n    \n    rounded_predictions = [round(p, 4) for p in predictions]\n    rounded_mse = round(mse, 4)\n    \n    return rounded_predictions, rounded_mse\n```\n\n### Explanation\n1. **Weighted Sum Calculation**: For each feature vector, the function computes the dot product with the weights, which gives the weighted sum of the features.\n2. **Bias Addition**: The bias is added to the weighted sum to shift the activation values.\n3. **Sigmoid Activation**: The sigmoid function is applied to the sum to produce a probability value between 0 and 1.\n4. **MSE Calculation**: The MSE is computed by averaging the squared differences between the predicted probabilities and the true labels.\n5. **Rounding**: Both the predicted probabilities and the MSE are rounded to four decimal places to meet the problem's requirements.\n\nThis approach ensures that the function efficiently computes the predictions and MSE while handling multidimensional input features."}
{"task_id": 25, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to simulate a single neuron with sigmoid activation and implement backpropagation to update the neuron's weights and bias using gradient descent based on the Mean Squared Error (MSE) loss. The function should take feature vectors, true binary labels, initial weights, initial bias, a learning rate, and the number of epochs as inputs, and return the updated weights, bias, and a list of MSE values for each epoch, each rounded to four decimal places.\n\n### Approach\n1. **Neuron Computation**: The neuron computes its output by multiplying each feature vector by its corresponding weight, summing these products, adding the bias, applying the sigmoid activation function, and producing a prediction.\n2. **Loss Calculation**: The MSE loss is calculated between the predicted output and the true labels.\n3. **Backpropagation**: The gradients of the loss with respect to the weights and bias are computed. The gradient for the weights is derived from the features and the gradient for the bias is directly the difference between the predicted and true outputs.\n4. **Weight and Bias Update**: The weights and bias are updated using gradient descent with the learning rate.\n5. **Epoch Loop**: The process is repeated for the specified number of epochs, updating the weights and bias each time and recording the MSE loss for each epoch.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef train_neuron(features: np.ndarray, labels: np.ndarray, initial_weights: np.ndarray, initial_bias: float, learning_rate: float, epochs: int) -> (np.ndarray, float, list[float]):\n    w = initial_weights.copy()\n    b = initial_bias\n    n_samples = features.shape[0]\n    \n    mse_list = []\n    \n    for epoch in range(epochs):\n        # Compute z = w^T X + b\n        z = np.dot(w, features) + b\n        # Compute activation a\n        a = np.sigmoid(z)\n        # Compute loss\n        loss = np.mean((a - labels)**2)\n        # Record loss rounded to four decimal places\n        mse_list.append(round(loss, 4))\n        \n        # Compute delta\n        delta = a - labels\n        # Compute gradients\n        dw = np.dot(delta, features)\n        db = delta\n        \n        # Compute average gradients across samples\n        dw_avg = np.mean(dw, axis=0)\n        db_avg = np.mean(db)\n        \n        # Update weights and bias\n        w -= learning_rate * dw_avg\n        b -= learning_rate * db_avg\n    \n    return w, b, mse_list\n```\n\n### Explanation\n1. **Initialization**: The function starts by copying the initial weights and bias to avoid modifying the original values. It also initializes an empty list to store the MSE losses for each epoch.\n2. **Epoch Loop**: For each epoch, the function computes the neuron's output `z` by multiplying the weights with the features and adding the bias. The activation function `sigmoid` is applied to get the predicted output `a`.\n3. **Loss Calculation**: The MSE loss is computed as the mean of the squared differences between the predicted output and the true labels.\n4. **Gradient Computation**: The gradient of the loss with respect to the weights (`dw`) is computed by multiplying the difference between the predicted and true outputs with the features. The gradient with respect to the bias (`db`) is simply the difference between the predicted and true outputs.\n5. **Weight and Bias Update**: The weights and bias are updated using gradient descent, with the learning rate scaling the gradients.\n6. **Result Compilation**: After completing all epochs, the function returns the updated weights, bias, and the list of MSE values, each rounded to four decimal places.\n\nThis approach ensures that the neuron's weights and bias are adjusted iteratively to minimize the MSE loss, leading to better model performance over time."}
{"task_id": 26, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a Python class that can handle basic autograd operations: addition, multiplication, and ReLU activation. This class should be able to compute gradients correctly using automatic differentiation.\n\n### Approach\nThe task involves creating a class that can perform basic operations and compute gradients. The class should be able to handle scalar values and correctly compute gradients through automatic differentiation. The operations to be implemented are addition, multiplication, and the ReLU activation function.\n\n1. **Class Structure**: The class will be similar to the provided `Value` class but will represent operations that can have children nodes. Each operation node will have a data attribute, a gradient attribute, and a method to compute the gradient backward.\n\n2. **Operations**:\n   - **Addition**: The gradient of the sum of two values is 1, so the gradient contribution is the same as the input gradient.\n   - **Multiplication**: The gradient of the product of two values is the sum of the gradients of the individual values.\n   - **ReLU Activation**: The gradient of ReLU is 1 if the input is less than zero and 0 otherwise.\n\n3. **Backward Pass**: The `_backward` method will return a function that computes the gradient contribution of the operation node to its parent. This function will be based on the type of operation and will use the gradients of the children nodes.\n\n### Solution Code\n```python\nclass Operation:\n    def __init__(self, data, children, op):\n        self.data = data\n        self.grad = 0\n        self._backward = None\n        self._prev = set(children)\n        self._op = op\n\n    def _backward(self):\n        if self._op == 'add':\n            self._backward = lambda grad: grad * 1\n        elif self._op == 'mul':\n            self._backward = lambda grad: grad * (self._prev[0].data if self._prev[0].data is not None else 0) + grad * (self._prev[1].data if self._prev[1].data is not None else 0)\n        elif self._op == 'relu':\n            self._backward = lambda grad: grad * (1 if self.data < 0 else 0)\n        else:\n            raise ValueError(\"Unknown operation\")\n```\n\n### Explanation\n- **Initialization**: The `__init__` method initializes the data, gradient, and sets up the children and operation type.\n- **Backward Method**: This method returns a lambda function that computes the gradient contribution based on the operation type:\n  - **Addition**: Returns the same gradient as the input.\n  - **Multiplication**: Computes the sum of the gradients of the children.\n  - **ReLU**: Returns 1 if the data is less than zero, otherwise 0, multiplied by the input gradient.\n\nThis approach ensures that each operation node correctly computes its gradient contribution to its parent node, enabling automatic differentiation for basic operations."}
{"task_id": 27, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the transformation matrix that converts vectors from one basis to another. This transformation matrix is essential for understanding how vectors in one basis (B) can be expressed in terms of another basis (C).\n\n### Approach\n1. **Problem Analysis**: Given two bases B and C in R^3, we need to find the transformation matrix P that converts vectors from B to C. This matrix P is such that when applied to a vector in B, it gives the coordinates of that vector in terms of the basis C.\n\n2. **Intuition**: The transformation matrix can be derived by understanding how each basis vector in B can be expressed in terms of the basis vectors in C. This involves solving a system of linear equations for each basis vector in B.\n\n3. **Matrix Construction**: \n   - Construct a matrix A using the vectors from basis B. Each column of A represents a vector in B.\n   - For each vector in basis C, solve the linear system A * x = c to find the coefficients that express the vector c in terms of the vectors in B. These coefficients form the columns of a new matrix M.\n   - The transformation matrix P is the inverse of matrix M, which transforms vectors from B to C.\n\n4. **Algorithm**:\n   - Convert the input bases B and C into numpy arrays.\n   - Construct matrix A from the vectors in B.\n   - For each vector in C, solve the linear system to find the transformation coefficients and construct matrix M.\n   - Compute the inverse of matrix M to get the transformation matrix P.\n   - Round the elements of P to four decimal places and return the result.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef transform_basis(B: list[list[int]], C: list[list[int]]) -> list[list[float]]:\n    # Convert the bases to numpy arrays of floats\n    B_np = np.array(B, dtype=np.float64)\n    C_np = np.array(C, dtype=np.float64)\n    \n    # Create matrix A from the B basis vectors\n    A = B_np\n    \n    # Initialize the transformation matrix M\n    M = np.zeros((3, 3))\n    \n    # Populate M with the transformation coefficients from B to C\n    for i in range(3):\n        c = C_np[i]\n        # Solve A * x = c to find the coefficients x\n        x = np.linalg.solve(A, c)\n        M[:, i] = x\n    \n    # Compute the transformation matrix P as the inverse of M\n    P = np.linalg.inv(M)\n    \n    # Round each element to 4 decimal places\n    P_rounded = [[round(element, 4) for element in row] for row in P]\n    \n    # Convert the numpy array to a list of lists\n    return P_rounded.tolist()\n```\n\n### Explanation\n- **Matrix A Construction**: Matrix A is constructed from the vectors in basis B. Each column of A corresponds to a vector in B.\n- **Matrix M Construction**: For each vector in basis C, we solve the linear system A * x = c to find the coefficients x. These coefficients form the columns of matrix M.\n- **Transformation Matrix P**: The inverse of matrix M gives the transformation matrix P, which transforms vectors from B to C.\n- **Rounding and Conversion**: The elements of P are rounded to four decimal places and converted into a list of lists for the final result.\n\nThis approach ensures that we accurately compute the transformation matrix between two bases in R^3, allowing for easy conversion of vectors between the two coordinate systems."}
{"task_id": 28, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the Singular Value Decomposition (SVD) of a 2x2 matrix using eigenvalues and eigenvectors. The SVD of a matrix A is represented as A = U * S * V, where U, S, and V are matrices such that U and V are orthogonal, and S is a diagonal matrix of singular values.\n\n### Approach\nThe approach to compute the SVD of a 2x2 matrix involves the following steps:\n\n1. **Compute A^T A**: This matrix is symmetric and positive semi-definite, making it suitable for eigenvalue decomposition.\n2. **Eigenvalue Decomposition**: Compute the eigenvalues and eigenvectors of A^T A. The eigenvalues will be used to determine the singular values, and the eigenvectors will be used to construct the matrix V.\n3. **Construct V**: Normalize the eigenvectors to form the matrix V.\n4. **Construct U**: For each eigenvector, compute A multiplied by the eigenvector, then normalize the result to form the matrix U.\n5. **Construct S**: The diagonal matrix S is formed using the square roots of the eigenvalues of A^T A, which are the singular values.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef svd_2x2(A: np.ndarray) -> tuple:\n    # Compute A^T A\n    AtA = A.T @ A\n    # Compute eigenvalues and eigenvectors\n    eigenvalues, eigenvectors = np.linalg.eig(AtA)\n    # Sort eigenvalues and eigenvectors in descending order\n    sorted_indices = np.argsort(eigenvalues)[::-1]\n    sorted_eigenvalues = eigenvalues[sorted_indices]\n    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n    # Compute singular values\n    singular_values = np.sqrt(sorted_eigenvalues)\n    # Normalize eigenvectors to get V\n    V = []\n    for v in sorted_eigenvectors:\n        norm = np.linalg.norm(v)\n        if norm == 0:\n            v = 0\n        else:\n            v = v / norm\n        V.append(v)\n    V = np.array(V)\n    # Compute U by normalizing A * v_i\n    U = []\n    for i in range(len(singular_values)):\n        av = A @ V[i]\n        norm = np.linalg.norm(av)\n        if norm == 0:\n            u = 0\n        else:\n            u = av / norm\n        U.append(u)\n    U = np.array(U)\n    # Reshape to 2x2 matrices and round to 4 decimals\n    U = U.reshape(2, 2)\n    S = np.diag(singular_values)\n    # Round and convert to lists\n    U = np.round(U, 4).tolist()\n    S = np.round(S, 4).tolist()\n    V = np.round(V, 4).tolist()\n    return (U, S, V)\n```\n\n### Explanation\n1. **Compute A^T A**: This step ensures that the matrix is symmetric and positive semi-definite, which is necessary for eigenvalue decomposition.\n2. **Eigenvalue Decomposition**: Using numpy's `np.linalg.eig` function, we compute the eigenvalues and eigenvectors of A^T A. The eigenvalues are sorted in descending order to ensure we get the largest singular values first.\n3. **Construct V**: The eigenvectors are normalized to form the columns of matrix V, ensuring each column is a unit vector.\n4. **Construct U**: For each normalized eigenvector, we compute the product with A, then normalize the result to form the columns of matrix U.\n5. **Construct S**: The diagonal matrix S is formed using the square roots of the eigenvalues, which are the singular values.\n\nThis approach efficiently computes the SVD of a 2x2 matrix using eigenvalues and eigenvectors, ensuring the resulting matrices U, S, and V are orthogonal and correctly decompose the original matrix A."}
{"task_id": 29, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a function that shuffles two numpy arrays, X and y, while maintaining their corresponding order. This means that each element in X should correspond to the same element in y after shuffling. Additionally, the function should include an optional seed parameter for reproducibility.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n\n1. **Check for Seed**: If a seed is provided, set it using `np.random.seed(seed)`. This ensures that the shuffling is reproducible.\n2. **Create Indices**: Generate an array of indices from 0 to the length of X minus one. This array helps in maintaining the order of elements while shuffling.\n3. **Generate Permutation**: Use `np.random.permutation` to create a shuffled order of the indices. This permutation ensures that the indices are in a random order, which will be applied to both X and y.\n4. **Apply Permutation**: Use the generated permutation to reorder both X and y. This ensures that the elements in X and y are shuffled together while maintaining their corresponding order.\n5. **Convert to Lists**: Convert the shuffled numpy arrays to lists using the `tolist()` method and return them as a list containing both lists.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef shuffle_data(X, y, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    indices = np.arange(len(X))\n    perm = np.random.permutation(indices)\n    X_shuffled = X[perm]\n    y_shuffled = y[perm]\n    return [X_shuffled.tolist(), y_shuffled.tolist()]\n```\n\n### Explanation\n- **Seed Check**: The function first checks if a seed is provided. If so, it sets the seed for reproducibility.\n- **Indices Creation**: It creates an array of indices from 0 to the length of X. This array represents the original positions of the elements in X.\n- **Permutation**: The function generates a permutation of these indices, which is a shuffled version of the original indices.\n- **Shuffling**: Using the permutation, the function reorders both X and y. This ensures that each element in X is paired with the corresponding element in y in the shuffled order.\n- **Conversion to Lists**: Finally, the shuffled numpy arrays are converted to lists and returned as a list containing both lists.\n\nThis approach ensures that the shuffling is random and reproducible, maintaining the correspondence between elements in X and y while returning the results in the required format."}
{"task_id": 30, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to create a batch iterator function that can sample data from a numpy array and an optional numpy array. The function should yield batches of a specified size, returning either pairs of (X, y) or just X depending on whether y is provided.\n\n### Approach\nThe approach involves the following steps:\n1. **Check for the presence of y**: If y is provided, each batch will be a tuple of (X_batch, y_batch). If not, each batch will only contain X.\n2. **Determine the number of batches**: Calculate the total number of batches by dividing the length of X by the batch size. This helps in iterating through the data in chunks.\n3. **Extract batches**: For each batch, extract the corresponding slice from X. If y is provided, extract the corresponding slice from y as well.\n4. **Convert to lists**: Use numpy's `tolist()` method to convert each batch into a list, as required by the problem constraints.\n\nThis approach ensures that we handle both cases where y is provided and where it is not, efficiently iterating through the data in chunks of the specified size.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef batch_iterator(X, y=None, batch_size=64):\n    n = len(X)\n    for i in range(0, n, batch_size):\n        X_batch = X[i:i+batch_size]\n        if y is not None:\n            y_batch = y[i:i+batch_size]\n            yield (X_batch.tolist(), y_batch.tolist())\n        else:\n            yield X_batch.tolist()\n```\n\n### Explanation\n- **Function Definition**: The function `batch_iterator` takes three parameters: X (a numpy array), y (an optional numpy array), and batch_size (an integer with a default value of 64).\n- **Loop through batches**: The loop starts from 0 and iterates in steps of `batch_size`, processing each chunk of data.\n- **Extracting Batches**: For each iteration, the current chunk of X is extracted. If y is provided, the corresponding chunk of y is also extracted.\n- **Conversion to Lists**: Each batch is converted into a list using `tolist()` to meet the problem's output requirements.\n\nThis solution efficiently handles the iteration over the data, ensuring that batches are processed correctly whether y is provided or not."}
{"task_id": 31, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a Python function that divides a dataset into two subsets based on a specified feature and a given threshold. The function will return two lists: one containing samples that meet the condition (feature value greater than or equal to the threshold) and another containing samples that do not.\n\n### Approach\n1. **Extract the Feature**: Extract the specified feature from the dataset using boolean indexing.\n2. **Create a Condition Mask**: Use numpy's `where` function to create a boolean mask where the feature value is greater than or equal to the given threshold.\n3. **Split the Dataset**: Use the boolean mask to split the dataset into two parts: one where the condition is met and another where it is not.\n4. **Convert to Lists**: Convert the resulting subsets into lists using the `tolist()` method for the required output format.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef divide_on_feature(X, feature_i, threshold):\n    # Extract the specified feature\n    feature = X[:, feature_i]\n    # Create a boolean mask where the feature is >= threshold\n    condition = np.where(feature >= threshold, True, False)\n    # Split the dataset into two parts\n    true_part = X[condition]\n    false_part = X[~condition]\n    # Convert to lists\n    true_list = true_part.tolist()\n    false_list = false_part.tolist()\n    return [true_list, false_list]\n```\n\n### Explanation\n- **Extract the Feature**: The feature is extracted using `X[:, feature_i]`, which selects the specified column from the dataset.\n- **Condition Mask**: The `np.where` function is used to create a boolean mask where each element is `True` if the corresponding feature value is greater than or equal to the threshold, otherwise `False`.\n- **Splitting the Dataset**: Using boolean indexing, the dataset is split into two parts: `true_part` where the condition is met and `false_part` where it is not.\n- **Conversion to Lists**: The `tolist()` method is applied to both subsets to convert them into lists, which is the required output format.\n\nThis approach efficiently divides the dataset based on the specified feature and threshold, ensuring that the output is in the desired format."}
{"task_id": 32, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to generate polynomial features for a given dataset. The function should take a 2D numpy array `X` and an integer `degree`, and return a new 2D numpy array with polynomial features up to the specified degree. Each polynomial feature is constructed by considering each column of the input array as a variable and computing all possible powers up to the given degree.\n\n### Approach\n1. **Understand the Problem**: The goal is to transform each column of the input array into a polynomial of the specified degree. For example, if the input array has columns `x1, x2, ..., xn` and the degree is 2, each column will be transformed into `[1, x, x\u00b2]`.\n\n2. **Iterate Over Columns**: For each column in the input array, compute the polynomial terms. This involves calculating the power of each element in the column from 0 up to the given degree.\n\n3. **Stack Results**: After computing the polynomial terms for each column, stack these results into a 2D array. Each row in this resulting array corresponds to a sample from the input array, and each column corresponds to a term in the polynomial for each feature.\n\n4. **Return as List**: Convert the resulting 2D numpy array into a list of lists for the final output.\n\n### Solution Code\n```python\nimport numpy as np\nfrom itertools import combinations_with_replacement\n\ndef polynomial_features(X, degree):\n    if degree < 0:\n        raise ValueError(\"Degree must be non-negative\")\n    n_cols = X.shape[1]\n    polynomials = []\n    for col in X:\n        powers = [col**i for i in range(degree + 1)]\n        polynomials.append(powers)\n    result = np.vstack(polynomials)\n    return result.tolist()\n```\n\n### Explanation\n1. **Input Handling**: The function starts by checking if the degree is non-negative and then determines the number of columns in the input array `X`.\n\n2. **Polynomial Term Calculation**: For each column, it computes each power from 0 up to the specified degree. This is done using a list comprehension that iterates over each element in the column and raises it to the respective power.\n\n3. **Stacking Results**: The computed polynomial terms for each column are collected into a list, which is then stacked into a single 2D array using `np.vstack`.\n\n4. **Conversion to List**: The resulting 2D numpy array is converted into a list of lists using the `tolist()` method to meet the problem's output requirements.\n\nThis approach efficiently transforms each feature into a polynomial of the specified degree and handles all edge cases, such as when the degree is zero, by ensuring each column is represented by a constant term."}
{"task_id": 34, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to perform one-hot encoding on a given numpy array of integer values. One-hot encoding is a technique used to convert categorical variables into a binary matrix where each unique value is represented by a unique combination of bits. Each row in the matrix corresponds to an original value, and each column represents a unique category.\n\n### Approach\n1. **Determine the Number of Columns**: If the number of columns (`n_col`) is not provided, it is automatically determined by the number of unique values in the input array. If `n_col` is provided, it is used as is.\n2. **Initialize the Result Array**: Create a numpy array initialized with zeros, where each row will represent an element from the input array and each column will correspond to a possible value.\n3. **Populate the Result Array**: For each element in the input array, set the corresponding column in the result array to 1. This ensures that each unique value is represented by a unique binary vector.\n4. **Return the Result**: Convert the result array into a list of lists and return it.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef to_categorical(x, n_col=None):\n    if n_col is None:\n        n_col = np.unique(x).size\n    result = np.zeros((len(x), n_col), dtype=np.int64)\n    for i in range(len(x)):\n        result[i, x[i]] = 1\n    return result.tolist()\n```\n\n### Explanation\n- **Determine `n_col`**: If `n_col` is not provided, it is calculated as the number of unique values in the input array using `np.unique(x).size`.\n- **Initialize Result Array**: The result array is created with dimensions `(len(x), n_col)` and initialized to zeros.\n- **Populate Result Array**: For each element in the input array `x`, the corresponding column in the result array is set to 1. This is done using a loop that iterates over each element and sets the appropriate position in the result array.\n- **Return Result**: The result array is converted to a list of lists using `tolist()` and returned.\n\nThis approach ensures that each unique value in the input array is converted into a unique binary vector, allowing for efficient and clear representation of categorical data in a binary format."}
{"task_id": 35, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to convert a 1D numpy array into a diagonal matrix. A diagonal matrix is a square matrix where all the non-diagonal elements are zero, and the diagonal elements are taken from the input 1D array.\n\n### Approach\n1. **Determine the Size of the Matrix**: The length of the input 1D array will determine the size of the resulting square matrix. If the input array has `n` elements, the resulting matrix will be an `n x n` matrix.\n2. **Create the Diagonal Matrix**: Using numpy's `np.diag` function, we can create a diagonal matrix where the diagonal elements are taken from the input 1D array. This function directly constructs the diagonal matrix from the 1D array.\n3. **Convert to List of Lists**: The resulting matrix from the `np.diag` function is a numpy array. We need to convert this numpy array into a list of lists for the final output.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef make_diagonal(x):\n    return np.diag(x).tolist()\n```\n\n### Explanation\n- **Step 1**: The function `make_diagonal` takes a 1D numpy array `x` as input.\n- **Step 2**: The `np.diag(x)` function is used to create a diagonal matrix from the input array `x`. This function constructs a square matrix where the diagonal elements are the elements of `x` and all other elements are zero.\n- **Step 3**: The resulting matrix from `np.diag(x)` is converted to a list of lists using the `tolist()` method, which is then returned as the final output.\n\nThis approach efficiently converts the input 1D array into a diagonal matrix and ensures the result is in the required format."}
{"task_id": 36, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the accuracy score of a model's predictions. The accuracy score is a measure of how well the model's predictions match the true labels. The function should take two 1D numpy arrays, `y_true` (true labels) and `y_pred` (predicted labels), and return the accuracy score as a float, rounded to the nearest fourth decimal.\n\n### Approach\n1. **Convert Data Types**: Ensure both `y_true` and `y_pred` are converted to integers if they are not already. This is necessary because accuracy is typically calculated for classification tasks where labels are integers.\n2. **Element-wise Comparison**: Use numpy's `equal` function to create a boolean mask where each element in `y_pred` matches the corresponding element in `y_true`.\n3. **Count Correct Predictions**: Sum the boolean mask to get the count of correct predictions.\n4. **Calculate Accuracy**: Divide the count of correct predictions by the total number of samples to get the accuracy score.\n5. **Round the Result**: Round the accuracy score to four decimal places before returning it.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef accuracy_score(y_true, y_pred):\n    # Convert to integers if necessary\n    y_true = np.asarray(y_true, dtype=np.int64)\n    y_pred = np.asarray(y_pred, dtype=np.int64)\n    # Find correct predictions\n    mask = np.equal(y_pred, y_true)\n    # Count the number of correct predictions\n    count = np.sum(mask)\n    # Calculate accuracy\n    accuracy = count / len(y_true)\n    # Round to four decimal places\n    return round(accuracy, 4)\n```\n\n### Explanation\n- **Conversion to Integers**: The function converts `y_true` and `y_pred` to integers to handle any potential type issues and ensure accurate comparison.\n- **Boolean Mask**: The `np.equal` function is used to create a boolean array where each entry is `True` if the corresponding elements in `y_pred` and `y_true` are equal, and `False` otherwise.\n- **Summing the Mask**: The sum of the boolean mask gives the count of correct predictions.\n- **Accuracy Calculation**: The count of correct predictions is divided by the total number of samples to compute the accuracy.\n- **Rounding**: The result is rounded to four decimal places to meet the problem's requirements.\n\nThis approach ensures that the function efficiently and accurately computes the accuracy score for the model's predictions."}
{"task_id": 37, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the correlation matrix for a given dataset. The correlation matrix measures how different variables in the dataset change together, indicating the strength and direction of their relationships. The function should handle both cases where the correlation matrix is computed for the same dataset (when Y is not provided) and when a different dataset is provided (Y is given).\n\n### Approach\n1. **Check for Y**: If Y is not provided, set Y to be the same as X. This allows the function to compute the correlation matrix for X with itself.\n2. **Compute Correlation Matrix**: Use NumPy's `corrcoef` function to compute the correlation matrix. This function handles both cases where Y is provided or not, and it returns a 2D array where each element represents the correlation between a pair of variables.\n3. **Round Values**: Round each element of the correlation matrix to four decimal places to meet the problem's precision requirement.\n4. **Convert to List**: Convert the resulting 2D array into a list of lists using NumPy's `tolist()` method to return the result in the required format.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef calculate_correlation_matrix(X, Y=None):\n    if Y is None:\n        Y = X\n    corr_matrix = np.corrcoef(X, Y)\n    rounded_corr = np.round(corr_matrix, 4)\n    return rounded_corr.tolist()\n```\n\n### Explanation\n- **Check for Y**: The function first checks if Y is provided. If not, it sets Y to be the same as X, ensuring that the correlation matrix is computed for X with itself.\n- **Compute Correlation Matrix**: The `corrcoef` function from NumPy is used to compute the correlation matrix. This function efficiently handles the computation and returns a 2D array where each element (i, j) represents the correlation between the i-th and j-th variables.\n- **Round Values**: Each element of the correlation matrix is rounded to four decimal places to ensure the required precision.\n- **Convert to List**: The resulting 2D array is converted into a list of lists using `tolist()`, which is the required output format.\n\nThis approach ensures that the function is efficient, handles edge cases, and returns the result in the specified format."}
{"task_id": 38, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the AdaBoost fit method, which is an ensemble method used to boost the performance of a weak classifier. The goal is to create a list of classifiers, each based on the best feature found in each iteration, and update the sample weights accordingly.\n\n### Approach\n1. **Initialization**: Start by initializing the sample weights to be equal for all samples.\n2. **Iteration**: For each iteration up to the specified number of classifiers:\n   - **Feature Evaluation**: For each feature, compute the optimal threshold that minimizes the error rate. This is done by evaluating a grid of possible thresholds and selecting the one that gives the minimum error.\n   - **Best Feature Selection**: Among all features, select the one with the smallest error rate.\n   - **Classifier Creation**: Create a classifier using the best feature and its optimal threshold.\n   - **Error Calculation**: Calculate the overall error rate of the current classifier.\n   - **Weight Update**: Update the sample weights based on the error rate. If a sample is misclassified, its weight is updated by multiplying it with an exponential term based on the error rate. The weights are then normalized to ensure they sum to 1.\n3. **Result**: Return the list of classifiers, each represented by their feature index and optimal threshold, rounded to the nearest 4th decimal.\n\n### Solution Code\n```python\nimport numpy as np\nimport math\n\ndef adaboost_fit(X, y, n_clf):\n    n_samples, n_features = X.shape\n    if n_samples == 0:\n        return []\n    \n    # Initialize weights\n    weights = np.ones(n_samples) / n_samples\n    classifiers = []\n    \n    for _ in range(n_clf):\n        min_error = float('inf')\n        best_feature = 0\n        best_t = 0.0\n        \n        # For each feature, find the best threshold\n        for j in range(n_features):\n            X_j = X[:, j]\n            y_j = y\n            \n            # Create a grid of possible t values\n            t_values = np.linspace(0, 1, 100)\n            current_min_error = float('inf')\n            best_t_j = None\n            \n            for t in t_values:\n                error = 0\n                for i in range(n_samples):\n                    if (X_j[i] >= t and y_j[i] == 1) or (X_j[i] < t and y_j[i] == 0):\n                        error += 1\n                if error < current_min_error:\n                    current_min_error = error\n                    best_t_j = t\n            \n            if current_min_error < min_error:\n                min_error = current_min_error\n                best_feature = j\n                best_t = best_t_j\n        \n        # Round the threshold to 4 decimal places\n        best_t = round(best_t, 4)\n        classifier = (best_feature, best_t)\n        classifiers.append(classifier)\n        \n        # Calculate the overall error\n        overall_error = min_error / n_samples\n        \n        # Update weights\n        exp_term = math.exp(-overall_error)\n        for i in range(n_samples):\n            if (X[:, best_feature][i] >= best_t and y[i] == 1) or (X[:, best_feature][i] < best_t and y[i] == 0):\n                weights[i] *= exp_term\n        \n        # Normalize the weights\n        weights = weights / weights.sum()\n    \n    return classifiers\n```\n\n### Explanation\n- **Initialization**: The weights for each sample are initialized to be equal, ensuring that each sample has an equal influence initially.\n- **Feature Evaluation**: For each feature, a grid of possible thresholds is evaluated to find the one that minimizes the error. This is done using a linear spacing of 100 points between 0 and 1.\n- **Best Feature Selection**: The feature with the smallest error rate is selected, and its optimal threshold is used to create a classifier.\n- **Weight Update**: After creating each classifier, the sample weights are updated based on the error rate. Weights of misclassified samples are adjusted by an exponential term, and the weights are normalized to ensure they sum to 1.\n- **Result**: The function returns a list of classifiers, each represented by their feature index and optimal threshold, rounded to four decimal places for precision."}
{"task_id": 39, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the log-softmax function for a given 1D numpy array of scores. The log-softmax function is the logarithm of the softmax function, which is useful for numerical stability when dealing with large numbers.\n\n### Approach\nThe approach to compute the log-softmax function involves the following steps:\n\n1. **Compute Exponential Scores**: Convert each score in the input array using the exponential function. This helps in converting the scores into probabilities.\n2. **Sum of Exponential Scores**: Calculate the sum of these exponential scores. This sum is used to normalize the probabilities.\n3. **Logarithm of the Sum**: Compute the natural logarithm of the sum obtained in the previous step. This step is crucial for the log-softmax function.\n4. **Element-wise Subtraction**: Subtract the logarithm of the sum from each score. This gives the log-softmax values for each element in the input array.\n5. **Reshape and Round**: Convert the resulting numpy array into a list of floats and round each element to the nearest 4th decimal place for the final output.\n\n### Solution Code\n```python\nimport numpy as np\nimport math\n\ndef log_softmax(scores: list):\n    scores = np.array(scores)\n    exp_scores = np.exp(scores)\n    sum_exp = np.sum(exp_scores)\n    log_sum = math.log(sum_exp)\n    log_softmax = scores - log_sum\n    result = log_softmax.tolist()\n    rounded_result = [round(x, 4) for x in result]\n    return rounded_result\n```\n\n### Explanation\n1. **Exponential Scores**: The function starts by converting each score into its exponential form using `np.exp(scores)`. This step ensures that each score is converted into a probability value.\n2. **Sum of Exponential Scores**: The sum of these exponential values is computed using `np.sum(exp_scores)`. This sum is used to normalize the probabilities.\n3. **Logarithm of the Sum**: The natural logarithm of the sum is computed using `math.log(sum_exp)`. This step is necessary to avoid numerical instability issues that can arise from directly computing the logarithm of a large sum.\n4. **Element-wise Subtraction**: Each score is then adjusted by subtracting the logarithm of the sum. This adjustment converts the scores into log-softmax values, which are the logarithms of the probabilities.\n5. **Reshape and Round**: The resulting numpy array of log-softmax values is converted into a list using `tolist()`. Each element of this list is then rounded to four decimal places to meet the specified precision requirement.\n\nThis approach ensures that the log-softmax function is computed efficiently and accurately, handling large numbers and avoiding numerical instability issues."}
{"task_id": 40, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a custom Dense layer for a neural network in Python. The Dense layer is a fully connected layer where each neuron in the input layer is connected to every neuron in the output layer. This layer will be extended from a base `Layer` class and will include methods for initialization, forward pass, backward pass, parameter count, and output shape.\n\n### Approach\n1. **Initialization**: The Dense layer is initialized with a specified number of neurons (`n_units`) and an optional input shape. The weights (`W`) are initialized using a uniform distribution with a limit of \\(1 / \\sqrt{\\text{input_shape}[0]}\\), and the biases (`w0`) are initialized to zero. Optimizers for both weights and biases are set up using a simple SGD (Stochastic Gradient Descent) optimizer with a default learning rate.\n\n2. **Forward Pass**: The forward pass computes the output of the layer by performing a dot product between the input `X` and the weight matrix `W`, then adding the bias `w0`.\n\n3. **Backward Pass**: The backward pass calculates the gradient of the loss with respect to the input. It uses the gradient from the next layer to compute the gradients for the weights (`W`) and biases (`w0`), then updates these parameters using the optimizer.\n\n4. **Parameter Count**: The total number of trainable parameters in the layer is the sum of the parameters in `W` and `w0`.\n\n5. **Output Shape**: The output shape of the layer is a tuple representing the number of neurons in the output layer.\n\n### Solution Code\n```python\nimport numpy as np\nimport copy\nimport math\n\nclass Layer(object):\n    def set_input_shape(self, shape):\n        self.input_shape = shape\n\n    def layer_name(self):\n        return self.__class__.__name__\n\n    def parameters(self):\n        return 0\n\n    def forward_pass(self, X, training):\n        raise NotImplementedError()\n\n    def backward_pass(self, accum_grad):\n        raise NotImplementedError()\n\n    def output_shape(self):\n        raise NotImplementedError()\n\nclass Dense(Layer):\n    def __init__(self, n_units, input_shape=None):\n        super().__init__()\n        self.set_input_shape(input_shape)\n        self.n_units = n_units\n        self.trainable = True\n        self.W = None\n        self.w0 = None\n        self.optimizer_W = self._create_optimizer(0.01)\n        self.optimizer_w0 = self._create_optimizer(0.01)\n\n    def _create_optimizer(self, lr=0.01):\n        def optimizer(param, grad):\n            param -= lr * grad\n            return param\n        return optimizer\n\n    def initialize(self):\n        if self.input_shape is None:\n            raise ValueError(\"Input shape must be provided.\")\n        n_input = self.input_shape[0]\n        # Initialize weights\n        self.W = np.random.uniform(-1.0 / np.sqrt(n_input), 1.0 / np.sqrt(n_input), (n_input, self.n_units))\n        # Initialize biases\n        self.w0 = np.zeros(self.n_units)\n\n    def parameters(self):\n        if self.input_shape is None:\n            raise ValueError(\"Input shape must be provided.\")\n        n_input = self.input_shape[0]\n        n_units = self.n_units\n        return n_input * n_units + n_units\n\n    def forward_pass(self, X, training):\n        if not self.trainable:\n            return X\n        output = X.dot(self.W) + self.w0\n        return output\n\n    def backward_pass(self, accum_grad):\n        if not self.trainable:\n            return None\n        # accum_grad is dL/dY\n        dW = accum_grad.dot(self.W.T)\n        dw0 = np.mean(accum_grad, axis=0)\n        # Update weights and biases\n        self.W = self.optimizer_W(self.W, dW)\n        self.w0 = self.optimizer_w0(self.w0, dw0)\n        return accum_grad\n\n    def output_shape(self):\n        return (self.n_units,)\n```\n\n### Explanation\n- **Initialization**: The `__init__` method sets up the layer with the specified number of neurons and input shape. It initializes the weights and biases and sets up optimizers for them.\n- **Forward Pass**: The `forward_pass` method computes the output of the layer by performing a dot product between the input and weights, then adds the biases.\n- **Backward Pass**: The `backward_pass` method computes the gradients of the loss with respect to the weights and biases using the gradient from the next layer. It updates the weights and biases using the optimizers.\n- **Parameter Count**: The `parameters` method calculates the total number of trainable parameters in the layer, which includes both the weights and biases.\n- **Output Shape**: The `output_shape` method returns the shape of the output produced by the forward pass, which is a tuple representing the number of neurons in the output layer.\n\nThis implementation ensures that the Dense layer functions correctly within a neural network framework, handling both the forward and backward passes efficiently."}
{"task_id": 41, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a 2D convolutional layer in Python. This function will process an input matrix using a specified convolutional kernel, padding, and stride. The goal is to compute the convolution of the input matrix with the kernel, apply the padding, and then downsample the result by the given stride.\n\n### Approach\n1. **Padding the Input Matrix**: The input matrix is padded with zeros on all sides to ensure the kernel can be fully applied without going out of bounds. This is done using the `np.pad` function.\n2. **Convolution Calculation**: Using NumPy's `np.convolve2d` function, we compute the convolution of the padded input matrix with the given kernel. This function handles the sliding window application of the kernel over the input matrix.\n3. **Downsampling by Stride**: After computing the convolution, the result is downsampled by the specified stride. This is achieved by taking every `stride`-th element from the convolution result in both row and column directions.\n4. **Reshaping and Rounding**: The resulting matrix from the downsampling step is reshaped into a list and each element is rounded to four decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef simple_conv2d(input_matrix: np.ndarray, kernel: np.ndarray, padding: int, stride: int):\n    # Pad the input matrix with zeros on all sides\n    padded_input = np.pad(input_matrix, ((0, 0), (0, 0)), mode='constant', constant_values=0)\n    \n    # Compute the convolution of the padded input with the kernel\n    kernel_rows = kernel.shape[0]\n    kernel_cols = kernel.shape[1]\n    conv_result = np.convolve2d(padded_input, kernel, mode='full')\n    \n    # Downsample the convolution result by the given stride\n    output_rows = conv_result.shape[0] // stride\n    output_cols = conv_result.shape[1] // stride\n    output = conv_result[::stride, ::stride]\n    \n    # Reshape the output to a list and round to four decimal places\n    output_list = output.tolist()\n    rounded_output = np.round(output_list * 10000) / 10000\n    return rounded_output\n```\n\n### Explanation\n1. **Padding**: The input matrix is padded with zeros to ensure the kernel can be applied without issues. This is crucial for maintaining the integrity of the convolution operation.\n2. **Convolution**: The `np.convolve2d` function is used to perform the 2D convolution. This function slides the kernel over the input matrix, multiplying corresponding elements and summing the results.\n3. **Downsampling**: The convolution result is downsampled by the specified stride. This step reduces the size of the resulting matrix, simulating the effect of pooling in convolutional neural networks.\n4. **Reshaping and Rounding**: The final result is converted into a list of numbers, each rounded to four decimal places to meet the problem's requirements.\n\nThis approach ensures that the convolutional layer correctly processes the input matrix, applies the kernel, handles padding, and downsamples the result as specified."}
{"task_id": 42, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Rectified Linear Unit (ReLU) activation function. The ReLU function is a common activation function used in neural networks. It takes a single float as input and returns the value after applying the ReLU function. The function returns the input value if it is greater than 0; otherwise, it returns 0.\n\n### Approach\nThe ReLU activation function is defined as follows:\n- If the input value \\( z \\) is greater than 0, the function returns \\( z \\).\n- If the input value \\( z \\) is less than or equal to 0, the function returns 0.\n\nThis approach is straightforward and involves a simple conditional check to determine the output value based on the input. The function handles all possible float inputs, including negative values and zero.\n\n### Solution Code\n```python\ndef relu(z: float) -> float:\n    if z > 0:\n        return z\n    else:\n        return 0\n```\n\n### Explanation\nThe function `relu` takes a single float `z` as input. It checks if `z` is greater than 0. If true, it returns `z` as the output. If false (i.e., `z` is less than or equal to 0), it returns 0. This implementation efficiently handles all cases with a simple conditional statement, ensuring that the output is always non-negative as required by the ReLU activation function."}
{"task_id": 43, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that computes the Ridge regression loss. Ridge regression is a technique used to build a regression model that includes a penalty term, encouraging the coefficients to be less extreme. This helps in preventing overfitting and improves generalization.\n\n### Approach\nThe Ridge regression loss function combines the Mean Squared Error (MSE) and a regularization term. The MSE measures the error between the predicted values and the true values, while the regularization term encourages the coefficients to be less extreme by adding a penalty proportional to the magnitude of the coefficients.\n\nThe steps to compute the Ridge loss are as follows:\n1. **Compute Predictions**: Use the feature matrix `X` and the coefficient vector `w` to compute the predicted values `y_pred`.\n2. **Compute MSE**: Calculate the mean of the squared differences between the predicted values and the true values.\n3. **Compute Regularization Term**: Add a penalty term proportional to the sum of the squares of the coefficients, scaled by the regularization parameter `alpha`.\n4. **Combine MSE and Regularization**: Sum the MSE and the regularization term to get the total Ridge loss.\n5. **Round the Result**: Return the total loss rounded to four decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef ridge_loss(X: np.ndarray, w: np.ndarray, y_true: np.ndarray, alpha: float) -> float:\n    y_pred = X.dot(w)\n    squared_errors = (y_true - y_pred) ** 2\n    mse = np.mean(squared_errors)\n    regularization = (alpha / 2) * np.sum(w ** 2)\n    total_loss = mse + regularization\n    return round(total_loss, 4)\n```\n\n### Explanation\n1. **Compute Predictions**: The predicted values `y_pred` are obtained by taking the dot product of the feature matrix `X` and the coefficient vector `w`.\n2. **Compute MSE**: The MSE is calculated by taking the mean of the squared differences between each predicted value and the corresponding true value.\n3. **Compute Regularization Term**: The regularization term is computed as half the sum of the squares of the coefficients, scaled by the regularization parameter `alpha`.\n4. **Combine MSE and Regularization**: The total loss is the sum of the MSE and the regularization term.\n5. **Round the Result**: The total loss is rounded to four decimal places to meet the problem's requirements.\n\nThis approach ensures that the model is both accurate and regularized, leading to better generalization performance."}
{"task_id": 44, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Leaky Rectified Linear Unit (Leaky ReLU) activation function. This function is a variation of the ReLU activation function, which introduces a small negative slope for negative inputs, allowing a \"leak\" of information through the network.\n\n### Approach\nThe Leaky ReLU function is defined as follows:\n- For non-negative inputs (z >= 0), the function returns the input value z, similar to the standard ReLU function.\n- For negative inputs (z < 0), the function returns a value that is scaled by a small slope, given by the parameter alpha. Specifically, for negative z, the function returns -alpha * z. This ensures that the output is a small positive value, allowing a leak through the network for negative inputs.\n\n### Solution Code\n```python\ndef leaky_relu(z: float, alpha: float = 0.01) -> float | int:\n    if z >= 0:\n        return z\n    else:\n        return -alpha * z\n```\n\n### Explanation\n- The function `leaky_relu` takes two parameters: a float `z` and an optional float `alpha` with a default value of 0.01.\n- If `z` is non-negative (z >= 0), the function returns `z` as is.\n- If `z` is negative (z < 0), the function returns `-alpha * z`, which ensures a small positive value, allowing a leak for negative inputs.\n- This implementation efficiently handles both positive and negative inputs, providing the desired behavior of the Leaky ReLU activation function."}
{"task_id": 45, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the linear kernel between two input vectors using their dot product. The dot product is a fundamental operation in linear algebra and is commonly used in machine learning to compute kernels, which measure the similarity between vectors.\n\n### Approach\nThe linear kernel between two vectors is defined as their dot product. The dot product of two vectors is computed by multiplying their corresponding elements and then summing up all the products. This approach is efficient and leverages the numpy library's `dot` function to perform the necessary computations.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef kernel_function(x1, x2):\n    return np.dot(x1, x2)\n```\n\n### Explanation\n1. **Import Numpy**: The numpy library is imported to utilize the `dot` function for efficient computation of the dot product.\n2. **Define Kernel Function**: The function `kernel_function` takes two arguments, `x1` and `x2`, which are the input vectors.\n3. **Compute Dot Product**: Using `np.dot(x1, x2)`, the function computes the dot product of the two vectors.\n4. **Return Result**: The result of the dot product is returned as the linear kernel between the two vectors.\n\nThis approach ensures that the computation is both efficient and straightforward, leveraging numpy's optimized functions for numerical operations."}
{"task_id": 46, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the precision metric for binary classification given two numpy arrays, `y_true` and `y_pred`. Precision is defined as the ratio of true positives to the sum of true positives and false positives.\n\n### Approach\n1. **Understand Precision**: Precision is a measure of how accurate the predictions are. It is calculated as the number of true positives divided by the total number of positive predictions (true positives + false positives).\n2. **Calculate True Positives (TP)**: These are the cases where both `y_true` and `y_pred` are 1.\n3. **Calculate False Positives (FP)**: These are the cases where `y_pred` is 1 but `y_true` is 0.\n4. **Compute Precision**: The precision is the ratio of true positives to the sum of true positives and false positives. If there are no positive predictions, the precision is 0 to avoid division by zero.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef precision(y_true, y_pred):\n    # Calculate the number of true positives\n    tp = np.sum(y_true * y_pred)\n    # Calculate the number of false positives\n    fp = np.sum((1 - y_true) * y_pred)\n    total = tp + fp\n    if total == 0:\n        return 0.0\n    else:\n        return tp / total\n```\n\n### Explanation\n1. **True Positives (TP)**: We compute the sum of `y_true` and `y_pred` element-wise. This gives the count of true positives.\n2. **False Positives (FP)**: We compute the sum of `(1 - y_true)` and `y_pred` element-wise. This gives the count of false positives.\n3. **Total Positive Predictions**: This is the sum of true positives and false positives.\n4. **Precision Calculation**: If there are no positive predictions, return 0. Otherwise, return the ratio of true positives to the total positive predictions.\n\nThis approach efficiently computes the precision using vectorized operations, ensuring that the solution is both concise and performant."}
{"task_id": 47, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that performs three variants of gradient descent using the Mean Squared Error (MSE) loss function. The function should be able to handle Stochastic Gradient Descent (SGD), Batch Gradient Descent, and Mini-Batch Gradient Descent. The function will take an additional parameter to specify which variant to use.\n\n### Approach\nThe function `gradient_descent` is designed to handle three different gradient descent variants: SGD, Batch, and Mini-Batch. Each variant has its own way of updating the model weights based on the gradient of the loss function. The loss function used is MSE, which measures the average squared difference between the predicted values and the actual values.\n\n1. **Stochastic Gradient Descent (SGD)**: For each iteration, a single sample is used to update the weights. This makes the algorithm sensitive to the order of samples, leading to different possible outcomes each time the function is run.\n\n2. **Batch Gradient Descent**: The entire dataset is used in one go to update the weights. This averages the gradients across all samples, making the algorithm less sensitive to individual sample order.\n\n3. **Mini-Batch Gradient Descent**: A subset of the data (mini-batch) is used to update the weights in each iteration. This balances computational efficiency and model performance by processing a smaller portion of the data at each step.\n\nThe function computes the gradient of the MSE loss for the entire dataset and then scales or selects a subset of this gradient based on the specified method. The weights are updated iteratively for the given number of iterations.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef gradient_descent(X, y, weights, learning_rate, n_iterations, batch_size=1, method='batch'):\n    N = X.shape[0]\n    for _ in range(n_iterations):\n        y_pred = np.dot(X, weights)\n        error = y_pred - y\n        full_gradient = (np.dot(X.T, error)) / N\n        if method == 'sgd':\n            i = np.random.randint(N)\n            sample_gradient = full_gradient[i, :]\n            weights -= learning_rate * sample_gradient\n        elif method == 'batch':\n            weights -= learning_rate * full_gradient\n        elif method == 'mini-batch':\n            scaled_gradient = full_gradient * (batch_size / N)\n            weights -= learning_rate * scaled_gradient\n    return np.round(weights.tolist(), 4)\n```\n\n### Explanation\n1. **Initialization**: The function starts by determining the number of samples, `N`, from the input matrix `X`.\n\n2. **Iteration Loop**: The function iterates `n_iterations` times, updating the model weights in each iteration.\n\n3. **Prediction and Error Calculation**: For each iteration, the model's predictions are computed, and the error between the predictions and the actual values is calculated.\n\n4. **Gradient Computation**: The gradient of the MSE loss with respect to the weights is computed. This gradient is the average of the squared errors across all samples.\n\n5. **Weight Update**: Depending on the specified method:\n   - **SGD**: A random sample is selected, and the weights are updated using the gradient of that sample.\n   - **Batch**: The weights are updated using the average gradient across all samples.\n   - **Mini-Batch**: The weights are updated using the average gradient of a subset of the data, scaled appropriately.\n\n6. **Return Result**: After all iterations, the final weights are rounded to four decimal places and returned as a list.\n\nThis approach ensures that the function efficiently and correctly implements the specified gradient descent variant, providing accurate model updates based on the chosen method."}
{"task_id": 48, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to convert a given matrix into its Reduced Row Echelon Form (RREF). The RREF of a matrix is a special form where each leading entry in a row is 1, and all other entries in the column containing the leading 1 are zeros, except for the leading 1 itself. \n\n### Approach\nThe approach to convert a matrix into its RREF involves two main steps: forward elimination and backward elimination.\n\n1. **Forward Elimination**: This step converts the matrix into row-echelon form. For each row, we find the pivot (the first non-zero element in the current row), then eliminate all entries below this pivot in its column. After this, the pivot is set to 1.\n\n2. **Backward Elimination**: This step converts the matrix from row-echelon form to reduced row-echelon form. For each row, starting from the last row and moving upwards, we eliminate all entries above the pivot in its column. After this, the pivot is set to 1.\n\nBy following these steps, we ensure that each leading entry in the matrix is 1, and all other entries in its column are zero, thus achieving the RREF.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef rref(matrix):\n    if isinstance(matrix, list):\n        matrix = np.array(matrix)\n    matrix = matrix.copy()\n    n_rows = matrix.shape[0]\n    if n_rows == 0:\n        return []\n    n_cols = matrix.shape[1]\n    \n    # Forward elimination to get row-echelon form\n    for row in range(n_rows):\n        pivot_col = None\n        for col in range(n_cols):\n            if abs(matrix[row, col]) > 1e-10:  # Avoid division by zero\n                pivot_col = col\n                break\n        if pivot_col is None:\n            continue\n        \n        max_row = row\n        max_val = abs(matrix[row, pivot_col])\n        for r in range(row + 1, n_rows):\n            if abs(matrix[r, pivot_col]) > max_val:\n                max_val = abs(matrix[r, pivot_col])\n                max_row = r\n        \n        if max_row != row:\n            matrix[row], matrix[max_row] = matrix[max_row], matrix[row]\n        \n        for r in range(row + 1, n_rows):\n            factor = matrix[r, pivot_col] / matrix[row, pivot_col]\n            matrix[r] = matrix[r] - factor * matrix[row]\n        \n        matrix[row, pivot_col] = 1\n    \n    # Backward elimination to get reduced row-echelon form\n    for row in reversed(range(n_rows)):\n        pivot_col = None\n        for col in range(n_cols):\n            if abs(matrix[row, col]) > 1e-10:\n                pivot_col = col\n                break\n        if pivot_col is None:\n            continue\n        \n        for r in range(row - 1, -1, -1):\n            factor = matrix[r, pivot_col] / matrix[row, pivot_col]\n            matrix[r] = matrix[r] - factor * matrix[row]\n        \n        matrix[row, pivot_col] = 1\n    \n    return matrix.tolist()\n```\n\n### Explanation\n1. **Forward Elimination**: For each row, we find the pivot column. If no pivot is found, we move to the next row. If a pivot is found, we find the row with the maximum absolute value in the pivot column (to avoid division by zero) and swap rows if necessary. We then eliminate all entries below the pivot in its column and set the pivot to 1.\n\n2. **Backward Elimination**: Starting from the last row, we find the pivot column for each row. If a pivot is found, we eliminate all entries above the pivot in its column and set the pivot to 1.\n\nThis two-step process ensures that the matrix is converted into its RREF, where each leading entry is 1, and all other entries in its column are zero. This form is essential for solving systems of linear equations and is widely used in numerical methods."}
{"task_id": 49, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Adam optimization algorithm, which is an efficient method for training deep neural networks by adapting the learning rate for each parameter. The Adam algorithm maintains two moving averages of the gradients, allowing it to adjust learning rates automatically without the need for manually setting them.\n\n### Approach\nThe Adam optimization algorithm works as follows:\n1. **Initialization**: Convert the initial parameter values into a numpy array. Initialize two momentum arrays, `m1` and `m2`, to keep track of the first and second moments of the gradients, respectively.\n2. **Iteration**: For each iteration, compute the gradient of the objective function at the current parameter values.\n3. **Update Moments**: Update the first moment `m1` using the gradient and a decay rate `beta1`. Similarly, update the second moment `m2` using the squared gradient and a decay rate `beta2`.\n4. **Compute Step Size**: Calculate the step size using the learning rate, the first moment, the second moment, and a small constant `epsilon` for numerical stability.\n5. **Update Parameters**: Adjust the parameter values using the computed step size.\n6. **Return Result**: After completing the specified number of iterations, convert the parameter values from a numpy array to a list and return them.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef adam_optimizer(f, grad, x0, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, num_iterations=1000):\n    x = np.array(x0, dtype=np.float64)\n    m1 = np.zeros_like(x)\n    m2 = np.zeros_like(x)\n    \n    for _ in range(num_iterations):\n        g = grad(x)\n        m1 = beta1 * m1 + (1 - beta1) * g\n        m2 = beta2 * m2 + (1 - beta2) * g**2\n        step = learning_rate * (m1 / (m2 + epsilon))\n        x += step\n    \n    return x.tolist()\n```\n\n### Explanation\n- **Initialization**: The initial parameter values `x0` are converted into a numpy array to facilitate vector operations. Two arrays `m1` and `m2` are initialized to zero to store the first and second moments of the gradients.\n- **Gradient Computation**: For each iteration, the gradient of the objective function is computed at the current parameter values using the provided `grad` function.\n- **Moment Updates**: The first moment `m1` is updated using the gradient and decay rate `beta1`, while the second moment `m2` is updated using the squared gradient and decay rate `beta2`.\n- **Step Size Calculation**: The step size is determined by scaling the learning rate with the ratio of the first moment to the sum of the second moment and a small constant `epsilon`.\n- **Parameter Update**: The parameter values are updated by adding the computed step size.\n- **Result Conversion**: After all iterations, the parameter values are converted from a numpy array to a list and returned.\n\nThis approach ensures that each parameter's learning rate is adapted automatically, leading to efficient optimization of the objective function."}
{"task_id": 50, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Lasso Regression algorithm using Gradient Descent. Lasso Regression (L1 Regularization) adds a penalty equal to the absolute value of the coefficients to the loss function, which helps in feature selection by shrinking some coefficients to zero.\n\n### Approach\nThe objective function of Lasso Regression is given by:\n\\[ J(w, b) = \\frac{1}{2n} \\sum_{i=1}^n (y_i - (\\sum_{j=1}^p X_{ij} w_j + b))^2 + \\alpha \\sum_{j=1}^p |w_j| \\]\nwhere \\( w \\) are the weights, \\( b \\) is the bias, \\( y_i \\) is the actual value for the i-th sample, \\( X_{ij} \\) is the i-th sample's j-th feature, and \\( \\alpha \\) is the regularization parameter.\n\nThe approach involves the following steps:\n1. **Initialization**: Start with initial weights \\( w \\) and bias \\( b \\) set to zero.\n2. **Iterative Update**: Use Gradient Descent to update the weights and bias iteratively. In each iteration:\n   - Compute the predicted values \\( \\hat{y}_i \\) using the current weights and bias.\n   - Calculate the error between the predicted and actual values.\n   - Compute the gradients of the loss function with respect to \\( w \\) and \\( b \\).\n   - Add the gradient of the L1 penalty to the gradient of the loss function.\n   - Update the weights and bias using the learning rate.\n3. **Convergence Check**: Stop the iterations if the change in weights and bias is below the specified tolerance.\n4. **Result**: Return the weights and bias, rounded to the nearest 4th decimal.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef l1_regularization_gradient_descent(X: np.array, y: np.array, alpha: float = 0.1, learning_rate: float = 0.01, max_iter: int = 1000, tol: float = 1e-4) -> tuple:\n    n = X.shape[0]\n    p = X.shape[1]\n    \n    w = np.zeros(p)\n    b = 0.0\n    \n    prev_w = None\n    prev_b = None\n    \n    for iter in range(max_iter):\n        hat_y = np.dot(X, w) + b\n        error = y - hat_y\n        \n        dw_loss = (1/n) * np.dot(X.T, error)\n        db_loss = (1/n) * np.sum(error)\n        \n        dw_penalty = alpha * np.sign(w)\n        dw = dw_loss + dw_penalty\n        \n        w -= learning_rate * dw\n        b -= learning_rate * db_loss\n        \n        if iter > 0:\n            diff_w = np.abs(w - prev_w)\n            diff_b = np.abs(b - prev_b)\n            if np.max(diff_w) < tol and np.max(diff_b) < tol:\n                break\n        \n        prev_w = w.copy()\n        prev_b = b.copy()\n    \n    w_rounded = np.round(w, 4)\n    b_rounded = np.round(b, 4)\n    \n    return (w_rounded.tolist(), b_rounded.tolist())\n```\n\n### Explanation\n- **Initialization**: The weights \\( w \\) and bias \\( b \\) are initialized to zero.\n- **Predicted Values**: For each iteration, the predicted values \\( \\hat{y}_i \\) are computed using the current weights and bias.\n- **Error Calculation**: The error between the predicted and actual values is computed.\n- **Gradients Calculation**: The gradients of the loss function with respect to \\( w \\) and \\( b \\) are computed. The gradient of the L1 penalty is added to the gradient of the loss function.\n- **Weight and Bias Update**: The weights and bias are updated using the computed gradients and the learning rate.\n- **Convergence Check**: The iteration stops if the change in weights and bias is below the specified tolerance.\n- **Result**: The final weights and bias are rounded to the nearest 4th decimal and returned as a tuple.\n\nThis approach ensures that the model is trained to minimize the loss function while incorporating the L1 regularization to help with feature selection."}
{"task_id": 51, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Optimal String Alignment (OSA) distance between two given strings. The OSA distance represents the minimum number of edits required to transform one string into another. The allowed edit operations are insert, delete, substitute, and transpose two adjacent characters, each costing 1 unit.\n\n### Approach\nThe problem can be approached using dynamic programming (DP). The key idea is to use a DP table where `dp[i][j]` represents the minimum cost to convert the first `i` characters of the first string (`source`) into the first `j` characters of the second string (`target`).\n\n1. **Initialization**: Create a 2D array `dp` with dimensions `(len(source) + 1) x (len(target) + 1)`, initialized to a large value (infinity). Set `dp[0][0]` to 0 because converting an empty string to another empty string requires 0 operations.\n\n2. **Base Cases**:\n   - If `i == 0`, the cost to convert an empty string to the first `j` characters of `target` is `j` (all insertions).\n   - If `j == 0`, the cost to convert the first `i` characters of `source` to an empty string is `i` (all deletions).\n\n3. **DP Transitions**:\n   - **Insert**: Move from `(i, j)` to `(i+1, j)` with a cost of 1.\n   - **Delete**: Move from `(i, j)` to `(i, j+1)` with a cost of 1.\n   - **Substitute**: Move from `(i, j)` to `(i+1, j+1)` with a cost of 1.\n   - **Transpose**: If the current characters at positions `i` and `j` are different, move from `(i, j)` to `(i+1, j+1)` with a cost of 1.\n\n4. **Filling the DP Table**: Iterate through each possible state `(i, j)` and update the DP table based on the allowed operations.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef OSA(source: str, target: str) -> int:\n    len_s1 = len(source)\n    len_s2 = len(target)\n    dp = np.full((len_s1 + 1, len_s2 + 1), float('inf'))\n    dp[0][0] = 0  # Base case: empty strings\n    \n    for i in range(len_s1 + 1):\n        for j in range(len_s2 + 1):\n            if i == 0:\n                dp[i][j] = j\n            elif j == 0:\n                dp[i][j] = i\n            else:\n                # Insert operation\n                if dp[i][j-1] + 1 < dp[i+1][j]:\n                    dp[i+1][j] = dp[i][j-1] + 1\n                # Delete operation\n                if dp[i-1][j] + 1 < dp[i][j+1]:\n                    dp[i][j+1] = dp[i-1][j] + 1\n                # Substitute operation\n                if dp[i-1][j-1] + 1 < dp[i][j+1]:\n                    dp[i][j+1] = min(dp[i][j+1], dp[i-1][j-1] + 1)\n                # Transpose operation\n                if i < len_s1 - 1 and j < len_s2 - 1 and source[i] != target[j]:\n                    if dp[i-1][j-1] + 1 < dp[i][j+1]:\n                        dp[i][j+1] = min(dp[i][j+1], dp[i-1][j-1] + 1)\n    \n    return dp[len_s1][len_s2]\n```\n\n### Explanation\nThe solution uses dynamic programming to efficiently compute the minimum number of edits required to transform one string into another. The DP table is filled by considering all possible operations (insert, delete, substitute, and transpose) and updating the minimum cost for each state. This approach ensures that we explore all possible ways to align the strings optimally, leading to the correct OSA distance."}
{"task_id": 52, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function to calculate the recall metric for a binary classification model. Recall is a measure of how effectively the model identifies positive instances from all the actual positive cases in a dataset.\n\n### Approach\nThe recall metric is calculated as the ratio of true positives to the total number of positive instances. Here's the step-by-step approach:\n\n1. **Calculate Total Positives**: Sum up all the true labels (y_true) to get the total number of positive instances.\n2. **Handle Division by Zero**: If there are no positive instances (total_positives is zero), return 0.0 to avoid division by zero.\n3. **Calculate Correct Positives**: Sum up the predicted labels (y_pred) where the corresponding true label is 1. This gives the number of correctly predicted positive instances.\n4. **Compute Recall**: Divide the number of correct positives by the total number of positives.\n5. **Round the Result**: Return the recall value rounded to three decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef recall(y_true, y_pred):\n    total_positives = np.sum(y_true)\n    if total_positives == 0:\n        return 0.0\n    correct_positives = np.sum(y_pred * (y_true == 1))\n    recall_value = correct_positives / total_positives\n    return round(recall_value, 3)\n```\n\n### Explanation\n- **Total Positives**: This is the count of all positive instances in the dataset, calculated by summing the true labels (y_true).\n- **Correct Positives**: This is the count of instances where both the true label and the predicted label are 1. This is computed by summing the product of y_pred and a boolean array indicating where y_true is 1.\n- **Recall Calculation**: The recall is the ratio of correct positives to the total positives. If there are no positives, the recall is 0.0 to avoid division by zero.\n- **Rounding**: The result is rounded to three decimal places for precision.\n\nThis approach ensures that we accurately measure the model's ability to identify positive instances, providing a clear and precise metric for evaluation."}
{"task_id": 53, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the self-attention mechanism, a fundamental component of transformer models. The self-attention mechanism allows a model to dynamically focus on different parts of the input sequence when generating a contextualized representation.\n\n### Approach\nThe self-attention mechanism involves three main steps: query transformation, key transformation, and value transformation. Here's a detailed breakdown of the approach:\n\n1. **Query, Key, and Value Transformation**: \n   - Transform the input sequence using the given weight matrices to obtain the query (Q), key (K), and value (V) representations.\n   \n2. **Compute Attention Scores**:\n   - Calculate the attention scores by taking the dot product of the query and key matrices. This results in a matrix where each element represents the similarity score between the query and key vectors.\n\n3. **Apply Softmax Function**:\n   - Normalize the attention scores using the softmax function to get the attention weights. These weights determine the importance of each part of the input sequence.\n\n4. **Compute the Output**:\n   - Multiply the query, key, and value matrices by their respective attention weights and sum the results to get the final output. This step combines the contextual information from different parts of the input sequence.\n\n5. **Rounding and Conversion**:\n   - Round the resulting output to the nearest 4th decimal place and convert the numpy array to a list for the final output.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef self_attention(X, W_q, W_k, W_v):\n    # Compute the query, key, and value transformations\n    batch_size, seq_len, embed_dim = X.shape\n    Q = X @ W_q\n    K = X @ W_k\n    V = X @ W_v\n\n    # Reshape to (seq_len, embed_dim)\n    Q = Q.reshape(seq_len, embed_dim)\n    K = K.reshape(seq_len, embed_dim)\n    V = V.reshape(seq_len, embed_dim)\n\n    # Compute the attention scores\n    QK = Q @ K.T\n    att_weights = np.softmax(QK, axis=-1)\n\n    # Compute the output\n    output = (Q * att_weights) + (K * att_weights) + (V * att_weights)\n\n    # Round to the nearest 4th decimal\n    output = np.round(output, 4)\n\n    # Convert to a list\n    output = output.tolist()\n\n    return output\n```\n\n### Explanation\n- **Query, Key, and Value Transformation**: The input sequence `X` is transformed using the weight matrices `W_q`, `W_k`, and `W_v` to produce the query (Q), key (K), and value (V) matrices.\n- **Attention Scores**: The dot product of the query and key matrices gives a matrix of attention scores, which are then normalized using the softmax function to get the attention weights.\n- **Output Computation**: The final output is computed by combining the query, key, and value matrices with their respective attention weights. This results in a contextualized representation of the input sequence.\n- **Rounding and Conversion**: The output is rounded to four decimal places and converted into a list for the final result.\n\nThis approach efficiently computes the self-attention mechanism, providing a contextualized representation of the input sequence, which is widely used in various applications such as natural language processing and computer vision."}
{"task_id": 54, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a simple Recurrent Neural Network (RNN) cell that processes a sequence of input vectors and produces the final hidden state. The RNN uses the tanh activation function for the hidden state updates. The function takes as inputs the sequence of input vectors, the initial hidden state, the weight matrices for input-to-hidden and hidden-to-hidden connections, and the bias vector. The function returns the final hidden state after processing the entire sequence, rounded to four decimal places.\n\n### Approach\n1. **Convert Weights and Bias to Numpy Arrays**: The input weight matrices (Wx and Wh) and the bias vector (b) are converted from lists to numpy arrays to facilitate matrix operations.\n2. **Initialize Hidden State**: The initial hidden state is converted from a list to a numpy array to allow for vector operations.\n3. **Process Each Input Vector**: For each input vector in the input sequence:\n   - Compute the pre-activation values by multiplying the input vector with the input-to-hidden weight matrix (Wx) and adding the bias vector.\n   - Apply the tanh activation function to the pre-activation values to get the new hidden state.\n4. **Update Hidden State**: Update the current hidden state with the new hidden state computed in the previous step.\n5. **Return Final Hidden State**: After processing all input vectors, the final hidden state is rounded to four decimal places and converted to a list before being returned.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef rnn_forward(input_sequence: list[list[float]], initial_hidden_state: list[float], Wx: list[list[float]], Wh: list[list[float]], b: list[float]) -> list[float]:\n    # Convert weights and bias to numpy arrays\n    Wx = np.array(Wx)\n    Wh = np.array(Wh)\n    b = np.array(b)\n    \n    # Convert initial hidden state to numpy array\n    current_h = np.array(initial_hidden_state)\n    \n    for input_vec in input_sequence:\n        # Convert input vector to numpy array\n        input_vec = np.array(input_vec)\n        # Compute pre_activation\n        pre_activation = np.dot(input_vec, Wx) + b\n        # Apply tanh activation function\n        current_h = np.tanh(pre_activation)\n    \n    # Round the final hidden state to four decimal places\n    final_h = round(current_h, 4)\n    # Convert to list and return\n    return final_h.tolist()\n```\n\n### Explanation\n- **Conversion to Numpy Arrays**: The weights and bias are converted to numpy arrays to leverage matrix operations, which are essential for efficient computation in neural networks.\n- **Processing Each Input Vector**: Each input vector is processed sequentially. The hidden state is updated at each step using the current input vector, weights, and bias.\n- **Tanh Activation Function**: The tanh function is applied to the pre-activation values to produce the hidden state for the next time step.\n- **Final State Rounding**: The final hidden state is rounded to four decimal places to meet the problem's requirements and returned as a list.\n\nThis approach ensures that the RNN processes each input vector correctly, updating the hidden state at each step and producing the final hidden state after the entire sequence is processed."}
{"task_id": 55, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that applies a 2D translation matrix to a set of points. The translation matrix will move each point by specified distances in the x and y directions. The function should return a new list of points after applying the translation.\n\n### Approach\nThe approach involves using a translation matrix to transform each point in the given list. The translation matrix is represented by a 2x2 identity matrix, which, when applied to a point, results in the point being moved by the specified translation distances. \n\n1. **Convert Points to Numpy Array**: Convert the list of points into a numpy array to leverage numpy's vectorized operations for efficient computation.\n2. **Apply Translation**: Add the translation vector to the numpy array. This operation will correctly move each point by the specified distances in both the x and y directions.\n3. **Convert Back to List**: Convert the resulting numpy array back into a list of lists using the `tolist()` method to meet the problem's output requirements.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef translate_object(points, tx, ty):\n    points_np = np.array(points)\n    translated_np = points_np + np.array([tx, ty])\n    return translated_np.tolist()\n```\n\n### Explanation\n1. **Conversion to Numpy Array**: The function starts by converting the input list of points into a numpy array. This allows us to use efficient vector operations.\n2. **Translation Application**: The translation is applied by adding a 1D numpy array containing the translation distances `[tx, ty]` to the numpy array of points. This effectively shifts each point by the specified amounts in both the x and y directions.\n3. **Conversion to List**: The result of the translation is converted back into a list of lists using `tolist()`, ensuring the output format matches the problem's requirements.\n\nThis approach efficiently handles the translation of multiple points using vectorized operations, making the solution both concise and performant."}
{"task_id": 56, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the Kullback-Leibler (KL) divergence between two normal distributions. The KL divergence measures how one probability distribution differs from another reference distribution. In this case, we are dealing with two normal distributions, and we want to find how one differs from the other.\n\n### Approach\nThe KL divergence between two normal distributions \\( P \\sim N(\\mu_P, \\sigma_P^2) \\) and \\( Q \\sim N(\\mu_Q, \\sigma_Q^2) \\) can be computed using a closed-form formula derived from the properties of normal distributions. The formula for the KL divergence \\( D \\) is:\n\n\\[ D = \\log\\left(\\frac{\\sigma_Q}{\\sigma_P}\\right) + \\frac{\\sigma_P^2}{2 \\sigma_Q^2} - 0.5 \\]\n\nThis formula is derived by integrating the difference between the probability density functions of the two normal distributions. The formula consists of three parts:\n1. The logarithm of the ratio of the standard deviations.\n2. A term involving the variances of the distributions.\n3. A constant term.\n\n### Solution Code\n```python\nimport math\n\ndef kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q):\n    # Compute the KL divergence between two normal distributions\n    log_term = math.log(sigma_q / sigma_p)\n    term2 = (sigma_p ** 2) / (2 * (sigma_q ** 2))\n    kl = log_term + term2 - 0.5\n    return kl\n```\n\n### Explanation\n1. **Logarithm of the Ratio of Standard Deviations**: The first term, `log_term`, is the natural logarithm of the ratio of the standard deviations of the two distributions. This term captures the difference in the spread of the distributions.\n\n2. **Term Involving Variances**: The second term, `term2`, involves the variances of the two distributions. This term adjusts for the difference in the spread and accounts for the fact that the KL divergence is a measure of divergence.\n\n3. **Constant Term**: The constant term `-0.5` is a result of the integration process and ensures the formula is correctly scaled.\n\nBy combining these three parts, the function computes the KL divergence between the two normal distributions accurately and efficiently. This approach avoids the need for numerical integration and provides a direct computation using the means and variances of the distributions."}
{"task_id": 57, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Gauss-Seidel method, an iterative technique for solving a system of linear equations. This method updates the solution vector using the most recent values available during the iteration process, which allows for faster convergence compared to other iterative methods like Jacobi.\n\n### Approach\nThe Gauss-Seidel method works by iteratively updating each component of the solution vector using the most recent values. Here's a step-by-step breakdown of the approach:\n\n1. **Initialization**: Start with an initial guess for the solution vector. If no initial guess is provided, use a vector of zeros.\n2. **Iteration**: For a specified number of iterations, update each component of the solution vector. In each iteration, use the most recently updated values of the solution vector to compute the next value.\n3. **Update Rule**: For each component \\( x_i \\), compute the new value using the formula:\n   \\[\n   x_i = \\frac{b_i - \\sum_{k \\neq i} A_{ik} x_k}{A_{ii}}\n   \\]\n   where \\( A_{ii} \\) is the diagonal element of the matrix \\( A \\).\n4. **Convergence**: Continue iterating until the specified number of iterations is reached or until the solution converges.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef gauss_seidel(A, b, n, x_ini=None):\n    if x_ini is None:\n        x = np.zeros(len(b))\n    else:\n        x = np.array(x_ini)\n    \n    for _ in range(n):\n        for i in range(len(x)):\n            sum_val = np.dot(A[i], x)\n            x_i = (b[i] - sum_val) / A[i][i]\n            x[i] = x_i\n    \n    x_rounded = np.round(x, 4)\n    return x_rounded.tolist()\n```\n\n### Explanation\n- **Initialization**: The function starts by checking if an initial guess is provided. If not, it initializes the solution vector \\( x \\) with zeros.\n- **Iteration Loop**: The outer loop runs for the specified number of iterations. In each iteration, the inner loop updates each component of the solution vector.\n- **Dot Product Calculation**: For each component \\( x_i \\), the function calculates the sum of the products of the corresponding row of matrix \\( A \\) and the current solution vector using `np.dot`.\n- **Update Rule**: The new value for \\( x_i \\) is computed and immediately assigned to the solution vector, ensuring that the most recent values are used in subsequent updates.\n- **Rounding**: After completing the specified number of iterations, the solution vector is rounded to four decimal places and converted to a list for the final output.\n\nThis approach efficiently leverages the most recent updates to accelerate convergence, making it suitable for systems where the Gauss-Seidel method is effective."}
{"task_id": 58, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Gaussian Elimination method with partial pivoting to solve a system of linear equations. This method transforms the system into an upper triangular matrix, which can then be solved using backward substitution to find the solution vector.\n\n### Approach\nThe Gaussian Elimination method involves the following steps:\n1. **Row Reduction**: Convert the given matrix into an upper triangular form using row operations. This involves finding the pivot element in each column, ensuring it is the largest in its column, and using it to eliminate the entries below it.\n2. **Partial Pivoting**: If the pivot element is zero, swap the current row with the row containing the maximum element in that column to ensure numerical stability.\n3. **Backward Substitution**: After transforming the matrix into an upper triangular form, use back substitution to solve for the variables starting from the last equation and moving up.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef gaussian_elimination(A, b):\n    A_copy = np.copy(A)\n    b_copy = np.copy(b)\n    n = A_copy.shape[1]\n    \n    for col in range(n):\n        # Find the pivot row\n        pivot_row = None\n        max_val = 0\n        for row in range(col, len(A_copy)):\n            current_val = abs(A_copy[row][col])\n            if current_val > max_val:\n                max_val = current_val\n                pivot_row = row\n        if pivot_row != col:\n            # Swap the current row (col) with the pivot row\n            A_copy[col], A_copy[pivot_row] = A_copy[pivot_row], A_copy[col]\n            b_copy[col], b_copy[pivot_row] = b_copy[pivot_row], b_copy[col]\n        \n        # Eliminate the current column in rows below\n        pivot_val = A_copy[col][col]\n        for row in range(col + 1, len(A_copy)):\n            factor = A_copy[row][col] / pivot_val\n            A_copy[row] = A_copy[row] - factor * A_copy[col]\n            b_copy[row] = b_copy[row] - factor * b_copy[col]\n    \n    # Backward substitution\n    x = [0.0 for _ in range(n)]\n    if n == 0:\n        return []\n    x[-1] = b_copy[-1] / A_copy[-1][-1]\n    for i in range(n - 2, -1, -1):\n        x[i] = (b_copy[i] - A_copy[i][-1] * x[i + 1]) / A_copy[i][i]\n    \n    # Round to the nearest 4th decimal\n    x = [round(val, 4) for val in x]\n    return x.tolist()\n```\n\n### Explanation\n1. **Row Reduction**: The code iterates over each column to find the pivot element, which is the largest element in that column from the current row downwards. If the pivot element is zero, the row with the maximum element in that column is swapped with the current row. The pivot element is then used to eliminate the entries below it in the current column.\n2. **Partial Pivoting**: This ensures that each pivot element is non-zero, which is crucial for the stability of the algorithm.\n3. **Backward Substitution**: After transforming the matrix into an upper triangular form, the solution is found by starting from the last equation and moving up, solving each variable using the known values from the subsequent equations.\n\nThis approach efficiently transforms the system of equations into a form that allows for straightforward solution using substitution, ensuring both accuracy and numerical stability."}
{"task_id": 59, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a Long Short-Term Memory (LSTM) network that processes a sequence of inputs and returns the hidden states at each time step, along with the final hidden state and cell state. The LSTM network computes gates (forget, input, output) at each time step to update the hidden state and cell state.\n\n### Approach\n1. **Initialization**: The LSTM network is initialized with input and hidden sizes. Weights and biases for the gates are randomly initialized.\n2. **Forward Pass**: For each time step in the sequence:\n   - Extract the current input.\n   - Compute the forget, input, and output gates using matrix multiplication and addition with biases.\n   - Compute the candidate cell state.\n   - Update the cell state and hidden state using the candidate cell state and gates.\n   - Append the hidden state to the list of hidden states.\n3. **Rounding and Conversion**: After processing all time steps, round the results to the nearest 4th decimal and convert them into lists for the final output.\n\n### Solution Code\n```python\nimport numpy as np\n\nclass LSTM:\n    def __init__(self, input_size, hidden_size):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n\n        # Initialize weights and biases\n        self.Wf = np.random.randn(hidden_size, input_size + hidden_size)\n        self.Wi = np.random.randn(hidden_size, input_size + hidden_size)\n        self.Wc = np.random.randn(hidden_size, input_size + hidden_size)\n        self.Wo = np.random.randn(hidden_size, input_size + hidden_size)\n\n        self.bf = np.zeros((hidden_size, 1))\n        self.bi = np.zeros((hidden_size, 1))\n        self.bc = np.zeros((hidden_size, 1))\n        self.bo = np.zeros((hidden_size, 1))\n\n    def forward(self, x, initial_hidden_state, initial_cell_state):\n        \"\"\"\n        Processes a sequence of inputs and returns the hidden states, final hidden state, and final cell state.\n        \"\"\"\n        batch_size, sequence_length, input_size = x.shape\n        hidden_size = self.hidden_size\n\n        # Initialize hidden and cell states\n        h = initial_hidden_state\n        c = initial_cell_state\n\n        # List to collect hidden states\n        hidden_states = []\n\n        for t in range(sequence_length):\n            x_t = x[:, t, :]  # current input\n\n            # Compute gates\n            forget = np.dot(self.Wf, x_t) + self.bf\n            input_gate = np.dot(self.Wi, x_t) + self.bi\n            cell_candidate = np.dot(self.Wc, x_t) + self.bc\n            output_gate = np.dot(self.Wo, x_t) + self.bo\n\n            # Compute new cell state\n            new_cell = np.multiply(cell_candidate, input_gate)\n            new_cell = np.add(new_cell, np.multiply(c, forget))\n\n            # Compute new hidden state\n            new_h = np.multiply(h, forget)\n            new_h = np.add(new_h, np.multiply(c, input_gate))\n\n            # Update states\n            h = new_h\n            c = new_cell\n\n            # Append hidden state to the list\n            hidden_states.append(h)\n\n        # Round the results to the nearest 4th decimal and convert to lists\n        rounded_hidden_states = [np.round(h, 4).tolist() for h in hidden_states]\n        rounded_h = np.round(h, 4).tolist()\n        rounded_c = np.round(c, 4).tolist()\n\n        return rounded_hidden_states, rounded_h, rounded_c\n```\n\n### Explanation\n- **Initialization**: The LSTM class is initialized with input and hidden sizes. Weights and biases for the gates are randomly initialized to ensure proper weightage during matrix multiplications.\n- **Forward Pass**: For each time step, the current input is extracted, and gates are computed using matrix multiplication and addition with biases. The cell state and hidden state are updated using these gates, and the hidden state is appended to the list of hidden states.\n- **Rounding and Conversion**: After processing all time steps, the results are rounded to the nearest 4th decimal and converted into lists to meet the output constraints.\n\nThis approach ensures that the LSTM network processes the sequence correctly, updating the hidden and cell states at each time step, and returns the required results in the specified format."}
{"task_id": 60, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the TF-IDF (Term Frequency-Inverse Document Frequency) scores for a query against a given corpus of documents. The TF-IDF score is a measure that combines the frequency of a term within a document and the inverse frequency of the term across all documents. This score is useful for information retrieval in natural language processing tasks.\n\n### Approach\n1. **Compute Document Frequencies (DF)**: For each word in the corpus, count how many documents contain the word at least once. This gives us the document frequency (DF) for each word.\n2. **Compute Inverse Document Frequencies (IDF)**: For each word in the query, compute the IDF using the formula:\n   \\[\n   \\text{IDF} = \\log\\left(\\frac{N + 1}{\\text{DF} + 1}\\right)\n   \\]\n   where \\(N\\) is the total number of documents in the corpus, and \\(\\text{DF}\\) is the document frequency of the word.\n3. **Compute TF-IDF Scores**: For each document in the corpus, compute the TF (term frequency) for each word in the query. Multiply the TF by the precomputed IDF to get the TF-IDF score for that word in the document.\n4. **Handle Edge Cases**: Ensure the function gracefully handles cases such as an empty corpus, empty query, or documents with no words. Also, handle division by zero by using the formula appropriately.\n\n### Solution Code\n```python\nimport math\nfrom collections import defaultdict\n\ndef compute_tf_idf(corpus, query):\n    if not corpus:\n        return []\n    \n    # Compute document frequencies\n    df_dict = defaultdict(int)\n    for doc in corpus:\n        unique_words = set(doc)\n        for word in unique_words:\n            df_dict[word] += 1\n    \n    N = len(corpus)\n    \n    # Precompute IDFs for each query word\n    query_words = set(query)\n    idf_scores = {}\n    for word in query_words:\n        df = df_dict.get(word, 0)\n        idf = math.log((N + 1) / (df + 1))\n        idf_scores[word] = idf\n    \n    # For each document, compute TF for each query word\n    result = []\n    for doc in corpus:\n        # Create a Counter for the document's words\n        word_counts = defaultdict(int)\n        for word in doc:\n            word_counts[word] += 1\n        \n        # For each query word, get the count and multiply by IDf\n        tfidf_scores = []\n        for word in query:\n            count = word_counts.get(word, 0)\n            idf = idf_scores.get(word, 0.0)\n            tfidf = count * idf\n            tfidf_scores.append(tfidf)\n        \n        # Round to 5 decimal places\n        rounded_scores = [round(x, 5) for x in tfidf_scores]\n        result.append(rounded_scores)\n    \n    return result\n```\n\n### Explanation\n1. **Document Frequencies (DF)**: We use a dictionary to count how many times each word appears across all documents. This helps in determining the global frequency of each word.\n2. **Inverse Document Frequencies (IDF)**: For each word in the query, we compute the IDF using the formula which accounts for the total number of documents and the frequency of the word. This helps in understanding the importance of a word across the entire corpus.\n3. **TF-IDF Calculation**: For each document, we count the occurrences of each query word (TF) and multiply it by the precomputed IDF to get the TF-IDF score. This score reflects how important the word is in the specific context of the document.\n4. **Edge Cases Handling**: The function handles empty corpus, empty query, and documents with no words gracefully. It also avoids division by zero by using the formula correctly.\n\nThis approach ensures that we efficiently compute the TF-IDF scores for each query word in each document, providing a robust solution for information retrieval tasks."}
{"task_id": 61, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that calculates the F-Score for a binary classification task. The F-Score is a measure that combines both Precision and Recall into a single metric, providing a balanced measure of a model's performance. The F-Score is particularly useful when the cost of different errors is not the same, allowing us to adjust the importance of Precision and Recall using a parameter called beta.\n\n### Approach\nThe F-Score is calculated using the following steps:\n1. **Compute the Confusion Matrix**: Calculate the number of True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives (TN) from the given true labels (y_true) and predicted labels (y_pred).\n2. **Calculate Precision and Recall**: Precision is the ratio of True Positives to the sum of True Positives and False Positives. Recall is the ratio of True Positives to the sum of True Positives and False Negatives.\n3. **Handle Division by Zero**: Ensure that Precision and Recall are handled correctly when their denominators are zero to avoid division by zero errors.\n4. **Compute the F-Score**: Use the formula for the F-Score, which is a weighted harmonic mean of Precision and Recall, where the weight is determined by the beta parameter.\n5. **Return the Result**: Round the computed F-Score to three decimal places and return it.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef f_score(y_true, y_pred, beta):\n    \"\"\"\n    Calculate F-Score for a binary classification task.\n\n    :param y_true: Numpy array of true labels\n    :param y_pred: Numpy array of predicted labels\n    :param beta: The weight of precision in the harmonic mean\n    :return: F-Score rounded to three decimal places\n    \"\"\"\n    # Compute counts for confusion matrix\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    tn = np.sum((y_true == 0) & (y_pred == 0))\n    \n    # Calculate precision and recall, handling division by zero\n    precision = np.where(tp + fp != 0, tp / (tp + fp), 0.0)\n    recall = np.where(tp + fn != 0, tp / (tp + fn), 0.0)\n    \n    # Compute F-score\n    numerator = (1 + beta) * precision * recall\n    denominator = beta * precision + recall\n    f = numerator / denominator\n    \n    # Handle division by zero by setting F-score to 0.0\n    f = np.where(denominator == 0, 0.0, f)\n    \n    # Round to three decimal places\n    return round(f, 3)\n```\n\n### Explanation\n1. **Confusion Matrix Calculation**: The function starts by computing the counts of True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives (TN) using boolean operations and summation.\n2. **Precision and Recall Calculation**: Precision and Recall are calculated using the counts from the confusion matrix. Special handling is included to avoid division by zero, setting Precision and Recall to 0.0 in such cases.\n3. **F-Score Calculation**: The F-Score is computed using the formula that weights the harmonic mean of Precision and Recall by the beta parameter. If the denominator is zero, the F-Score is set to 0.0 to avoid division by zero errors.\n4. **Result Rounding**: The computed F-Score is rounded to three decimal places before being returned as the result.\n\nThis approach ensures that the F-Score is accurately computed for any given binary classification task, taking into account the importance of Precision and Recall as dictated by the beta parameter."}
{"task_id": 62, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a simple Recurrent Neural Network (RNN) with Backpropagation Through Time (BPTT) to learn from sequential data. The RNN will process input sequences, update hidden states, and perform backpropagation to adjust weights based on the error gradient.\n\n### Approach\nThe task involves implementing two main methods: the forward pass and the backward pass. The forward pass processes the input sequence to compute the output, hidden states, and last inputs. The backward pass uses BPTT to compute the gradients of the loss with respect to the weights and biases, and updates the weights accordingly.\n\n1. **Initialization**: The RNN is initialized with random weights and zero biases.\n2. **Forward Pass**: For each input sequence, the RNN computes the hidden states and outputs step by step. The hidden state at each time step depends on the previous hidden state and the current input.\n3. **Backward Pass**: Using BPTT, the RNN computes the gradients of the loss with respect to the weights and biases. The error at each time step is propagated backward through the network to update the weights.\n\n### Solution Code\n```python\nimport numpy as np\n\nclass SimpleRNN:\n    def __init__(self, input_size, hidden_size, output_size):\n        \"\"\"\n        Initializes the RNN with random weights and zero biases.\n        \"\"\"\n        self.hidden_size = hidden_size\n        self.W_xh = np.random.randn(hidden_size, input_size) * 0.01\n        self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.01\n        self.W_hy = np.random.randn(output_size, hidden_size) * 0.01\n        self.b_h = np.zeros((hidden_size, 1))\n        self.b_y = np.zeros((output_size, 1))\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass through the RNN for a given sequence of inputs.\n        Returns:\n            outputs: The output predictions for each time step.\n            last_inputs: The last input(s) in the sequence.\n            hidden_states: The hidden states at each time step.\n        \"\"\"\n        T = len(x)\n        hidden_states = np.zeros((T, self.hidden_size))\n        outputs = np.zeros((T, self.output_size))\n        last_hiddens = np.zeros((1, self.hidden_size))  # Initial hidden state\n        for t in range(T):\n            x_t = x[t]\n            h_t = last_hiddens\n            next_h = self.W_hh.dot(h_t) + self.b_h\n            next_h = next_h.reshape(1, self.hidden_size)\n            output = self.W_hy.dot(h_t) + self.b_y\n            outputs[t] = output\n            hidden_states[t] = h_t\n            last_hiddens = next_h\n        last_inputs = x  # The entire input sequence\n        return outputs, last_inputs, hidden_states\n\n    def rnn_backward(self, W_xh, W_hh, W_hy, b_h, b_y, hidden_size, input_sequence, expected_output, outputs, last_inputs, last_hiddens, learning_rate):\n        \"\"\"\n        Backward pass through the RNN using BPTT.\n        Returns:\n            None\n        \"\"\"\n        T = len(input_sequence)\n        # Compute loss\n        loss = 0\n        for t in range(T):\n            loss += 0.5 * np.mean((outputs[t] - expected_output[t])**2)\n        \n        # Initialize gradients\n        dW_xh = np.zeros_like(W_xh)\n        dW_hh = np.zeros_like(W_hh)\n        dW_hy = np.zeros_like(W_hy)\n        \n        # Compute deltas for each time step in reverse order\n        for t in reversed(range(T)):\n            h_t = last_hiddens[t]\n            x_t = last_inputs[t]\n            \n            # Compute delta3 (error at current time step)\n            delta3_t = (expected_output[t] - outputs[t]) * W_hy.T\n            \n            # Compute delta2 (error for hidden layer)\n            delta2_t = delta3_t.dot(h_t)\n            \n            # Compute delta1 (error for input layer)\n            delta1_t = delta2_t.dot(W_hh.T)\n            \n            # Compute delta0 (error for input)\n            delta0_t = delta1_t.dot(x_t)\n            \n            # Accumulate gradients\n            dW_hy += delta3_t\n            dW_hh += delta2_t\n            dW_xh += delta0_t\n        \n        # Update weights\n        self.W_xh -= learning_rate * dW_xh\n        self.W_hh -= learning_rate * dW_hh\n        self.W_hy -= learning_rate * dW_hy\n        \n        # Compute gradients for biases\n        d_b_h = np.zeros_like(self.b_h)\n        d_b_y = np.zeros_like(self.b_y)\n        for t in reversed(range(T)):\n            # Accumulate delta2 for b_h\n            d_b_h += delta2_t.sum(axis=0)\n        for t in reversed(range(T)):\n            # Accumulate delta3 for b_y\n            d_b_y += delta3_t.sum(axis=0)\n        \n        # Update biases\n        self.b_h -= learning_rate * d_b_h\n        self.b_y -= learning_rate * d_b_y\n```\n\n### Explanation\n1. **Initialization**: The RNN is initialized with random weights and zero biases. The weights are scaled by 0.01 to prevent large initial values.\n2. **Forward Pass**: The input sequence is processed step by step. For each time step, the hidden state is updated using the previous hidden state and the current input. The output is computed based on the current hidden state.\n3. **Backward Pass**: The loss is computed as the mean squared error. The error at each time step is propagated backward to compute the gradients of the loss with respect to the weights and biases. The gradients are accumulated and used to update the weights. The biases are also updated based on the accumulated errors.\n\nThis approach ensures that the RNN learns from sequential data efficiently by updating the weights based on the error gradient through time."}
{"task_id": 63, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Conjugate Gradient (CG) method, an efficient iterative algorithm for solving large, sparse, symmetric, positive-definite linear systems. The goal is to find the solution vector \\( x \\) for the system \\( Ax = b \\) using the given matrix \\( A \\) and vector \\( b \\).\n\n### Approach\nThe Conjugate Gradient method is an iterative algorithm that starts with an initial guess for the solution vector \\( x \\) and improves it in each iteration. The key steps of the method are as follows:\n\n1. **Initialization**: Start with an initial guess for \\( x \\) (if provided) or set it to the zero vector.\n2. **Residual Calculation**: Compute the residual vector \\( r \\) as \\( r = b - Ax \\).\n3. **Search Direction**: Compute the initial search direction vector \\( d \\) as the same as the residual vector \\( r \\).\n4. **Conjugate Coefficient**: Calculate the conjugate coefficient \\( \\alpha \\) using the formula \\( \\alpha = \\frac{r^T r}{r^T d} \\).\n5. **Update Solution**: Use the search direction and conjugate coefficient to update the solution vector \\( x \\).\n6. **New Residual**: Compute the new residual vector using the updated solution.\n7. **New Search Direction**: Update the search direction vector using the formula \\( d = d - \\frac{A d}{r^T d} \\).\n8. **Stopping Criterion**: Check if the norm of the residual vector is below the specified tolerance. If so, stop the iterations.\n\nThe algorithm continues iterating until the norm of the residual vector is below the tolerance or the maximum number of iterations is reached.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef conjugate_gradient(A: np.array, b: np.array, n: int, x0: np.array=None, tol=1e-8):\n    \"\"\"\n    Solve the system Ax = b using the Conjugate Gradient method.\n\n    :param A: Symmetric positive-definite matrix\n    :param b: Right-hand side vector\n    :param n: Maximum number of iterations\n    :param x0: Initial guess for solution (default is zero vector)\n    :param tol: Convergence tolerance\n    :return: Solution vector x\n    \"\"\"\n    if x0 is None:\n        x0 = np.zeros(A.shape[0], dtype=np.float64)\n    \n    r0 = b - A @ x0\n    d0 = r0.copy()\n    \n    for _ in range(n):\n        r0T_r0 = np.dot(r0, r0)\n        r0T_d0 = np.dot(r0, d0)\n        \n        if r0T_d0 == 0:\n            break  # Avoid division by zero\n        \n        alpha = r0T_r0 / r0T_d0\n        \n        x1 = x0 + alpha * d0\n        r1 = r0 - A @ (alpha * d0)\n        \n        A_d0 = A @ d0\n        r1T_d0 = np.dot(r1, d0)\n        \n        if r1T_d0 == 0:\n            break  # Avoid division by zero\n        \n        factor = r0T_d0 / r1T_d0\n        d1 = d0 - A_d0 * factor\n        \n        norm_r1 = np.linalg.norm(r1)\n        if norm_r1 < tol:\n            break\n        \n        x0 = x1\n        r0 = r1\n        d0 = d1\n    \n    solution = np.round(x0, 8).tolist()\n    return solution\n```\n\n### Explanation\nThe provided code implements the Conjugate Gradient method as follows:\n\n1. **Initialization**: The initial guess \\( x_0 \\) is set to the zero vector if not provided.\n2. **Residual Calculation**: The initial residual vector \\( r_0 \\) is computed as \\( b - Ax_0 \\).\n3. **Search Direction**: The initial search direction vector \\( d_0 \\) is set to \\( r_0 \\).\n4. **Iteration Loop**: For each iteration up to \\( n \\):\n   - Compute the conjugate coefficient \\( \\alpha \\).\n   - Update the solution vector \\( x \\) using the current search direction and \\( \\alpha \\).\n   - Compute the new residual vector \\( r_1 \\).\n   - Update the search direction vector \\( d \\) using the formula involving \\( A \\) and the current residual.\n   - Check if the norm of the residual is below the tolerance to stop early.\n5. **Solution**: After the loop, the solution vector \\( x \\) is rounded to 8 decimal places and returned as a list.\n\nThis method efficiently converges to the solution for large sparse systems, leveraging the properties of symmetric positive-definite matrices."}
{"task_id": 64, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Gini impurity for a given list of class labels. The Gini impurity is a measure of impurity or disorder within a node in decision tree algorithms. It is calculated based on the confusion matrix of the data and is used to evaluate how well a node is classified.\n\n### Approach\nThe Gini impurity is calculated using the following formula:\n\\[ G = 2 \\times (1 - \\frac{\\text{correct}}{\\text{total}}) \\times (1 - \\frac{\\text{max\\_freq}}{\\text{total}}) \\]\nwhere:\n- `correct` is the number of samples correctly classified as the majority class.\n- `max_freq` is the highest frequency of any single class in the node.\n- `total` is the total number of samples in the node.\n\nThe steps to compute the Gini impurity are:\n1. Count the frequency of each class in the list of class labels.\n2. Determine the maximum frequency among all classes.\n3. Calculate the total number of samples.\n4. Use the formula to compute the Gini impurity.\n\n### Solution Code\n```python\nfrom collections import Counter\n\ndef gini_impurity(y: list[int]) -> float:\n    \"\"\"\n    Calculate Gini Impurity for a list of class labels.\n\n    :param y: List of class labels\n    :return: Gini Impurity rounded to three decimal places\n    \"\"\"\n    if not y:\n        return 0.0  # Handle empty list case\n    \n    counts = Counter(y)\n    max_freq = max(counts.values())\n    total = len(y)\n    correct = max_freq  # The correct count is the maximum frequency\n    \n    g = 2 * (1 - correct / total) * (1 - max_freq / total)\n    return round(g, 3)\n```\n\n### Explanation\n1. **Counting Frequencies**: We use the `Counter` class from the `collections` module to count the frequency of each class in the input list.\n2. **Finding Maximum Frequency**: The maximum value from the frequency counts is determined, which gives us the highest number of samples in any single class.\n3. **Total Samples**: The total number of samples is simply the length of the input list.\n4. **Gini Impurity Calculation**: Using the formula, we compute the Gini impurity by first calculating the probabilities of correct classification and the majority class, then applying the formula to get the impurity value.\n\nThis approach efficiently computes the Gini impurity by leveraging the properties of the confusion matrix and the distribution of class labels in the node. The result is rounded to three decimal places for precision."}
{"task_id": 65, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to convert a given dense matrix into the Compressed Row Sparse (CSR) format. The CSR format is an efficient way to store sparse matrices by only keeping track of the non-zero elements and their positions, significantly reducing memory usage for matrices with a large number of zeros.\n\n### Approach\nThe approach involves the following steps:\n\n1. **Initialization**: We start by initializing three lists: `values` to store the non-zero elements, `columns` to store the column indices of these non-zero elements, and `row_pointers` to store the cumulative count of non-zero elements per row.\n\n2. **Iterate through each row**: For each row in the dense matrix, we check each element. If the element is non-zero, we add it to the `values` list and its column index to the `columns` list.\n\n3. **Update row pointers**: After processing each row, we update the `row_pointers` list with the cumulative count of non-zero elements up to the current row. This cumulative count helps in mapping the non-zero elements back to their respective rows efficiently.\n\n4. **Return the result**: Finally, we return a tuple containing the `values`, `columns`, and `row_pointers` lists.\n\n### Solution Code\n```python\ndef compressed_row_sparse_matrix(dense_matrix):\n    \"\"\"\n    Convert a dense matrix to its Compressed Row Sparse (CSR) representation.\n\n    :param dense_matrix: 2D list representing a dense matrix\n    :return: A tuple containing (values array, column indices array, row pointer array)\n    \"\"\"\n    values = []\n    columns = []\n    row_pointers = []\n    total_non_zeros = 0\n\n    for row_index, row in enumerate(dense_matrix):\n        current_non_zeros = 0\n        for col_index, value in enumerate(row):\n            if value != 0:\n                values.append(value)\n                columns.append(col_index)\n                current_non_zeros += 1\n        row_pointers.append(total_non_zeros)\n        total_non_zeros += current_non_zeros\n\n    return (values, columns, row_pointers)\n```\n\n### Explanation\n- **Initialization**: We start with empty lists for `values`, `columns`, and `row_pointers`, and a counter `total_non_zeros` initialized to zero.\n- **Row Processing**: For each row, we iterate through each element. Non-zero elements are added to `values` and their column indices to `columns`.\n- **Cumulative Count**: After processing each row, the cumulative count of non-zero elements is stored in `row_pointers`, which helps in efficiently mapping the non-zero elements to their respective rows.\n- **Efficiency**: The CSR format reduces the memory footprint by only storing non-zero elements, making it suitable for large sparse matrices.\n\nThis approach ensures that we efficiently convert a dense matrix into the CSR format, leveraging the sparse nature of the matrix to minimize memory usage."}
{"task_id": 66, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the orthogonal projection of a vector `v` onto another vector `L`. The orthogonal projection of a vector onto a line is the vector on the line that is closest to the given vector. This can be achieved using vector projection formulas.\n\n### Approach\nThe orthogonal projection of a vector `v` onto a vector `L` can be computed using the following steps:\n\n1. **Compute the Dot Product**: The dot product of `v` and `L` is calculated. This gives a scalar value.\n2. **Compute the Squared Magnitude of `L`**: The squared magnitude of `L` is computed to avoid dealing with square roots, which simplifies the calculation.\n3. **Compute the Scalar Projection Factor**: The scalar projection factor is obtained by dividing the dot product by the squared magnitude of `L`.\n4. **Compute the Projection Vector**: Multiply each component of `L` by the scalar projection factor to get the projection vector.\n5. **Round the Result**: The resulting projection vector is rounded to three decimal places for the final output.\n\n### Solution Code\n```python\ndef orthogonal_projection(v, L):\n    \"\"\"\n    Compute the orthogonal projection of vector v onto line L.\n\n    :param v: The vector to be projected\n    :param L: The line vector defining the direction of projection\n    :return: List representing the projection of v onto L\n    \"\"\"\n    # Compute the dot product of v and L\n    dot_product = sum(v[i] * L[i] for i in range(len(v)))\n    \n    # Compute the squared magnitude of L\n    squared_L = sum(L[i] ** 2 for i in range(len(L)))\n    \n    # Handle the case where L is a zero vector (though problem assumes it's not)\n    if squared_L == 0:\n        return [0.0] * len(v)\n    \n    # Compute the scalar projection factor\n    scalar = dot_product / squared_L\n    \n    # Compute the projection vector\n    projection = [L[i] * scalar for i in range(len(L))]\n    \n    # Round each component to three decimal places\n    projection = [round(component, 3) for component in projection]\n    \n    return projection\n```\n\n### Explanation\n1. **Dot Product Calculation**: The dot product of `v` and `L` is computed by summing the products of corresponding components of `v` and `L`.\n2. **Squared Magnitude of `L`**: This is the sum of the squares of each component of `L`, which is used to normalize the projection.\n3. **Scalar Projection Factor**: This factor scales the vector `L` to the correct length for the projection.\n4. **Projection Vector**: Each component of `L` is scaled by the scalar factor to get the projection vector.\n5. **Rounding**: The result is rounded to three decimal places to meet the problem's requirements.\n\nThis approach ensures that the projection is computed efficiently and accurately, adhering to the mathematical definition of orthogonal projection."}
{"task_id": 67, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to convert a dense matrix into its Compressed Column Sparse (CSC) format. The CSC format efficiently stores only the non-zero elements of the matrix, which is particularly useful for matrices with a high number of zero elements.\n\n### Approach\nThe approach involves iterating through each column of the dense matrix and collecting the non-zero elements, their corresponding row indices, and noting the starting index of each column in the values array. Here are the detailed steps:\n\n1. **Initialize Data Structures**: Create three lists to store the non-zero values, their corresponding row indices, and the starting indices of each column in the values array.\n2. **Iterate Over Columns**: For each column, determine the starting index in the values array.\n3. **Collect Non-Zero Elements**: For each row in the current column, if the element is non-zero, add it to the values list and its row index to the row indices list.\n4. **Update Column Pointer**: After processing all rows in a column, record the starting index of the next column in the column pointer list.\n\nThis method ensures that we efficiently collect only the non-zero elements and their positions, resulting in a compressed representation of the original dense matrix.\n\n### Solution Code\n```python\ndef compressed_col_sparse_matrix(dense_matrix):\n    \"\"\"\n    Convert a dense matrix into its Compressed Column Sparse (CSC) representation.\n\n    :param dense_matrix: List of lists representing the dense matrix\n    :return: Tuple of (values, row indices, column pointer)\n    \"\"\"\n    if not dense_matrix:\n        return ([], [], [])\n    \n    rows = len(dense_matrix)\n    cols = len(dense_matrix[0]) if rows > 0 else 0\n    \n    values = []\n    row_indices = []\n    column_pointer = []\n    \n    for j in range(cols):\n        start = len(values)\n        column_pointer.append(start)\n        for i in range(rows):\n            if dense_matrix[i][j] != 0:\n                values.append(dense_matrix[i][j])\n                row_indices.append(i)\n    \n    return (values, row_indices, column_pointer)\n```\n\n### Explanation\n- **Initialization**: The function starts by checking if the input matrix is empty and initializes the necessary lists.\n- **Column Iteration**: For each column, the starting index in the values array is determined and recorded in the column pointer.\n- **Row Processing**: Each row in the current column is checked. Non-zero elements are added to the values and row indices lists.\n- **Efficiency**: This approach ensures that only non-zero elements are stored, making the representation efficient in terms of both time and space.\n\nThis method effectively compresses the dense matrix into a more efficient format, suitable for applications where sparse matrices are beneficial, such as in numerical linear algebra."}
{"task_id": 68, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to find the column space (or image) of a given matrix `A` using concepts from linear algebra. The column space consists of all linear combinations of the columns of `A`, and we can determine the basis vectors for this space by identifying the linearly independent columns of `A`.\n\n### Approach\n1. **Gaussian Elimination**: Transform the given matrix `A` into its row-echelon form. This form helps in identifying the pivot columns, which are the columns corresponding to the linearly independent vectors.\n2. **Identify Pivot Columns**: In the row-echelon form, the pivot columns are the columns containing the leading 1s (or the first non-zero entry) in each row. These columns form the basis of the column space.\n3. **Extract Basis Vectors**: Extract the columns from the original matrix `A` corresponding to the identified pivot columns. These extracted columns form the basis vectors of the column space.\n4. **Round and Format the Result**: Round the basis vectors to 8 decimal places and convert them into a list of lists for the final result.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef matrix_image(A):\n    # Make a copy of the matrix to avoid modifying the original\n    R = A.copy()\n    n_rows = R.shape[0]\n    n_cols = R.shape[1]\n    \n    # Perform Gaussian elimination to get row-echelon form\n    for i in range(n_rows):\n        # Find the pivot column\n        p = None\n        for j in range(i, n_cols):\n            if abs(R[i, j]) > 1e-8:  # considering floating point precision\n                p = j\n                break\n        if p is None:\n            continue  # no pivot in this row\n        # Swap rows i and p\n        R[i, :], R[p, :] = R[p, :], R[i, :]\n        # Eliminate entries below row i in column p\n        for j in range(i+1, n_rows):\n            factor = R[j, p]\n            R[j, :] = R[j, :] - factor * R[i, :]\n            # Set very small values to zero to avoid floating point issues\n            R[j, :] = np.where(np.abs(R[j, :]) < 1e-8, 0, R[j, :])\n    \n    # Identify pivot columns\n    pivot_cols = []\n    for i in range(n_rows):\n        for j in range(n_cols):\n            if abs(R[i, j]) > 1e-8:\n                if j not in pivot_cols:\n                    pivot_cols.append(j)\n                break\n    \n    # Extract the basis vectors from the original matrix A\n    basis_matrix = np.zeros((len(pivot_cols), n_cols))\n    for j in range(len(pivot_cols)):\n        col = A[:, pivot_cols[j]]\n        basis_matrix[:, j] = col\n    \n    # Round to 8 decimal places\n    rounded_basis = np.round(basis_matrix, 8)\n    # Convert to list of lists\n    result = rounded_basis.tolist()\n    \n    return result\n```\n\n### Explanation\n1. **Gaussian Elimination**: The code first performs Gaussian elimination on the matrix `A` to transform it into its row-echelon form. This involves finding the pivot columns, swapping rows to bring the pivot to the top, and eliminating entries below the pivot.\n2. **Identify Pivot Columns**: After transforming `A` into its row-echelon form, the code identifies the pivot columns by checking each row for the first non-zero entry.\n3. **Extract Basis Vectors**: The columns of the original matrix `A` corresponding to the pivot columns are extracted. These columns form the basis vectors of the column space.\n4. **Round and Format**: The basis vectors are rounded to 8 decimal places and converted into a list of lists for the final output.\n\nThis approach ensures that we correctly identify the linearly independent columns of `A` and return them as the basis vectors for the column space."}
{"task_id": 69, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the R-squared value for a regression analysis given arrays of true values and predicted values. The R-squared value, also known as the coefficient of determination, measures how well the independent variables explain the variability of the dependent variable.\n\n### Approach\nThe R-squared value is calculated using the formula:\n\\[ R^2 = 1 - \\frac{SSE}{SSW} \\]\nwhere:\n- \\( SSE \\) is the sum of squared errors (the difference between the predicted values and the true values).\n- \\( SSW \\) is the sum of squared deviations from the mean of the true values.\n\nThe steps to compute the R-squared value are as follows:\n1. Compute the mean of the true values.\n2. Calculate the sum of squared errors (SSE) between the predicted and true values.\n3. Calculate the sum of squared deviations from the mean of the true values (SSW).\n4. If the sum of squared deviations (SSW) is zero, return 1.0 because the model perfectly fits the data.\n5. Otherwise, compute the R-squared value using the formula and round it to three decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef r_squared(y_true, y_pred):\n    mean_y = np.mean(y_true)\n    sum_errors = np.sum((y_pred - y_true) ** 2)\n    sum_total = np.sum((y_true - mean_y) ** 2)\n    \n    if sum_total == 0:\n        return 1.0\n    else:\n        r_squared = 1 - (sum_errors / sum_total)\n        return round(r_squared, 3)\n```\n\n### Explanation\n1. **Mean Calculation**: The mean of the true values is computed to determine the central value around which the deviations are measured.\n2. **Sum of Squared Errors (SSE)**: This measures how far each predicted value is from the corresponding true value. A lower SSE indicates a better fit.\n3. **Sum of Squared Deviations (SSW)**: This measures the total variability of the true values. A higher SSW indicates more variability, which the model needs to explain.\n4. **R-squared Calculation**: The R-squared value is computed as 1 minus the ratio of SSE to SSW. This value ranges from 0 to 1, where 0 indicates that the model explains no variability and 1 indicates that the model explains all variability.\n\nThis approach ensures that we accurately measure how well the regression model fits the given data, providing a clear and interpretable metric for the quality of the fit."}
{"task_id": 70, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the average brightness of a grayscale image represented as a 2D matrix. Each element in the matrix represents a pixel value between 0 (black) and 255 (white). The function should handle various edge cases and return the average brightness rounded to two decimal places, or -1 if any edge case is encountered.\n\n### Approach\n1. **Check for an Empty Image**: If the input matrix is empty, return -1 immediately.\n2. **Check for Inconsistent Row Lengths**: Ensure all rows in the matrix have the same length. If any row has a different length, return -1.\n3. **Check for Valid Pixel Values**: Verify that all pixel values are within the valid range (0-255). If any pixel value is outside this range, return -1.\n4. **Calculate Total Pixels and Sum**: Compute the total number of pixels and the sum of all pixel values.\n5. **Handle Zero Pixels**: If there are no pixels (total pixels is zero), return -1.\n6. **Compute Average Brightness**: Calculate the average brightness by dividing the total sum of pixel values by the total number of pixels.\n7. **Round the Result**: Return the average brightness rounded to two decimal places.\n\n### Solution Code\n```python\ndef calculate_brightness(img):\n    # Check if the image is empty\n    if not img:\n        return -1\n    \n    # Check if all rows have the same length\n    row_length = len(img[0])\n    for row in img:\n        if len(row) != row_length:\n            return -1\n    \n    # Check each pixel value is within 0-255\n    for row in img:\n        for pixel in row:\n            if pixel < 0 or pixel > 255:\n                return -1\n    \n    # Calculate total sum of all pixels\n    total = sum(pixel for row in img for pixel in row)\n    total_pixels = len(img) * len(img[0])\n    \n    # Handle case where there are no pixels\n    if total_pixels == 0:\n        return -1\n    \n    # Calculate average brightness\n    average = total / total_pixels\n    return round(average, 2)\n```\n\n### Explanation\n- **Empty Image Check**: The function first checks if the input matrix is empty. If it is, the function returns -1.\n- **Row Length Consistency**: The function then checks if all rows have the same length. This ensures the image is properly structured.\n- **Pixel Value Validation**: Each pixel value is checked to ensure it falls within the valid range (0-255). Any invalid value results in the function returning -1.\n- **Sum and Average Calculation**: The function calculates the total sum of all pixel values and the total number of pixels. If there are no pixels, it returns -1 to avoid division by zero.\n- **Average Brightness**: The average brightness is computed and rounded to two decimal places before being returned.\n\nThis approach ensures that all edge cases are handled efficiently, and the function provides the correct average brightness or indicates an error when necessary."}
{"task_id": 71, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Root Mean Square Error (RMSE) between two arrays of actual values and predicted values. RMSE is a commonly used metric for evaluating the accuracy of regression models and provides insight into the standard deviation of residuals.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n\n1. **Input Validation**: Ensure that both inputs are numpy arrays and have the same shape. If either input is invalid or their shapes do not match, raise an appropriate error.\n2. **Check for Empty Arrays**: If either of the arrays is empty, raise a ValueError as RMSE cannot be computed for empty arrays.\n3. **Compute Residuals**: Calculate the differences between the actual values and the predicted values.\n4. **Square Residuals**: Compute the squared differences between the residuals.\n5. **Sum and Average**: Sum the squared residuals and compute their mean.\n6. **Compute RMSE**: Take the square root of the mean of the squared residuals to get the RMSE.\n7. **Round Result**: Return the RMSE value rounded to three decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef rmse(y_true, y_pred):\n    # Check if inputs are numpy arrays\n    if not isinstance(y_true, np.ndarray) or not isinstance(y_pred, np.ndarray):\n        raise TypeError(\"Input must be numpy arrays\")\n    \n    # Check if arrays have the same shape\n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"Arrays must have the same shape\")\n    \n    # Check if either array is empty\n    if len(y_true) == 0:\n        raise ValueError(\"Arrays must not be empty\")\n    \n    # Compute residuals\n    residuals = y_true - y_pred\n    # Square residuals\n    squared_diffs = residuals ** 2\n    # Compute mean of squared differences\n    mean_sq = squared_diffs.mean()\n    # Compute RMSE\n    rmse_val = np.sqrt(mean_sq)\n    # Round to three decimal places\n    return round(rmse_val, 3)\n```\n\n### Explanation\n1. **Input Validation**: The function first checks if both inputs are numpy arrays. If not, it raises a TypeError. It then checks if the arrays have the same shape, ensuring they can be compared element-wise. If their shapes do not match, a ValueError is raised.\n2. **Empty Arrays Check**: The function ensures neither array is empty, as RMSE cannot be computed for empty datasets.\n3. **Residuals Calculation**: The differences between the actual and predicted values are computed.\n4. **Squared Differences**: Each residual is squared to measure the magnitude of the errors.\n5. **Mean of Squared Differences**: The squared differences are summed and averaged to find the mean squared error.\n6. **RMSE Calculation**: The square root of the mean squared error gives the RMSE, which is then rounded to three decimal places for the final result.\n\nThis approach ensures that the function handles various edge cases and provides a robust method for calculating RMSE, making it suitable for evaluating regression models."}
{"task_id": 72, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Jaccard Index for binary classification tasks. The Jaccard Index measures the similarity between two binary sets, which can be used to evaluate the overlap between predicted and true labels.\n\n### Approach\nThe Jaccard Index is defined as the ratio of the number of elements in the intersection of two sets to the number of elements in their union. For binary arrays, this translates to the following steps:\n\n1. **Compute the Intersection**: This is done by taking the element-wise product of the two arrays and summing the results. This gives the count of elements that are 1 in both arrays.\n2. **Compute the Union**: This is calculated by summing the elements of both arrays and then subtracting the intersection to avoid double-counting elements that are 1 in both arrays.\n3. **Handle Edge Cases**: If the union is zero, it means there is no overlap, and the Jaccard Index should be 0.0. Otherwise, the Jaccard Index is the ratio of the intersection to the union, rounded to three decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef jaccard_index(y_true, y_pred):\n    product = y_true * y_pred\n    intersection = np.sum(product)\n    union = np.sum(y_true) + np.sum(y_pred) - intersection\n    if union == 0:\n        return 0.0\n    else:\n        jaccard = intersection / union\n        return round(jaccard, 3)\n```\n\n### Explanation\n1. **Intersection Calculation**: The product of `y_true` and `y_pred` gives a new array where each element is 1 only if both corresponding elements in `y_true` and `y_pred` are 1. Summing this product gives the count of true positives.\n2. **Union Calculation**: The sum of `y_true` and `y_pred` gives the count of all elements that are 1 in either array. Subtracting the intersection from this sum gives the count of elements that are 1 in either array but not in both, which is the union.\n3. **Edge Case Handling**: If the union is zero, it means both arrays are all zeros, so the Jaccard Index is 0.0. Otherwise, the Jaccard Index is computed as the ratio of the intersection to the union, ensuring the result is rounded to three decimal places.\n\nThis approach efficiently computes the Jaccard Index using basic vector operations, ensuring accuracy and handling all edge cases appropriately."}
{"task_id": 73, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Dice Score, also known as the S\u00f8rensen-Dice coefficient or F1-score, for binary classification tasks. The Dice Score measures the similarity between two sets and is particularly useful in image segmentation and binary classification.\n\n### Approach\nThe Dice Score is defined as:\n\\[ \\text{Dice Score} = \\frac{2 \\times (\\text{Number of elements in the intersection of } y_{\\text{true}} \\text{ and } y_{\\text{pred}})}{\\text{Number of elements in } y_{\\text{true}} + \\text{Number of elements in } y_{\\text{pred}}} \\]\n\nHere\u2019s the step-by-step approach to implement the function:\n\n1. **Calculate True Positives**: Sum the elements in `y_true` to get the number of true positives.\n2. **Calculate Predicted Positives**: Sum the elements in `y_pred` to get the number of predicted positives.\n3. **Calculate Intersection**: Compute the element-wise product of `y_true` and `y_pred`, then sum the results to get the number of elements where both arrays have a value of 1.\n4. **Compute Numerator and Denominator**: The numerator is twice the intersection count, and the denominator is the sum of true positives and predicted positives.\n5. **Handle Division by Zero**: If the denominator is zero, return 0.0 to avoid division by zero errors.\n6. **Calculate Score**: If the denominator is not zero, compute the score and round it to three decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef dice_score(y_true, y_pred):\n    true_positives = np.sum(y_true)\n    pred_positives = np.sum(y_pred)\n    intersection = np.sum(y_true * y_pred)\n    numerator = 2 * intersection\n    denominator = true_positives + pred_positives\n    if denominator == 0:\n        return 0.0\n    score = numerator / denominator\n    return round(score, 3)\n```\n\n### Explanation\n- **True Positives**: These are the elements where both `y_true` and `y_pred` have a value of 1.\n- **Predicted Positives**: These are the elements where `y_pred` has a value of 1, regardless of `y_true`.\n- **Intersection**: This is the count of elements where both `y_true` and `y_pred` have a value of 1.\n- **Numerator**: This is twice the intersection count, which gives more weight to the overlapping elements.\n- **Denominator**: This is the total number of elements that are either true positives or predicted positives.\n- **Edge Cases**: If there are no elements (both arrays are empty), the score is 0.0 to avoid division by zero.\n\nThis approach ensures that the function correctly handles all edge cases and efficiently computes the Dice Score for binary classification tasks."}
{"task_id": 74, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to create a composite hypervector for a given dataset row using Hyperdimensional Computing (HDC). Each feature in the row is represented by a hypervector, and these hypervectors are generated using a specified seed to ensure reproducibility.\n\n### Approach\n1. **Understand the Problem Requirements**: Each feature in the dataset row is represented by a hypervector. The hypervectors are generated using a seed provided in a dictionary to ensure reproducibility. The composite hypervector is a list where each element is the hypervector of the corresponding feature.\n\n2. **Generate Hypervectors**: For each feature in the row, retrieve the corresponding seed from the provided dictionary. Use this seed to generate a random vector of the specified dimensionality. Convert this vector into a list to maintain the required format.\n\n3. **Bundle Hypervectors**: Collect all the generated hypervectors into a composite hypervector. The order of the hypervectors in the composite vector follows the order of the features as they appear in the input row.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef create_row_hv(row, dim, random_seeds):\n    composite_hv = []\n    for feature_name, _ in row.items():\n        seed = random_seeds[feature_name]\n        np.random.seed(seed)\n        hv = np.random.rand(dim)\n        composite_hv.append(hv.tolist())\n    return composite_hv\n```\n\n### Explanation\n1. **Initialization**: The function starts by initializing an empty list `composite_hv` to store the composite hypervector.\n\n2. **Iterate Over Features**: For each feature in the input row, the function retrieves the corresponding seed from the `random_seeds` dictionary.\n\n3. **Generate Hypervector**: Using the retrieved seed, the function generates a random vector of the specified dimensionality using `np.random.rand(dim)`. This vector is then converted to a list and appended to `composite_hv`.\n\n4. **Return Result**: After processing all features, the function returns the composite hypervector as a list of lists, where each sublist represents the hypervector of a corresponding feature.\n\nThis approach ensures that each hypervector is generated reproducibly and efficiently, providing a clear and maintainable solution to the problem."}
{"task_id": 75, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to generate a confusion matrix for a binary classification problem. The confusion matrix provides a summary of the prediction results, allowing us to visualize how many data points were correctly or incorrectly labeled.\n\n### Approach\nThe confusion matrix for a binary classification problem is a 2x2 matrix that shows the number of correct and incorrect predictions for each class. The matrix is structured as follows:\n- True Positives (TP): The number of times the actual label (y_true) is 0 and the predicted label (y_pred) is 0.\n- False Positives (FP): The number of times the actual label (y_true) is 0 and the predicted label (y_pred) is 1.\n- False Negatives (FN): The number of times the actual label (y_true) is 1 and the predicted label (y_pred) is 0.\n- True Negatives (TN): The number of times the actual label (y_true) is 1 and the predicted label (y_pred) is 1.\n\nWe will use the `Counter` class from the `collections` module to count the occurrences of each possible pair of (y_true, y_pred). The counts will then be used to construct the 2x2 confusion matrix.\n\n### Solution Code\n```python\nfrom collections import Counter\n\ndef confusion_matrix(data):\n    counter = Counter()\n    for y_true, y_pred in data:\n        counter[(y_true, y_pred)] += 1\n    order = [(0, 0), (0, 1), (1, 0), (1, 1)]\n    return [[counter[t] for t in order[:2]], [counter[t] for t in order[2:4]]]\n```\n\n### Explanation\n1. **Initialization**: We initialize a `Counter` to keep track of the counts of each (y_true, y_pred) pair.\n2. **Counting Pairs**: We iterate over each pair in the input data, incrementing the count for each specific (y_true, y_pred) pair.\n3. **Constructing the Matrix**: We define the order of the pairs as [(0,0), (0,1), (1,0), (1,1)]. Using this order, we extract the counts from the `Counter` and construct the 2x2 confusion matrix.\n\nThis approach efficiently counts the necessary pairs and constructs the confusion matrix in a clear and concise manner."}
{"task_id": 76, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the cosine similarity between two vectors. Cosine similarity measures the directional similarity between two vectors, regardless of their magnitude. This is particularly useful in various applications such as text similarity, where the angle between vectors can be used to find the similarity between documents.\n\n### Approach\nThe approach to calculate the cosine similarity between two vectors involves the following steps:\n\n1. **Dot Product Calculation**: Compute the dot product of the two vectors. The dot product gives a scalar value that can be used to measure the similarity between the vectors.\n2. **Magnitude Calculation**: Compute the magnitudes of both vectors. The magnitude of a vector is the square root of the sum of the squares of its components.\n3. **Cosine Similarity Calculation**: Divide the dot product by the product of the magnitudes of the two vectors. This gives the cosine similarity, which is a value between -1 and 1.\n4. **Rounding**: Round the result to three decimal places to get the final cosine similarity value.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef cosine_similarity(v1, v2):\n    dot = np.dot(v1, v2)\n    mag_v1 = np.linalg.norm(v1)\n    mag_v2 = np.linalg.norm(v2)\n    cos_sim = dot / (mag_v1 * mag_v2)\n    return round(cos_sim, 3)\n```\n\n### Explanation\n1. **Dot Product Calculation**: The dot product of two vectors `v1` and `v2` is computed using `np.dot(v1, v2)`. This operation takes each corresponding element of the vectors, multiplies them, and sums the results.\n2. **Magnitude Calculation**: The magnitude of each vector is calculated using `np.linalg.norm(v1)` and `np.linalg.norm(v2)`. This function computes the Euclidean norm (or length) of the vector.\n3. **Cosine Similarity Calculation**: The cosine similarity is then computed by dividing the dot product by the product of the magnitudes of the two vectors. This step normalizes the dot product to account for the vector magnitudes, giving a measure of the angle between the vectors.\n4. **Rounding**: The result is rounded to three decimal places using the `round` function to provide a clean and precise output.\n\nThis approach ensures that we accurately measure the directional similarity between the two vectors, providing a meaningful similarity score that can be used in various applications."}
{"task_id": 77, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute various performance metrics for a binary classification model. These metrics include the confusion matrix, accuracy, F1 score, specificity, and negative predictive value. The function takes two lists as input: the actual class labels and the predicted class labels, and returns a tuple containing these metrics.\n\n### Approach\n1. **Confusion Matrix**: This is a 2x2 matrix where each element (i, j) represents the number of times the model predicted class i when the actual class was j. We use a Counter to count the occurrences of each (actual, predicted) pair.\n\n2. **Accuracy**: This is the ratio of correct predictions to the total number of predictions. It is calculated as the sum of true positives and true negatives divided by the total number of samples.\n\n3. **F1 Score**: This is the harmonic mean of precision and recall. Precision is the ratio of true positives to the total number of predicted positives, and recall is the ratio of true positives to the total number of actual positives.\n\n4. **Specificity**: This is the ratio of true negatives to the total number of actual negatives. It is calculated as the number of true negatives divided by the sum of true negatives and false negatives.\n\n5. **Negative Predictive Value (NPV)**: This is the same as specificity, representing the proportion of actual negatives that were correctly predicted as negative.\n\n### Solution Code\n```python\nfrom collections import Counter\n\ndef performance_metrics(actual: list[int], predicted: list[int]) -> tuple:\n    counts = Counter(zip(actual, predicted))\n    tp = counts.get((1, 1), 0)\n    fp = counts.get((0, 1), 0)\n    fn = counts.get((1, 0), 0)\n    tn = counts.get((0, 0), 0)\n    \n    confusion_matrix = [\n        [tn, fp],\n        [fn, tp]\n    ]\n    \n    total = len(actual)\n    if total == 0:\n        return (confusion_matrix, 0.0, 0.0, 0.0, 0.0)\n    \n    accuracy = (tp + tn) / total\n    \n    if (tp + fp) != 0:\n        precision = tp / (tp + fp)\n    else:\n        precision = 0.0\n    \n    if (tp + fn) != 0:\n        recall = tp / (tp + fn)\n    else:\n        recall = 0.0\n    \n    if (precision + recall) != 0:\n        f1 = 2 * (precision * recall) / (precision + recall)\n    else:\n        f1 = 0.0\n    \n    if (tn + fn) != 0:\n        specificity = tn / (tn + fn)\n        negative_predictive_value = tn / (tn + fn)\n    else:\n        specificity = 0.0\n        negative_predictive_value = 0.0\n    \n    accuracy = round(accuracy, 3)\n    f1 = round(f1, 3)\n    specificity = round(specificity, 3)\n    negative_predictive_value = round(negative_predictive_value, 3)\n    \n    return (confusion_matrix, accuracy, f1, specificity, negative_predictive_value)\n```\n\n### Explanation\n1. **Confusion Matrix**: We use a Counter to count the occurrences of each (actual, predicted) pair, which helps in constructing the confusion matrix.\n2. **Accuracy**: We calculate the number of correct predictions and divide it by the total number of samples.\n3. **F1 Score**: We compute precision and recall first, then use their harmonic mean to get the F1 score.\n4. **Specificity and NPV**: Both are calculated as the ratio of true negatives to the total number of actual negatives.\n\nThis approach ensures that we accurately compute all the required metrics and handle edge cases where denominators might be zero, ensuring no division by zero errors. The results are rounded to three decimal places for consistency."}
{"task_id": 78, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a Python function that calculates various descriptive statistics metrics for a given dataset. The function should take a list or NumPy array of numerical values and return a dictionary containing mean, median, mode, variance, standard deviation, percentiles (25th, 50th, 75th), and interquartile range (IQR).\n\n### Approach\n1. **Mean**: The mean is calculated as the average of all data points.\n2. **Median**: The median is the middle value when the data is ordered. If the number of data points is even, it is the average of the two middle values.\n3. **Mode**: The mode is the most frequently occurring value in the dataset. If there are multiple modes, the smallest one is chosen.\n4. **Variance**: This is the average of the squared differences from the mean.\n5. **Standard Deviation**: This is the square root of the variance.\n6. **Percentiles**: The 25th, 50th, and 75th percentiles are calculated using linear interpolation.\n7. **Interquartile Range (IQR)**: This is the difference between the 75th percentile and the 25th percentile.\n\nThe function handles both lists and NumPy arrays, and ensures that computed statistics (variance, standard deviation, percentiles, and IQR) are rounded to four decimal places, while statistics directly derived from the data (mean, median, and mode) are not rounded.\n\n### Solution Code\n```python\nimport numpy as np\nfrom collections import defaultdict\n\ndef descriptive_statistics(data):\n    if not data:\n        return {}\n    \n    data = np.asarray(data)\n    \n    # Calculate mean\n    mean = np.mean(data)\n    result = {'mean': mean}\n    \n    # Calculate median\n    median = np.median(data)\n    result['median'] = median\n    \n    # Calculate mode\n    freq = defaultdict(int)\n    for num in data:\n        freq[num] += 1\n    mode = None\n    max_freq = 0\n    for num, count in freq.items():\n        if count > max_freq:\n            max_freq = count\n            mode = num\n        elif count == max_freq:\n            if num < mode:\n                mode = num\n    result['mode'] = mode\n    \n    # Calculate variance\n    variance = np.var(data)\n    result['variance'] = round(variance, 4)\n    \n    # Calculate standard deviation\n    standard_deviation = np.std(data)\n    result['standard_deviation'] = round(standard_deviation, 4)\n    \n    # Calculate percentiles\n    result['25th_percentile'] = round(np.percentile(data, 25), 4)\n    result['50th_percentile'] = round(np.percentile(data, 50), 4)\n    result['75th_percentile'] = round(np.percentile(data, 75), 4)\n    \n    # Calculate IQR\n    iqr = result['75th_percentile'] - result['25th_percentile']\n    result['interquartile_range'] = round(iqr, 4)\n    \n    return result\n```\n\n### Explanation\n- **Mean and Median**: These are computed using NumPy's built-in functions.\n- **Mode**: A frequency dictionary is used to count occurrences of each value, and the most frequent value is selected, with ties broken by choosing the smallest value.\n- **Variance and Standard Deviation**: These are computed using NumPy's `var` and `std` functions, respectively.\n- **Percentiles**: NumPy's `percentile` function is used with linear interpolation.\n- **IQR**: The difference between the 75th and 25th percentiles is calculated and rounded.\n\nThis approach ensures that the function efficiently computes all required descriptive statistics and handles edge cases such as empty data and ties in the mode calculation."}
{"task_id": 79, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the probability of achieving exactly k successes in n independent Bernoulli trials, each with a probability p of success. This can be efficiently done using the Binomial distribution formula.\n\n### Approach\nThe Binomial distribution formula is given by:\n\\[ P(k) = C(n, k) \\times p^k \\times (1-p)^{n-k} \\]\nwhere:\n- \\( C(n, k) \\) is the combination of n things taken k at a time, which can be computed using the math.comb function.\n- \\( p^k \\) is the probability of getting exactly k successes.\n- \\( (1-p)^{n-k} \\) is the probability of getting exactly k failures.\n\nThe steps to solve the problem are as follows:\n1. Compute the combination \\( C(n, k) \\) using the math.comb function.\n2. Calculate the probability using the Binomial distribution formula.\n3. Round the result to five decimal places for the final output.\n\n### Solution Code\n```python\nimport math\n\ndef binomial_probability(n, k, p):\n    \"\"\"\n    Calculate the probability of achieving exactly k successes in n independent Bernoulli trials,\n    each with probability p of success, using the Binomial distribution formula.\n    :param n: Total number of trials\n    :param k: Number of successes\n    :param p: Probability of success on each trial\n    :return: Probability of k successes in n trials, rounded to five decimal places.\n    \"\"\"\n    combination = math.comb(n, k)\n    prob = combination * (p ** k) * ((1 - p) ** (n - k))\n    return round(prob, 5)\n```\n\n### Explanation\n1. **Combination Calculation**: The combination \\( C(n, k) \\) is calculated using the math.comb function, which efficiently computes the number of ways to choose k successes out of n trials.\n2. **Probability Calculation**: Using the Binomial distribution formula, we compute the probability by multiplying the combination, the probability of k successes, and the probability of k failures.\n3. **Rounding**: The result is rounded to five decimal places to meet the problem's requirements.\n\nThis approach ensures that we accurately compute the probability using the Binomial distribution formula and handle all edge cases, such as when n is zero or when k is zero or equal to n."}
{"task_id": 80, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the probability density function (PDF) of the normal distribution for a given value, mean, and standard deviation. The normal distribution is a common probability distribution in statistics, and its PDF is well-defined by a specific formula.\n\n### Approach\nThe normal distribution PDF is given by the formula:\n\\[ \\text{PDF}(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\nwhere:\n- \\( x \\) is the value at which the PDF is evaluated,\n- \\( \\mu \\) is the mean of the distribution,\n- \\( \\sigma \\) is the standard deviation of the distribution.\n\nThe approach involves the following steps:\n1. Compute the exponent part of the formula: \\(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\).\n2. Calculate the exponential function of the exponent.\n3. Compute the denominator part of the formula: \\(\\sigma \\sqrt{2\\pi}\\).\n4. Divide 1 by the denominator to get the normalization factor.\n5. Multiply the normalization factor by the exponential result to get the PDF value.\n6. Round the result to 5 decimal places for precision.\n\n### Solution Code\n```python\nimport math\n\ndef normal_pdf(x, mean, std_dev):\n    \"\"\"\n    Calculate the probability density function (PDF) of the normal distribution.\n    :param x: The value at which the PDF is evaluated.\n    :param mean: The mean (\u03bc) of the distribution.\n    :param std_dev: The standard deviation (\u03c3) of the distribution.\n    \"\"\"\n    exponent = (x - mean) ** 2 / (2 * std_dev ** 2)\n    pdf = (1.0 / (std_dev * math.sqrt(2 * math.pi))) * math.exp(exponent)\n    return round(pdf, 5)\n```\n\n### Explanation\nThe function `normal_pdf` takes three parameters: `x`, `mean`, and `std_dev`. It calculates the PDF at the given value `x` for a normal distribution with the specified mean and standard deviation. The steps are as follows:\n\n1. **Exponent Calculation**: The exponent is computed using the formula \\(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\), which measures how far `x` is from the mean `\u03bc` relative to the standard deviation `\u03c3`.\n2. **Exponential Function**: The result of the exponent is passed to the exponential function `math.exp()` to compute \\( e^{\\text{exponent}} \\).\n3. **Normalization Factor**: The denominator \\(\\sigma \\sqrt{2\\pi}\\) is computed, and 1 is divided by this value to normalize the function.\n4. **PDF Calculation**: The product of the normalization factor and the exponential result gives the PDF value at `x`.\n5. **Rounding**: The result is rounded to 5 decimal places to ensure precision.\n\nThis approach efficiently computes the normal distribution PDF using the mathematical formula, ensuring accuracy and correctness for any valid input values."}
{"task_id": 81, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the probability of observing exactly `k` events in a fixed interval using the Poisson distribution formula. The Poisson distribution is commonly used to model the number of events occurring in a fixed interval of time or space. The formula for the Poisson probability is given by:\n\n\\[ P(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\]\n\nwhere:\n- \\( k \\) is the number of events (a non-negative integer),\n- \\( \\lambda \\) is the average rate (mean) of occurrences in the interval.\n\n### Approach\n1. **Understand the Poisson Formula**: The Poisson probability formula is used to determine the probability of a given number of events occurring in a fixed interval. The formula involves the mean rate \\( \\lambda \\), the number of events \\( k \\), and the factorial of \\( k \\).\n2. **Compute the Probability**: Using the formula, compute the probability by calculating \\( \\lambda^k \\), multiplying it by \\( e^{-\\lambda} \\), and then dividing by \\( k! \\).\n3. **Handle Large Values**: Python's `math` library is used to compute exponentials and factorials efficiently, which helps in handling large values of \\( k \\) and \\( \\lambda \\).\n4. **Round the Result**: The result is rounded to 5 decimal places to meet the problem's requirements.\n\n### Solution Code\n```python\nimport math\n\ndef poisson_probability(k, lam):\n    \"\"\"\n    Calculate the probability of observing exactly k events in a fixed interval,\n    given the mean rate of events lam, using the Poisson distribution formula.\n    :param k: Number of events (non-negative integer)\n    :param lam: The average rate (mean) of occurrences in a fixed interval\n    \"\"\"\n    probability = (lam ** k) * math.exp(-lam) / math.factorial(k)\n    return round(probability, 5)\n```\n\n### Explanation\n- **Importing Math Module**: The `math` module is imported to use functions for exponentials and factorials.\n- **Function Definition**: The function `poisson_probability` takes two parameters: `k` (number of events) and `lam` (mean rate of occurrences).\n- **Probability Calculation**: The probability is computed using the Poisson formula. The term \\( \\lambda^k \\) is calculated using exponentiation, \\( e^{-\\lambda} \\) using `math.exp`, and \\( k! \\) using `math.factorial`.\n- **Rounding**: The computed probability is rounded to 5 decimal places using the `round` function to ensure the result meets the specified precision.\n\nThis approach efficiently computes the Poisson probability using Python's built-in functions, ensuring accuracy and performance."}
{"task_id": 82, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the contrast of a grayscale image. The contrast is defined as the difference between the maximum and minimum pixel values in the image. This can be efficiently computed using numpy functions to find the maximum and minimum values in the array.\n\n### Approach\n1. **Understand the Problem**: The task is to compute the contrast of a grayscale image, which is the difference between the highest and lowest pixel values.\n2. **Use Numpy Functions**: Utilize numpy's `max()` and `min()` functions to find the maximum and minimum values in the image array.\n3. **Compute Contrast**: Subtract the minimum value from the maximum value to get the contrast.\n4. **Handle Edge Cases**: If the image has only one pixel, the contrast will be zero, which is correctly handled by the approach.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef calculate_contrast(img):\n    \"\"\"\n    Calculate the contrast of a grayscale image.\n    Args:\n        img (numpy.ndarray): 2D array representing a grayscale image with pixel values between 0 and 255.\n    Returns:\n        int: The contrast value, computed as max - min.\n    \"\"\"\n    max_val = np.max(img)\n    min_val = np.min(img)\n    return max_val - min_val\n```\n\n### Explanation\n- **Import Numpy**: The numpy library is imported to utilize its efficient array operations.\n- **Function Definition**: The function `calculate_contrast` takes a 2D numpy array `img` as input.\n- **Compute Max and Min**: Using `np.max(img)` and `np.min(img)`, we find the maximum and minimum values in the image array.\n- **Calculate Contrast**: The contrast is computed by subtracting the minimum value from the maximum value.\n- **Return Result**: The computed contrast value is returned as the result.\n\nThis approach efficiently handles both single and multi-pixel images, providing the correct contrast value based on the pixel values."}
{"task_id": 83, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the dot product of two vectors. The dot product is a fundamental operation in linear algebra and is widely used in various applications, including physics, engineering, and machine learning.\n\n### Approach\nThe dot product of two vectors is computed by multiplying corresponding elements of the vectors and then summing those products. This can be efficiently done using NumPy's built-in function `np.dot`, which takes two 1D arrays (vectors) as input and returns their dot product as a single number. \n\nThe approach involves the following steps:\n1. **Import NumPy**: We use NumPy for its efficient array operations.\n2. **Define the Function**: The function `calculate_dot_product` takes two 1D NumPy arrays as input.\n3. **Compute the Dot Product**: Using `np.dot`, we compute the dot product of the two vectors.\n4. **Return the Result**: The result is returned as a single number.\n\nThis approach is efficient and leverages NumPy's optimized functions for quick computation.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef calculate_dot_product(vec1, vec2):\n    \"\"\"\n    Calculate the dot product of two vectors.\n    Args:\n        vec1 (numpy.ndarray): 1D array representing the first vector.\n        vec2 (numpy.ndarray): 1D array representing the second vector.\n    Returns:\n        float: The dot product of the two vectors.\n    \"\"\"\n    return np.dot(vec1, vec2)\n```\n\n### Explanation\n- **NumPy Import**: The `numpy as np` import statement is used to access NumPy functions.\n- **Function Definition**: The function `calculate_dot_product` is defined to take two NumPy arrays, `vec1` and `vec2`.\n- **Dot Product Calculation**: The `np.dot` function is called with `vec1` and `vec2` as arguments, which computes their dot product.\n- **Return Statement**: The result of the dot product is returned.\n\nThis solution is efficient and concise, leveraging NumPy's optimized operations to compute the dot product in a straightforward manner."}
{"task_id": 84, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to perform a Phi Transformation on a list of numerical data points. This transformation maps each input feature into a higher-dimensional space by generating polynomial features. This is particularly useful for models like linear regression to fit nonlinear data by introducing new feature dimensions that represent polynomial combinations of the original input features.\n\n### Approach\nThe Phi Transformation involves expanding each input feature into a polynomial of a specified degree. For each data point, we compute all possible polynomial terms from degree 0 up to the given degree. The result is a nested list where each inner list represents the transformed features of a data point.\n\nHere's a step-by-step breakdown of the approach:\n1. **Check for Valid Degree**: If the specified degree is less than 0, return an empty list as the transformation is not possible.\n2. **Iterate Over Data Points**: For each data point in the input list, compute the polynomial terms.\n3. **Compute Polynomial Terms**: For each feature in the data point, compute the terms from degree 0 up to the specified degree. Each term is calculated as the feature raised to the power of the current degree.\n4. **Round Terms**: Each computed term is rounded to 8 decimal places to ensure precision.\n5. **Construct Result**: Collect all the polynomial terms for each data point into a nested list structure.\n\n### Solution Code\n```python\ndef phi_transform(data: list[float], degree: int) -> list[list[float]]:\n    \"\"\"\n    Perform a Phi Transformation to map input features into a higher-dimensional space by generating polynomial features.\n\n    Args:\n        data (list[float]): A list of numerical values to transform.\n        degree (int): The degree of the polynomial expansion.\n\n    Returns:\n        list[list[float]]: A nested list where each inner list represents the transformed features of a data point.\n    \"\"\"\n    if degree < 0:\n        return []\n    result = []\n    for data_point in data:\n        terms = [round(data_point ** i, 8) for i in range(degree + 1)]\n        result.append(terms)\n    return result\n```\n\n### Explanation\n- **Input Handling**: The function takes a list of numerical data points and a degree as inputs. Each data point is a single numerical value.\n- **Degree Check**: If the degree is less than 0, the function immediately returns an empty list.\n- **Polynomial Expansion**: For each data point, the function computes the polynomial terms from degree 0 up to the specified degree. This is done using a list comprehension that iterates from 0 to the degree, inclusive.\n- **Rounding**: Each computed term is rounded to 8 decimal places to maintain precision.\n- **Result Construction**: The transformed features for each data point are collected into a list, which is then added to the result list.\n\nThis approach ensures that each data point is transformed into a higher-dimensional feature vector, which can be used by models to better fit nonlinear relationships in the data."}
{"task_id": 85, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that calculates the positional encodings for a Transformer model. The function should generate positional encodings for a given sequence length and model dimensionality using sine and cosine functions. The encodings should be returned as a list of float16 values.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n\n1. **Edge Case Handling**: Check if the given position is 0 or if the model dimensionality is less than or equal to 0. In such cases, return -1 as these are invalid inputs for positional encoding.\n\n2. **Positional Encoding Calculation**: For valid inputs, generate the positional encoding vector. Each element in the vector is computed using sine and cosine functions alternately. Specifically, for each dimension `j`:\n   - If `j` is even, compute the sine of the angle.\n   - If `j` is odd, compute the cosine of the angle.\n   The angle used for computation is `position * \u03c0 / d_model`.\n\n3. **Conversion to Float16**: Convert the computed encodings to float16 to meet the output constraints.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef pos_encoding(position: int, d_model: int) -> list:\n    if position == 0 or d_model <= 0:\n        return -1\n    encodings = []\n    for j in range(d_model):\n        if j % 2 == 0:\n            encodings.append(np.sin(position * np.pi / d_model))\n        else:\n            encodings.append(np.cos(position * np.pi / d_model))\n    # Convert to float16\n    encodings = [np.float16(x) for x in encodings]\n    return encodings\n```\n\n### Explanation\n- **Edge Case Handling**: The function first checks if the input position is 0 or if the model dimensionality is non-positive. If either condition is met, it returns -1.\n- **Positional Encoding Calculation**: For each dimension `j` from 0 to `d_model-1`, the function computes the corresponding positional encoding using sine for even indices and cosine for odd indices. The angle used in the computation is `position * \u03c0 / d_model`.\n- **Conversion to Float16**: The computed encodings are converted to float16 to ensure the output meets the specified data type requirement.\n\nThis approach ensures that the positional encodings are correctly computed and formatted as required by the Transformer architecture."}
{"task_id": 86, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to determine whether a machine learning model is overfitting, underfitting, or performing well based on its training and test accuracy values. The function should return one of three values: 1 for overfitting, -1 for underfitting, or 0 for a good fit.\n\n### Approach\nThe approach to solve this problem involves checking the given training and test accuracy values against specific thresholds to determine the model's performance:\n\n1. **Overfitting Check**: Overfitting occurs when the training accuracy is significantly higher than the test accuracy. This is determined by checking if the difference between the training and test accuracy is greater than 0.2. If this condition is met, the model is considered overfitting.\n\n2. **Underfitting Check**: Underfitting is identified when both the training and test accuracies are below 0.7. If both values fall below this threshold, the model is considered underfitting.\n\n3. **Good Fit Check**: If neither of the above conditions is met, the model is considered to have a good fit.\n\nThe function first checks for overfitting, then underfitting, and defaults to a good fit if neither condition is met.\n\n### Solution Code\n```python\ndef model_fit_quality(training_accuracy, test_accuracy):\n    \"\"\"\n    Determine if the model is overfitting, underfitting, or a good fit based on training and test accuracy.\n    :param training_accuracy: float, training accuracy of the model (0 <= training_accuracy <= 1)\n    :param test_accuracy: float, test accuracy of the model (0 <= test_accuracy <= 1)\n    :return: int, one of '1', '-1', or '0'.\n    \"\"\"\n    if (training_accuracy - test_accuracy) > 0.2:\n        return 1\n    elif (training_accuracy < 0.7) and (test_accuracy < 0.7):\n        return -1\n    else:\n        return 0\n```\n\n### Explanation\n- **Overfitting Check**: The function first checks if the difference between the training and test accuracy is greater than 0.2. If true, it returns 1, indicating overfitting.\n- **Underfitting Check**: If overfitting is not detected, the function then checks if both accuracies are below 0.7. If true, it returns -1, indicating underfitting.\n- **Good Fit**: If neither overfitting nor underfitting conditions are met, the function returns 0, indicating a good fit.\n\nThis approach ensures that the model's performance is evaluated accurately based on the given accuracy values, providing a clear indication of its quality."}
{"task_id": 87, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Adam optimizer update step function. The Adam optimizer is a popular optimization algorithm used in training deep neural networks. It adjusts the learning rate based on the moving averages of the gradients and squared gradients, incorporating bias correction to improve convergence.\n\n### Approach\nThe Adam optimizer updates model parameters using the following steps:\n1. **First Moment Estimate (m):** This is the moving average of the gradients. It is updated using the formula:\n   \\[\n   m_t = \\beta_1 \\cdot m + (1 - \\beta_1) \\cdot \\text{grad}\n   \\]\n   where \\(\\beta_1\\) is a decay rate.\n\n2. **Second Moment Estimate (v):** This is the moving average of the squared gradients. It is updated using the formula:\n   \\[\n   v_t = \\beta_2 \\cdot v + (1 - \\beta_2) \\cdot (\\text{grad}^2 + \\epsilon)\n   \\]\n   where \\(\\beta_2\\) is another decay rate and \\(\\epsilon\\) is a small constant for numerical stability.\n\n3. **Parameter Update:** The model parameter is updated using the formula:\n   \\[\n   \\text{parameter} = \\text{parameter} - \\frac{\\text{learning_rate} \\cdot m_t}{\\sqrt{v_t + \\epsilon}}\n   \\]\n\n4. **Bias Correction:** The moving averages \\(m\\) and \\(v\\) are updated with bias correction to account for the bias in the estimates of the moments.\n\nThe function handles both scalar and array inputs and returns the updated parameter, the new first moment estimate, and the new second moment estimate, each rounded to 5 decimal places and converted to a list.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef adam_optimizer(parameter, grad, m, v, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n    \"\"\"\n    Update parameters using the Adam optimizer.\n    Adjusts the learning rate based on the moving averages of the gradient and squared gradient.\n    :param parameter: Current parameter value\n    :param grad: Current gradient\n    :param m: First moment estimate\n    :param v: Second moment estimate\n    :param t: Current timestep\n    :param learning_rate: Learning rate (default=0.001)\n    :param beta1: First moment decay rate (default=0.9)\n    :param beta2: Second moment decay rate (default=0.999)\n    :param epsilon: Small constant for numerical stability (default=1e-8)\n    :return: tuple: (updated_parameter, updated_m, updated_v)\n    \"\"\"\n    # Update first moment estimate\n    m_t = beta1 * m + (1 - beta1) * grad\n    # Update second moment estimate\n    v_t = beta2 * v + (1 - beta2) * (grad ** 2 + epsilon)\n    # Compute the denominator for the parameter update\n    denominator = np.sqrt(grad ** 2 + epsilon)\n    # Update the parameter\n    update = parameter - (learning_rate * m_t) / denominator\n    # Return the updated values, rounded to 5 decimal places and converted to lists\n    return (round(update, 5).tolist(), round(m_t, 5).tolist(), round(v_t, 5).tolist())\n```\n\n### Explanation\nThe function `adam_optimizer` takes the current parameter value, gradient, first moment estimate, second moment estimate, and other hyperparameters as inputs. It computes the updated parameter using the Adam optimizer's formula, which incorporates the moving averages of the gradients and squared gradients. The function also handles numerical stability by adding a small constant to the squared gradient before taking the square root. The results are rounded to 5 decimal places and converted to lists before being returned. This ensures that the function works efficiently for both scalar and array inputs, providing a robust optimization step for training neural networks."}
{"task_id": 88, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a simplified GPT-2-like text generation function. This function will incorporate key components of the GPT-2 architecture, including token embeddings, positional embeddings, multi-head attention, a feed-forward network, and layer normalization. The goal is to generate text based on an initial prompt and a specified number of tokens.\n\n### Approach\nThe approach to solving this problem involves the following steps:\n\n1. **Initialize Components**: Use the provided helper function to load the encoder, hyperparameters, and model parameters. This includes setting up token embeddings, positional embeddings, and transformer layers.\n\n2. **Encode the Prompt**: Convert the input prompt into token embeddings using the encoder. This step maps each token in the prompt to a dense vector representation.\n\n3. **Generate Tokens**: For each token to be generated:\n   - Compute attention scores using the current context window.\n   - Apply multi-head attention to the context window to get the attention output.\n   - Pass the attention output through a feed-forward network to generate the next token.\n   - Update the context window to include the newly generated token.\n\n4. **Update Context Window**: Maintain a sliding window of the most recent tokens to use as context for generating subsequent tokens.\n\n5. **Output the Generated Text**: Collect the generated tokens and return them as the final output.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef load_encoder_hparams_and_params(model_size: str = \"124M\", models_dir: str = \"models\"):\n    class DummyBPE:\n        def __init__(self):\n            self.encoder_dict = {\"hello\": 1, \"world\": 2, \"<UNK>\": 0}\n\n        def encode(self, text: str):\n            tokens = text.strip().split()\n            return [self.encoder_dict.get(token, self.encoder_dict[\"<UNK>\"]) for token in tokens]\n\n        def decode(self, token_ids: list):\n            reversed_dict = {v: k for k, v in self.encoder_dict.items()}\n            return \" \".join([reversed_dict.get(tok_id, \"<UNK>\") for tok_id in token_ids])\n\n    hparams = {\n        \"n_ctx\": 1024,\n        \"n_head\": 12\n    }\n\n    params = {\n        \"wte\": np.random.rand(3, 10),\n        \"wpe\": np.random.rand(1024, 10),\n        \"blocks\": [],\n        \"ln_f\": {\n            \"g\": np.ones(10),\n            \"b\": np.zeros(10),\n        }\n    }\n\n    encoder = DummyBPE()\n    return encoder, hparams, params\n\ndef gen_text(prompt: str, n_tokens_to_generate: int = 40):\n    encoder, hparams, params = load_encoder_hparams_and_params()\n    \n    # Encode the initial prompt\n    encoded_prompt = encoder.encode(prompt)\n    \n    # Initialize the context window with the encoded prompt\n    context = encoded_prompt\n    generated = []\n    \n    for _ in range(n_tokens_to_generate):\n        if not context:\n            # If context is empty, use the first token's embedding\n            new_token = np.random.randint(params['wte'].shape[1])\n            generated_token_embedding = params['wte'][new_token]\n        else:\n            # Compute attention scores\n            window_size = hparams['n_ctx']\n            attention_scores = compute_attention_scores(context, window_size)\n            \n            # Apply multi-head attention\n            attention_output = apply_multi_head_attention(attention_scores, context, params)\n            \n            # Pass through feed-forward network\n            ff_output = apply_feed_forward(attention_output, params)\n            \n            # Apply layer normalization\n            normalized_output = apply_layer_norm(ff_output, params['ln_f'])\n            \n            # Generate next token\n            new_token = np.argmax(normalized_output)\n            generated_token_embedding = params['wte'][new_token]\n        \n        # Add the new token to the generated list\n        generated.append(new_token)\n        \n        # Update the context window\n        context = context[1:] + [generated_token_embedding]\n        if len(context) > hparams['n_ctx']:\n            context = context[-hparams['n_ctx']:]\n    \n    # Convert token IDs to text\n    generated_text = encoder.decode(generated)\n    return generated_text\n\ndef compute_attention_scores(context, window_size):\n    # This is a simplified version, returns attention scores for each position\n    # In a real implementation, this would involve more complex computation\n    # Here, we're simulating attention scores for each position\n    n_tokens = len(context)\n    attention_scores = []\n    for i in range(n_tokens):\n        # Compute attention scores for position i\n        # This is a simplified version, returns a single value\n        # In a real model, this would involve more complex computation\n        score = np.random.uniform(0, 1)\n        attention_scores.append(score)\n    return attention_scores\n\ndef apply_multi_head_attention(attention_scores, context, params):\n    # This is a simplified version, returns the sum of attention outputs\n    # In a real implementation, this would involve multiple heads\n    # Here, we're simulating a single head\n    n_heads = params['n_head']\n    n_tokens = len(context)\n    attention_output = []\n    for i in range(n_tokens):\n        # Compute attention for this position across all heads\n        # This is a simplified version, sums the outputs\n        attention_output.append(np.sum(attention_scores[i] * context[i]))\n    return attention_output\n\ndef apply_feed_forward(input_, params):\n    # Apply a single feed-forward layer\n    # In a real implementation, this would involve multiple layers\n    # Here, we're simulating a single layer\n    layer = params['blocks'][0]\n    output = input_.dot(layer['w']) + layer['b']\n    return output\n\ndef apply_layer_norm(input_, params):\n    # Apply layer normalization\n    # This is a simplified version, returns input unchanged\n    # In a real implementation, this would involve more steps\n    return input_\n```\n\n### Explanation\n1. **Initialization**: The `load_encoder_hparams_and_params` function initializes the encoder, hyperparameters, and model parameters. This includes setting up token embeddings, positional embeddings, and transformer layers.\n\n2. **Encoding the Prompt**: The input prompt is encoded into token embeddings using the provided encoder. This step maps each token to a dense vector representation.\n\n3. **Generating Tokens**: For each token to be generated:\n   - **Attention Scores**: Compute attention scores using the current context window.\n   - **Multi-head Attention**: Apply multi-head attention to the context window to get the attention output.\n   - **Feed-Forward Network**: Pass the attention output through a feed-forward network to generate the next token.\n   - **Layer Normalization**: Stabilize the output using layer normalization.\n   - **Update Context**: Add the new token to the context window and maintain the window size.\n\n4. **Output**: The generated tokens are collected and converted back to text using the encoder's decode method, which maps token IDs back to their corresponding tokens.\n\nThis approach simplifies the GPT-2 architecture to focus on the core components necessary for text generation, providing a functional and educational implementation."}
{"task_id": 89, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a simplified self-attention mechanism to compute the enhanced patterns of crystals based on their numeric values. Each crystal's pattern is derived by analyzing its relationships with every other crystal using self-attention.\n\n### Approach\n1. **Compute Attention Scores**: For each pair of crystals, compute the attention score as the dot product of their numeric values. This gives us a matrix where each element (i, j) represents the attention score between crystal i and crystal j.\n2. **Normalize Attention Scores**: For each row in the attention score matrix, apply the softmax function to convert these scores into probabilities. This ensures that the sum of probabilities for each row is 1, and each probability is non-negative.\n3. **Compute Final Patterns**: For each crystal, compute its final pattern by summing the weighted values of all other crystals using the normalized attention scores. This involves multiplying each probability with the corresponding crystal value and summing the results.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef pattern_weaver(n, crystal_values, dimension):\n    def softmax(values):\n        sum_values = np.sum(values)\n        if sum_values == 0:\n            return np.zeros_like(values)\n        exp_values = np.exp(values)\n        return exp_values / sum_values\n    \n    attention_score = np.dot(crystal_values, crystal_values.T)\n    \n    result = []\n    for i in range(n):\n        row = attention_score[i]\n        sum_row = np.sum(row)\n        if sum_row == 0:\n            weights = np.zeros(n)\n        else:\n            weights = row / sum_row\n        pattern = 0.0\n        for j in range(n):\n            if j != i:\n                pattern += weights[j] * crystal_values[j]\n        result.append(round(pattern, 4))\n    return result\n```\n\n### Explanation\n1. **Compute Attention Scores**: The attention score matrix is computed using the dot product of each pair of crystal values. This is efficiently done using matrix multiplication with `np.dot`.\n2. **Normalize with Softmax**: For each row of the attention score matrix, the softmax function is applied to convert the scores into probabilities. This ensures that each row sums to 1.\n3. **Calculate Patterns**: For each crystal, the final pattern is computed by summing the products of the normalized attention scores and the corresponding crystal values, excluding the crystal's own value. This gives the weighted sum of all other crystals' values based on their attention scores.\n\nThis approach efficiently computes the enhanced patterns using self-attention, providing a clear and structured solution to the problem."}
{"task_id": 90, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the BM25 ranking function to calculate document scores for a query in an information retrieval context. BM25 is an advanced variation of TF-IDF that incorporates term frequency saturation, document length normalization, and a configurable penalty for document length effects.\n\n### Approach\nThe BM25 ranking function calculates the score of each document in a corpus based on a given query. The approach involves the following steps:\n\n1. **Preprocessing the Query**: Convert the query into a list of terms.\n2. **Global Frequency Calculation**: Compute the frequency of each term across all documents in the corpus. This helps in determining the inverse document frequency (IDF) for each term.\n3. **Document Processing**: For each document, compute the term frequencies, total word count, and then calculate the BM25 score using the formula:\n   - **TF (Term Frequency)**: The frequency of a term in a document, capped at 1 to prevent saturation.\n   - **IDF (Inverse Document Frequency)**: The number of documents where the term appears, divided by the total number of documents.\n   - **TF-IDF**: The product of TF and IDF for each term in the query.\n   - **Document Length Normalization**: A factor that adjusts the score based on the document's length, using the formula \\((1 + (len(document) * (1 - b)))^{-b}\\).\n4. **Score Calculation**: Sum the TF-IDF scores for all terms in the query and apply the document length normalization to get the final score for each document.\n\n### Solution Code\n```python\nimport numpy as np\nfrom collections import Counter\n\ndef calculate_bm25_scores(corpus, query, k1=1.5, b=0.75):\n    query_terms = query.split()\n    if not query_terms:\n        return [0.0]  # Return 0 if query is empty\n    \n    # Precompute global term frequencies\n    global_freq = {}\n    for doc in corpus:\n        terms = doc.split()\n        unique_terms = set(terms)\n        for term in unique_terms:\n            if term in global_freq:\n                global_freq[term] += 1\n            else:\n                global_freq[term] = 1\n    \n    scores = []\n    total_documents = len(corpus)\n    \n    for doc in corpus:\n        terms = doc.split()\n        count = Counter(terms)\n        total_words = len(terms)\n        score_sum = 0.0\n        \n        for term in query_terms:\n            if term in count:\n                # Calculate TF with saturation\n                tf = (k1 + 1) * count[term] / total_words\n                if tf > 1:\n                    tf = 1.0\n                # Calculate IDF\n                idf = global_freq[term] / total_documents\n                score_sum += tf * idf\n        \n        # Calculate document length normalization\n        if total_words == 0:\n            norm = 1.0\n        else:\n            norm = (1 + total_words * (1 - b)) ** (-b)\n        \n        score = score_sum * norm\n        scores.append(round(score, 3))\n    \n    return scores\n```\n\n### Explanation\n1. **Query Processing**: The query is split into individual terms to form a list of query terms.\n2. **Global Frequency Calculation**: For each term in each document, we maintain a count of how many documents contain that term. This helps in computing the inverse document frequency (IDF) for each term.\n3. **Document Processing**: Each document is processed to count the frequency of each term within the document. Using these frequencies, we compute the term frequency (TF) and inverse document frequency (IDF) for each term in the query.\n4. **Score Calculation**: For each document, the scores of all terms in the query are summed up. This sum is then adjusted by a normalization factor based on the document's length to get the final BM25 score for the document.\n\nThis approach ensures that the BM25 ranking function efficiently computes document scores by incorporating both local and global information about the corpus, providing a robust solution for information retrieval tasks."}
{"task_id": 91, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the F1 score given the true labels and predicted labels. The F1 score is a widely used metric in machine learning that combines precision and recall into a single measure. \n\n### Approach\nThe F1 score is computed as the harmonic mean of precision and recall. Here's a step-by-step breakdown of the approach:\n\n1. **Precision and Recall Calculation**: For each class, precision is the number of correct predictions divided by the total number of predictions, and recall is the number of correct predictions divided by the total number of true cases.\n2. **F1 Score Calculation**: For each class, the F1 score is calculated as 2 * (precision * recall) / (precision + recall).\n3. **Summing F1 Scores**: Sum the F1 scores of all classes and divide by the number of classes to get the overall F1 score.\n4. **Handling Edge Cases**: If a class has zero true labels or zero predicted labels, it contributes zero to the F1 score for that class.\n\n### Solution Code\n```python\nfrom collections import Counter\n\ndef calculate_f1_score(y_true, y_pred):\n    \"\"\"\n    Calculate the F1 score based on true and predicted labels.\n\n    Args:\n        y_true (list): True labels (ground truth).\n        y_pred (list): Predicted labels.\n\n    Returns:\n        float: The F1 score rounded to three decimal places.\n    \"\"\"\n    if not y_true or not y_pred:\n        return 0.0\n    \n    true_counter = Counter(y_true)\n    pred_counter = Counter(y_pred)\n    unique_classes = set(y_true)\n    \n    total_f1 = 0.0\n    \n    for class_ in unique_classes:\n        true_count = true_counter[class_]\n        pred_count = pred_counter.get(class_, 0)\n        \n        if true_count == 0 or pred_count == 0:\n            continue\n        \n        correct = (true_counter & pred_counter)[class_]\n        precision = correct / pred_count\n        recall = correct / true_count\n        \n        f1 = 2 * (precision * recall) / (precision + recall)\n        total_f1 += f1\n    \n    if not unique_classes:\n        return 0.0\n    \n    average_f1 = total_f1 / len(unique_classes)\n    return round(average_f1, 3)\n```\n\n### Explanation\n1. **Importing Counter**: We use `collections.Counter` to efficiently count occurrences of each label in both the true and predicted lists.\n2. **Handling Empty Lists**: If either the true or predicted list is empty, the function returns 0.0 immediately.\n3. **Counting Occurrences**: We create counters for both true and predicted labels to keep track of occurrences of each class.\n4. **Iterating Over Classes**: For each unique class in the true labels, we calculate the number of correct predictions, precision, recall, and F1 score.\n5. **Summing F1 Scores**: The F1 scores for all classes are summed, and the average F1 score is computed by dividing by the number of unique classes.\n6. **Rounding the Result**: The final F1 score is rounded to three decimal places before returning.\n\nThis approach ensures that we accurately compute the F1 score by considering each class's performance, handling edge cases, and efficiently counting occurrences using the Counter class."}
{"task_id": 92, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to forecast the power grid consumption for day 15, considering both a linear trend and daily fluctuations. The goal is to remove the known daily fluctuation, fit a linear regression model to the detrended data, predict the base consumption for day 15, add back the fluctuation, and include a 5% safety margin.\n\n### Approach\n1. **Subtract Daily Fluctuation**: For each data point, subtract the daily fluctuation given by the formula \\( f(i) = 10 \\times \\sin(2\\pi i / 10) \\), where \\( i \\) is the day number from 1 to 10.\n2. **Linear Regression**: Perform a linear regression on the detrended data to find the best fit line, which gives the slope and intercept of the line.\n3. **Predict Day 15 Consumption**: Using the linear regression model, predict the base consumption for day 15.\n4. **Add Fluctuation Back**: Since the fluctuation for day 15 is zero, the base consumption remains the predicted value.\n5. **Add Safety Margin**: Add a 5% safety margin to the predicted value, round the result, and return it as an integer.\n\n### Solution Code\n```python\nimport math\nPI = 3.14159\n\ndef power_grid_forecast(consumption_data):\n    # Step 1: Subtract the daily fluctuation\n    detrended = []\n    for i in range(10):\n        day = i + 1\n        fluctuation = 10 * math.sin(2 * PI * day / 10)\n        detrended.append(consumption_data[i] - fluctuation)\n    \n    # Step 2: Perform linear regression\n    sum_x = 55  # Sum of days from 1 to 10\n    sum_y = sum(detrended)\n    sum_xy = 0\n    sum_x2 = 0\n    for x, y in zip(range(1, 11), detrended):\n        sum_xy += x * y\n        sum_x2 += x ** 2\n    \n    n = 10\n    mean_x = sum_x / n\n    mean_y = sum_y / n\n    \n    # Calculate covariance and variance\n    covariance = (sum_xy - (sum_x * sum_y) / n) / n\n    variance_x = (sum_x2 - (sum_x ** 2) / n) / n\n    if variance_x == 0:\n        # To avoid division by zero, though variance shouldn't be zero with real data\n        slope = 0\n    else:\n        slope = covariance / variance_x\n    \n    intercept = mean_y - slope * mean_x\n    \n    # Step 3: Predict day 15's base consumption\n    y_pred = intercept + slope * 15\n    \n    # Step 4: Add back the fluctuation for day 15 (which is 0)\n    total = y_pred  # since f(15) = 0\n    \n    # Step 5: Add 5% safety margin and round\n    total_with_margin = total * 1.05\n    rounded_total = round(total_with_margin)\n    \n    return rounded_total\n```\n\n### Explanation\n1. **Subtract Fluctuation**: Each data point is adjusted by subtracting the daily fluctuation, resulting in detrended data.\n2. **Linear Regression**: The linear regression model is fit using the detrended data. The slope and intercept of the best fit line are calculated using the covariance and variance of the data points.\n3. **Prediction**: The linear regression model is used to predict the base consumption for day 15.\n4. **Safety Margin**: The predicted value is increased by 5% and then rounded to the nearest integer to ensure future energy needs are met.\n\nThis approach ensures that we accurately remove the known daily fluctuations, fit a reliable linear model, and provide a forecast with a safety margin to handle uncertainties."}
{"task_id": 93, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Mean Absolute Error (MAE) between two arrays of actual and predicted values. The MAE is a metric used to measure the average magnitude of errors in a set of predictions without considering their direction.\n\n### Approach\nThe Mean Absolute Error (MAE) is calculated by following these steps:\n1. **Calculate Absolute Differences**: For each corresponding element in the actual and predicted arrays, compute the absolute difference.\n2. **Sum the Differences**: Sum all the absolute differences calculated in the previous step.\n3. **Compute the Mean**: Divide the sum of absolute differences by the number of elements to get the mean.\n4. **Round the Result**: Round the computed mean to 3 decimal places to get the final MAE value.\n\nThis approach ensures that we consider the magnitude of each error without worrying about its direction, which is a key characteristic of the MAE metric.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef mae(y_true, y_pred):\n    \"\"\"\n    Calculate Mean Absolute Error between two arrays.\n\n    Parameters:\n    y_true (numpy.ndarray): Array of true values\n    y_pred (numpy.ndarray): Array of predicted values\n\n    Returns:\n    float: Mean Absolute Error rounded to 3 decimal places\n    \"\"\"\n    return round(np.mean(np.abs(y_true - y_pred)), 3)\n```\n\n### Explanation\n- **Importing Numpy**: The numpy library is imported to handle array operations efficiently.\n- **Function Definition**: The function `mae` takes two parameters, `y_true` and `y_pred`, which are numpy arrays representing the actual and predicted values, respectively.\n- **Absolute Differences Calculation**: Using `np.abs(y_true - y_pred)`, we compute the absolute differences between corresponding elements of the two arrays.\n- **Mean Calculation**: The `np.mean` function is used to compute the mean of the absolute differences.\n- **Rounding**: The result is rounded to 3 decimal places using the `round` function to meet the requirement of returning a float with 3 decimal places precision.\n\nThis solution efficiently computes the MAE using vectorized operations, which is both concise and performant."}
{"task_id": 94, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the multi-head attention mechanism, a key component in the Transformer model. The multi-head attention mechanism involves projecting the input into multiple subspaces, computing attention scores for each subspace, and then combining the results. This process is essential for capturing long-range dependencies in sequential data.\n\n### Approach\nThe approach to implement multi-head attention involves three main steps:\n\n1. **Compute Q, K, V for each head**: This step involves projecting the input tensor `X` using learnable parameters `W_q`, `W_k`, and `W_v` to obtain the query, key, and value vectors for each head. Each head has its own set of parameters, and the input is projected into `n_heads` subspaces.\n\n2. **Self-attention computation**: For each head, compute the attention scores using the query, key, and value vectors. The attention scores are computed as the dot product of the query and key vectors, scaled by the square root of the dimension of each head. The scores are then normalized using the softmax function.\n\n3. **Combine outputs**: After computing the attention scores for each head, the corresponding values are weighted by these scores and summed to produce the output for each head. The outputs from all heads are then concatenated to form the final output.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef compute_qkv(X: np.ndarray, W_q: np.ndarray, W_k: np.ndarray, W_v: np.ndarray, n_heads: int) -> tuple:\n    # Split the weights into n_heads parts\n    qkv = [W_q[i] for i in range(n_heads)]\n    kv = [W_k[i] for i in range(n_heads)]\n    vv = [W_v[i] for i in range(n_heads)]\n    \n    # Compute Q, K, V for each head\n    Q = []\n    K = []\n    V = []\n    for i in range(n_heads):\n        w_q = qkv[i]\n        w_k = kv[i]\n        w_v = vv[i]\n        q = X @ w_q\n        k = X @ w_k\n        v = X @ w_v\n        Q.append(q)\n        K.append(k)\n        V.append(v)\n    # Reshape to (n_heads, batch_size, seq_len)\n    Q = np.stack([q[:, :, i] for i in range(n_heads)], axis=1)\n    K = np.stack([k[:, :, i] for i in range(n_heads)], axis=1)\n    V = np.stack([v[:, :, i] for i in range(n_heads)], axis=1)\n    return (Q, K, V)\n\ndef self_attention(queries: np.ndarray, keys: np.ndarray, values: np.ndarray, n_heads: int) -> np.ndarray:\n    # Compute the attention scores\n    d = queries.shape[-1]\n    inv_sqrt_d = 1.0 / np.sqrt(d)\n    \n    # Compute QK^T\n    QK = queries @ keys.T\n    QK_scaled = QK * inv_sqrt_d\n    # Apply softmax\n    attention_weights = np.softmax(QK_scaled, axis=-1)\n    \n    # Compute the output\n    output = attention_weights @ values\n    # Round to the nearest 4th decimal\n    output = np.round(output, 4)\n    return output\n\ndef multi_head_attention(X: np.ndarray, W_q: np.ndarray, W_k: np.ndarray, W_v: np.ndarray, n_heads: int) -> list:\n    # Compute qkv for all heads\n    Q, K, V = compute_qkv(X, W_q, W_k, W_v, n_heads)\n    \n    # Compute self attention\n    output = self_attention(Q, K, V, n_heads)\n    \n    # Reshape the output to (n_heads, batch_size, seq_len)\n    output_reshaped = output.reshape(n_heads, -1)\n    \n    # Convert to list of lists\n    result = []\n    for i in range(n_heads):\n        result.append(output_reshaped[i])\n    \n    return result\n```\n\n### Explanation\n1. **compute_qkv Function**: This function computes the query, key, and value vectors for each head. It splits the learnable parameters `W_q`, `W_k`, and `W_v` into `n_heads` parts and projects the input tensor `X` onto each part to get the respective vectors.\n\n2. **self_attention Function**: This function computes the attention scores for each head. It uses the query and key vectors to compute the dot product, scales it by the square root of the dimension, applies the softmax function to get the attention weights, and then computes the output by weighting the value vectors with these weights.\n\n3. **multi_head_attention Function**: This function ties everything together. It first computes the query, key, and value vectors for all heads using `compute_qkv`, then computes the attention scores and outputs for each head using `self_attention`, and finally reshapes and returns the result as a list of outputs for each head.\n\nThis approach ensures that the input tensor is transformed into multiple subspaces, allowing the model to capture complex patterns and relationships in the data. The use of multi-head attention helps in effectively capturing long-range dependencies, which is crucial for tasks like machine translation and text generation."}
{"task_id": 95, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Phi coefficient, a measure of the correlation between two binary variables. The Phi coefficient is particularly useful for analyzing the relationship between two categorical variables, such as presence or absence of a trait in a population.\n\n### Approach\nThe Phi coefficient is calculated using the formula:\n\\[ \\Phi = \\frac{C - D}{\\sqrt{A \\times B}} \\]\nwhere:\n- \\( C \\) is the number of concordant pairs (both variables are either 0 or 1).\n- \\( D \\) is the number of discordant pairs (one variable is 0 and the other is 1).\n- \\( A \\) is the total number of 1s in the first variable.\n- \\( B \\) is the total number of 1s in the second variable.\n\nThe steps to compute the Phi coefficient are as follows:\n1. **Count Concordant and Discordant Pairs**: Iterate through each pair of elements in the two lists. If both elements are the same (both 0 or both 1), increment the concordant count (C). Otherwise, increment the discordant count (D).\n2. **Calculate Totals**: Compute the total number of 1s in each list (A and B).\n3. **Handle Edge Cases**: If either list has no 1s, the Phi coefficient is 0 because there is no correlation.\n4. **Compute Phi**: Use the formula to compute the Phi coefficient.\n5. **Round the Result**: Round the result to four decimal places for the final output.\n\n### Solution Code\n```python\ndef phi_corr(x: list[int], y: list[int]) -> float:\n    \"\"\"\n    Calculate the Phi coefficient between two binary variables.\n\n    Args:\n        x (list[int]): A list of binary values (0 or 1).\n        y (list[int]): A list of binary values (0 or 1).\n\n    Returns:\n        float: The Phi coefficient rounded to 4 decimal places.\n    \"\"\"\n    C = 0\n    D = 0\n    for xi, yi in zip(x, y):\n        if xi == yi:\n            C += 1\n        else:\n            D += 1\n    A = sum(x)\n    B = sum(y)\n    if A == 0 or B == 0:\n        return 0.0\n    denominator = (A * B) ** 0.5\n    phi = (C - D) / denominator\n    return round(phi, 4)\n```\n\n### Explanation\n- **Counting Concordant and Discordant Pairs**: The loop iterates through each corresponding pair of elements in the two lists. If both elements are the same, it increments the concordant count (C). Otherwise, it increments the discordant count (D).\n- **Calculating Totals**: The total number of 1s in each list is computed using the `sum` function.\n- **Handling Edge Cases**: If either list has no 1s, the function returns 0.0 immediately as there is no correlation possible.\n- **Computing Phi**: The formula for the Phi coefficient is applied using the counts of concordant and discordant pairs, along with the totals of 1s in each list.\n- **Rounding**: The result is rounded to four decimal places to provide a precise and readable output.\n\nThis approach efficiently computes the Phi coefficient by leveraging simple counting and mathematical operations, ensuring accuracy and performance."}
{"task_id": 96, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Hard Sigmoid activation function, which is a computationally efficient approximation of the standard sigmoid function. The Hard Sigmoid function is a piecewise linear function that outputs 0 for inputs below a threshold and 1 for inputs equal to or above the threshold.\n\n### Approach\nThe Hard Sigmoid function is defined as follows:\n- 0, when the input value is less than a threshold `a`\n- 1, when the input value is equal to or greater than the threshold `a`\n\nThe threshold `a` is derived from the standard sigmoid function by setting the output to 0.5. This threshold is calculated as:\n\\[ a = -\\ln(0.5) \\]\nThis value is approximately 0.6931. For any input value less than this threshold, the function returns 0.0. For input values equal to or greater than this threshold, the function returns 1.0.\n\n### Solution Code\n```python\nimport math\n\ndef hard_sigmoid(x: float) -> float:\n    \"\"\"\n    Implements the Hard Sigmoid activation function.\n\n    Args:\n        x (float): Input value\n\n    Returns:\n        float: The Hard Sigmoid of the input\n    \"\"\"\n    a = -math.log(0.5)\n    return 0.0 if x < a else 1.0\n```\n\n### Explanation\n1. **Threshold Calculation**: The threshold `a` is calculated using the natural logarithm of 0.5, which is approximately 0.6931.\n2. **Condition Check**: The function checks if the input value `x` is less than the threshold `a`. If true, it returns 0.0. Otherwise, it returns 1.0.\n\nThis approach ensures that the function is computationally efficient, as it avoids the need for complex calculations involving exponential and logarithmic functions, making it suitable for use in neural networks and other applications where efficiency is crucial."}
{"task_id": 97, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Exponential Linear Unit (ELU) activation function. ELU is a variant of the ReLU activation function that addresses the limitation of ReLU by providing negative outputs for negative inputs. This is achieved using an exponential function to scale the output for negative inputs.\n\n### Approach\nThe ELU activation function is defined as:\n- For non-negative inputs (x >= 0), the function returns the input value x.\n- For negative inputs (x < 0), the function returns a scaled exponential function: alpha * (e^(-x) - 1), where alpha is a parameter that controls the shape of the function.\n\nThe steps to implement this function are:\n1. Check if the input value x is non-negative. If it is, return x rounded to 4 decimal places.\n2. If x is negative, compute the scaled exponential function using the formula alpha * (e^(-x) - 1) and return the result rounded to 4 decimal places.\n\n### Solution Code\n```python\nimport math\n\ndef elu(x: float, alpha: float = 1.0) -> float:\n    \"\"\"\n    Compute the ELU activation function.\n\n    Args:\n        x (float): Input value\n        alpha (float): ELU parameter for negative values (default: 1.0)\n\n    Returns:\n        float: ELU activation value, rounded to 4 decimal places.\n    \"\"\"\n    if x >= 0:\n        return round(x, 4)\n    else:\n        return round(alpha * (math.exp(-x) - 1), 4)\n```\n\n### Explanation\n- The function `elu` takes two parameters: `x` (the input value) and `alpha` (a scaling parameter, defaulting to 1.0).\n- If `x` is non-negative, the function directly returns `x` rounded to 4 decimal places.\n- If `x` is negative, the function computes the exponential function `math.exp(-x)`, subtracts 1, scales the result by `alpha`, and then rounds the result to 4 decimal places before returning it.\n\nThis approach ensures that the ELU function behaves similarly to ReLU for non-negative inputs but provides a smooth transition for negative inputs, avoiding the vanishing gradient problem that can occur with ReLU."}
{"task_id": 98, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Parametric ReLU (PReLU) activation function. PReLU is a variant of the ReLU activation function that introduces a learnable parameter, alpha, which is used to scale the output for negative inputs. This allows the function to better handle negative values during training.\n\n### Approach\nThe PReLU activation function is defined as follows:\n- For non-negative inputs (x >= 0), the function returns the input value x.\n- For negative inputs (x < 0), the function returns alpha multiplied by x, where alpha is a learnable parameter that typically has a default value of 0.25.\n\nThe approach involves:\n1. Checking if the input value x is non-negative.\n2. If x is non-negative, return x as the output.\n3. If x is negative, return alpha multiplied by x as the output.\n\nThis approach ensures that the function behaves similarly to ReLU for non-negative inputs but provides a scaled output for negative inputs, which can be beneficial during training.\n\n### Solution Code\n```python\ndef prelu(x: float, alpha: float = 0.25) -> float:\n    \"\"\"\n    Implements the PReLU (Parametric ReLU) activation function.\n\n    Args:\n        x: Input value\n        alpha: Slope parameter for negative values (default: 0.25)\n\n    Returns:\n        float: PReLU activation value\n    \"\"\"\n    return x if x >= 0 else alpha * x\n```\n\n### Explanation\nThe function `prelu` takes two parameters: `x` (the input value) and `alpha` (a learnable parameter with a default value of 0.25). The function returns the PReLU activation value based on the following logic:\n- If `x` is greater than or equal to zero, the function returns `x` directly.\n- If `x` is less than zero, the function returns `alpha * x`, which scales the negative input by the alpha parameter.\n\nThis implementation efficiently handles both positive and negative inputs, providing a smooth transition for the activation function during training."}
{"task_id": 99, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Softplus activation function, which is a smooth approximation of the ReLU (Rectified Linear Unit) function. The Softplus function is defined as log(1 + e^x) and is used in various applications, including neural networks, to introduce non-linearity to the model.\n\n### Approach\nThe Softplus function, also known as the logistic function, is a continuous version of the ReLU function. It is defined as:\n\\[ \\text{Softplus}(x) = \\log(1 + e^x) \\]\n\nThe steps to compute the Softplus value for a given input x are as follows:\n1. Compute \\( e^x \\) using the exponential function.\n2. Add 1 to the result of the exponential function.\n3. Take the natural logarithm of the sum obtained in the previous step.\n4. Round the result to four decimal places to handle numerical precision.\n\nThis approach ensures that the function handles both very large and very small values of x gracefully, avoiding numerical overflow or underflow issues.\n\n### Solution Code\n```python\nimport math\n\ndef softplus(x: float) -> float:\n    \"\"\"\n    Compute the softplus activation function.\n\n    Args:\n        x: Input value\n\n    Returns:\n        The softplus value: log(1 + e^x), rounded to four decimal places.\n    \"\"\"\n    return round(math.log(1 + math.exp(x)), 4)\n```\n\n### Explanation\n- **Exponential Function**: The function `math.exp(x)` computes \\( e^x \\), which is the exponential of x.\n- **Logarithm Function**: The function `math.log` computes the natural logarithm of the result from the exponential function.\n- **Rounding**: The result is rounded to four decimal places using the `round` function to ensure precision and avoid issues with floating-point representation.\n\nThis implementation efficiently computes the Softplus value for any given input x, ensuring numerical stability and precision."}
{"task_id": 100, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Softsign activation function, which is a smooth activation function used in neural networks. The Softsign function maps any real number to a value between -1 and 1, making it suitable for various applications in neural network models.\n\n### Approach\nThe Softsign activation function can be computed using the formula:\n\\[ f(x) = \\frac{e^x - 1}{e^x + 1} \\]\nThis formula is derived from the properties of the exponential function and ensures that the output is bounded between -1 and 1. The function works by transforming the input value \\( x \\) through the exponential function and then normalizing the result to the desired range.\n\n### Solution Code\n```python\nimport math\n\ndef softsign(x: float) -> float:\n    \"\"\"\n    Implements the Softsign activation function.\n\n    Args:\n        x (float): Input value\n\n    Returns:\n        float: The Softsign of the input, rounded to 4 decimal places.\n    \"\"\"\n    value = (math.exp(x) - 1) / (math.exp(x) + 1)\n    return round(value, 4)\n```\n\n### Explanation\n1. **Formula Application**: The function uses the formula \\((e^x - 1) / (e^x + 1)\\) to compute the Softsign of the input \\( x \\). This formula ensures that the output is always between -1 and 1.\n2. **Exponential Function**: The code computes the exponential of \\( x \\) using `math.exp(x)`, which efficiently handles both large and small values of \\( x \\).\n3. **Rounding**: The result is rounded to four decimal places to meet the problem's requirements, ensuring precision and consistency in the output.\n\nThis approach efficiently computes the Softsign function while maintaining numerical stability and precision, making it suitable for use in neural network models."}
{"task_id": 101, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the GRPO (Group Relative Policy Optimization) objective function used in reinforcement learning to optimize policy parameters. The GRPO objective function combines several components: the policy gradient term, a KL divergence penalty, and a clipped advantage term to maintain training stability.\n\n### Approach\nThe GRPO objective function is designed to optimize policy parameters by balancing the exploration and exploitation trade-off. It consists of the following components:\n\n1. **Policy Gradient Term**: This term encourages the policy to explore by summing the product of likelihood ratios (rhos) and advantage estimates (A).\n2. **KL Divergence Penalty**: This term regularizes the policy update by penalizing deviations from a reference policy distribution.\n3. **Clipped Advantage Term**: This term prevents excessive exploitation by clipping the advantage estimates within a specified range and subtracting their contribution to the objective function.\n\nThe objective function is computed as follows:\n1. **Clipping the Advantage Estimates**: Each advantage estimate is clipped between -epsilon and epsilon to prevent overexploitation.\n2. **Summing the Policy Gradient Term**: Compute the sum of the product of likelihood ratios and advantage estimates.\n3. **Computing the KL Divergence**: Calculate the KL divergence between the old policy distribution and the reference policy distribution.\n4. **Combining Components**: The final objective is the sum of the policy gradient term, minus the KL divergence penalty, and minus the sum of the clipped advantage term.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef grpo_objective(rhos, A, pi_theta_old, pi_theta_ref, epsilon=0.2, beta=0.01) -> float:\n    \"\"\"\n    Compute the GRPO objective function.\n\n    Args:\n        rhos: List of likelihood ratios (p_i) = pi_theta(o_i | q) / pi_theta_old(o_i | q).\n        A: List of advantage estimates (A_i).\n        pi_theta_old: List representing the old policy probabilities pi_theta_old(o_i | q).\n        pi_theta_ref: List representing the reference policy probabilities pi_ref(o_i | q).\n        epsilon: Clipping parameter (eps).\n        beta: KL divergence penalty coefficient (beta).\n\n    Returns:\n        The computed GRPO objective value, rounded to the nearest 6th decimal.\n    \"\"\"\n    # Clip the advantage estimates\n    clipped_A = np.clip(np.array(A), -epsilon, epsilon)\n    \n    # Compute the sum of r_i * A_i\n    sum_A = np.sum(rhos * A)\n    \n    # Compute the sum of r_i * clipped_A_i\n    sum_clipped = np.sum(rhos * clipped_A)\n    \n    # Compute the KL divergence between pi_theta_old and pi_theta_ref\n    kl = np.sum(pi_theta_old * np.log(pi_theta_ref))\n    \n    # Calculate the objective function\n    objective = sum_A - sum_clipped - beta * kl\n    \n    # Round to the nearest 6th decimal\n    return round(objective, 6)\n```\n\n### Explanation\n1. **Clipping the Advantage Estimates**: The advantage estimates are clipped to ensure that the policy does not exploit too much, which could lead to suboptimal solutions.\n2. **Policy Gradient Term**: This term encourages the exploration of new policies by rewarding actions that increase the likelihood of the next state.\n3. **KL Divergence Penalty**: This term penalizes the policy update if it deviates significantly from the reference policy distribution, ensuring stability in the policy updates.\n4. **Combining Components**: The objective function combines these components to balance exploration and exploitation, ensuring that the policy updates are both effective and stable.\n\nThis approach ensures that the policy optimization process is both efficient and stable, leading to better performance in reinforcement learning tasks."}
{"task_id": 102, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Swish activation function, which is a self-gated activation function that has shown superior performance in deep neural networks compared to traditional activations like ReLU. The Swish function is defined as a combination of sigmoid functions and has a unique S-shaped curve that allows it to better capture the complexity of data in neural networks.\n\n### Approach\nThe Swish activation function is mathematically defined as:\n\\[ f(x) = x \\cdot \\sigma(x) - x \\cdot \\sigma(1 - x) \\]\nwhere \\(\\sigma\\) is the sigmoid function. The sigmoid function is a logistic function that maps any real number to a value between 0 and 1, which is crucial for the self-gating property of the Swish function.\n\nThe steps to compute the Swish activation function are as follows:\n1. Compute the sigmoid of the input value \\(x\\).\n2. Compute the sigmoid of \\(1 - x\\).\n3. Multiply the input value \\(x\\) by both sigmoid values.\n4. Subtract the second product from the first to get the Swish activation value.\n5. Round the result to four decimal places for precision.\n\n### Solution Code\n```python\nimport math\n\ndef swish(x: float) -> float:\n    \"\"\"\n    Implements the Swish activation function.\n\n    Args:\n        x: Input value\n\n    Returns:\n        The Swish activation value, rounded to four decimal places.\n    \"\"\"\n    sigmoid_x = math.sigmoid(x)\n    sigmoid_1x = math.sigmoid(1 - x)\n    swish_value = x * sigmoid_x - x * sigmoid_1x\n    return round(swish_value, 4)\n```\n\n### Explanation\nThe Swish function is implemented using the sigmoid function from the math library. The function first computes the sigmoid of the input value \\(x\\) and the sigmoid of \\(1 - x\\). It then calculates the product of \\(x\\) with each of these sigmoid values and subtracts the second product from the first. The result is rounded to four decimal places to ensure precision. This implementation efficiently captures the unique characteristics of the Swish activation function, making it suitable for use in neural networks."}
{"task_id": 103, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the SELU (Scaled Exponential Linear Unit) activation function, which is a self-normalizing variant of the ELU (Exponential Linear Unit) activation function. The goal is to compute the SELU value for a given input while ensuring numerical stability.\n\n### Approach\nThe SELU activation function is defined as:\n\\[ \\text{SELU}(x) = \\alpha \\times \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\]\nwhere \\(\\alpha\\) is a scaling factor that helps in maintaining the range of the output values. This formula ensures that the output values are within the range \\([-1, 1]\\), making it self-normalizing.\n\nTo compute the SELU value, we follow these steps:\n1. Compute the exponential of the input value \\(x\\).\n2. Compute the exponential of the negative of the input value \\(x\\).\n3. Calculate the denominator as the sum of these two exponential values.\n4. Calculate the numerator as the difference of these two exponential values.\n5. Multiply the result by the scaling factor \\(\\alpha\\).\n6. Round the result to the nearest 4th decimal place to ensure precision.\n\n### Solution Code\n```python\nimport math\nimport numpy as np\n\ndef selu(x: float) -> float:\n    \"\"\"\n    Implements the SELU (Scaled Exponential Linear Unit) activation function.\n\n    Args:\n        x: Input value\n\n    Returns:\n        SELU activation value rounded to the nearest 4th decimal.\n    \"\"\"\n    alpha = 1.6732632423543772\n    denominator = math.exp(x) + math.exp(-x)\n    numerator = math.exp(x) - math.exp(-x)\n    selu_value = alpha * numerator / denominator\n    return round(selu_value, 4)\n```\n\n### Explanation\n- **Exponential Calculations**: The function uses `math.exp(x)` to compute \\(e^x\\) and `math.exp(-x)` to compute \\(e^{-x}\\). These values are used to compute the numerator and denominator.\n- **Denominator and Numerator**: The denominator is the sum of \\(e^x\\) and \\(e^{-x}\\), while the numerator is the difference between these two values.\n- **Scaling by Alpha**: The result of the division of the numerator by the denominator is scaled by \\(\\alpha\\) to ensure the output is within the range \\([-1, 1]\\).\n- **Rounding**: The final result is rounded to four decimal places to meet the precision requirement.\n\nThis approach ensures numerical stability by handling large and small values of \\(x\\) effectively, and it provides a self-normalizing activation function suitable for neural network applications."}
{"task_id": 104, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a binary classification prediction function using Logistic Regression. The goal is to compute class probabilities using the sigmoid function and return binary predictions based on a threshold of 0.5.\n\n### Approach\nThe approach involves the following steps:\n1. **Compute the Linear Combination**: For each sample, compute the linear combination of the input features, weights, and bias. This is done using matrix multiplication followed by addition of the bias.\n2. **Apply the Sigmoid Function**: Convert the linear combination into probabilities using the sigmoid function, which transforms the output into a probability value between 0 and 1.\n3. **Determine Binary Predictions**: Compare each probability to a threshold of 0.5. If the probability is 0.5 or higher, predict 1; otherwise, predict 0.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef predict_logistic(X: np.ndarray, weights: np.ndarray, bias: float) -> list:\n    \"\"\"\n    Implements binary classification prediction using Logistic Regression.\n\n    Args:\n        X: Input feature matrix (shape: N \u00c3\u0097 D)\n        weights: Model weights (shape: D)\n        bias: Model bias\n\n    Returns:\n        Binary predictions (0 or 1)\n    \"\"\"\n    # Compute the linear combination of features and weights, then add bias\n    z = X.dot(weights) + bias\n    # Apply the sigmoid function to get probabilities\n    probabilities = np.sigmoid(z)\n    # Convert probabilities to binary predictions based on 0.5 threshold\n    predictions = np.where(probabilities >= 0.5, 1, 0)\n    # Return the predictions as a list\n    return predictions.tolist()\n```\n\n### Explanation\n1. **Linear Combination**: The function first computes the dot product of the input features matrix `X` with the weights vector. This results in a 1D array where each element represents the sum of the products of each feature with the corresponding weight for that sample. The bias is then added to this array.\n2. **Sigmoid Function**: The sigmoid function is applied to the linear combination to convert it into a probability value. The sigmoid function is defined as `sigmoid(z) = 1 / (1 + e^(-z))`, which ensures that the output is always between 0 and 1.\n3. **Binary Prediction**: The probabilities are compared against the threshold of 0.5. If a probability is 0.5 or higher, the corresponding prediction is 1; otherwise, it is 0. The predictions are then converted into a list and returned.\n\nThis approach efficiently computes the binary classification predictions using the logistic regression model, ensuring accurate and interpretable results."}
{"task_id": 105, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a gradient descent-based training algorithm for Softmax regression using Cross Entropy loss. The goal is to compute the model parameters and return the optimized coefficients along with the collected loss values over iterations.\n\n### Approach\n1. **Problem Analysis**: Softmax regression is a technique used for classification tasks where each sample is assigned a probability vector that sums to 1. The Cross Entropy loss is a common loss function for classification tasks, measuring the difference between the predicted probabilities and the actual labels.\n\n2. **Intuition**: The Softmax function converts the linear output of the network into a probability distribution. The Cross Entropy loss then measures the difference between the predicted probabilities and the actual labels, providing a way to update the model parameters to minimize the loss.\n\n3. **Algorithm Selection**: We use gradient descent to optimize the model parameters. The gradients of the loss with respect to the weights and biases are computed using the chain rule, which involves the derivative of the Softmax function and the Cross Entropy loss.\n\n4. **Steps**:\n   - Initialize the weights and biases.\n   - For each iteration, compute the linear output, apply the Softmax function, and calculate the loss.\n   - Compute the gradients of the loss with respect to the weights and biases.\n   - Update the weights and biases using the computed gradients and the learning rate.\n   - Collect the loss values over iterations.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef train_softmaxreg(X: np.ndarray, y: np.ndarray, learning_rate: float, iterations: int) -> tuple[list[float], ...]:\n    \"\"\"\n    Gradient-descent training algorithm for Softmax regression, optimizing parameters with Cross Entropy loss.\n\n    Returns:\n        B : list[float], CxM updated parameter vector rounded to 4 floating points\n        losses : list[float], collected values of a Cross Entropy rounded to 4 floating points\n    \"\"\"\n    m, n_features = X.shape\n    num_classes = y.shape[1]\n    \n    # Initialize weights and bias\n    W = np.random.randn(n_features, num_classes) * np.sqrt(1. / n_features)\n    b = np.zeros(num_classes)\n    \n    losses = []\n    \n    for _ in range(iterations):\n        # Compute z = Wx + b\n        z = W.dot(X) + b\n        \n        # Compute Softmax\n        a = np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n        \n        # Compute loss\n        correct_indices = np.argmax(y, axis=1)\n        a_correct = a[np.arange(m), correct_indices]\n        loss = -np.log(a_correct).mean()\n        losses.append(loss)\n        \n        # Compute gradients\n        dx = (a - y) * a\n        dw = (1/m) * X.T.dot(dx)\n        db = (1/m) * np.sum(dx, axis=0)\n        \n        # Update parameters\n        W -= learning_rate * dw\n        b -= learning_rate * db\n    \n    # Round the results\n    B = W.flatten().tolist()\n    B = [round(b, 4) for b in B]\n    losses = [round(loss, 4) for loss in losses]\n    \n    return (B, losses)\n```\n\n### Explanation\n1. **Initialization**: The weights (W) are initialized using a random distribution scaled by the square root of the number of features to prevent the initial outputs from being too large. The biases (b) are initialized to zero.\n\n2. **Forward Pass**: For each iteration, the linear output (z) is computed by multiplying the weights with the input features and adding the biases. The Softmax function is then applied to convert this linear output into a probability distribution.\n\n3. **Loss Calculation**: The Cross Entropy loss is computed by taking the negative logarithm of the probabilities of the correct class for each sample.\n\n4. **Gradients Calculation**: The gradients of the loss with respect to the weights and biases are computed. The gradient for the weights is derived from the outer product of the input features and the difference between the predicted and actual probabilities. The gradient for the biases is the average of the predicted probabilities.\n\n5. **Parameter Update**: The weights and biases are updated using the computed gradients and the learning rate.\n\n6. **Result Collection**: The optimized weights and biases are returned as a flattened list, and the collected loss values are rounded to four decimal places.\n\nThis approach ensures that the model parameters are optimized using gradient descent, and the loss values are collected to monitor the training process."}
{"task_id": 106, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a gradient descent-based training algorithm for logistic regression. The goal is to optimize the model parameters using Binary Cross Entropy (BCE) loss and return the optimized coefficients along with the loss values over iterations, rounded to four decimal places.\n\n### Approach\n1. **Logistic Regression Setup**: The logistic regression model is represented as a linear transformation followed by a sigmoid function. The prediction for a given input is computed as \\( p = a \\cdot X + b \\), where \\( a \\) and \\( b \\) are the coefficients, and \\( X \\) is the input matrix. The actual labels \\( y \\) are converted to probabilities using the sigmoid function.\n\n2. **Loss Function**: We use Binary Cross Entropy (BCE) loss, which is suitable for binary classification problems. The BCE loss for a single sample is given by \\( -y \\cdot \\log(p) - (1 - y) \\cdot \\log(1 - p) \\). For multiple samples, we sum this loss.\n\n3. **Gradient Computation**: The gradient of the loss with respect to the coefficients \\( a \\) and \\( b \\) is computed. The gradient for \\( a \\) is the average of the predictions \\( p \\), and the gradient for \\( b \\) is the average of \\( 1 - p \\).\n\n4. **Gradient Descent Update**: Using the computed gradients, we update the parameters \\( a \\) and \\( b \\) by subtracting the learning rate multiplied by the gradient. This process is repeated for a specified number of iterations.\n\n5. **Loss Collection**: After each iteration, the loss value is recorded. After all iterations, the optimized parameters and the list of losses are returned.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef train_logreg(X: np.ndarray, y: np.ndarray, learning_rate: float, iterations: int) -> tuple[list[float], ...]:\n    \"\"\"\n    Gradient-descent training algorithm for logistic regression, optimizing parameters with Binary Cross Entropy loss.\n    \"\"\"\n    # Initialize parameters\n    a = np.zeros(X.shape[1], dtype=np.float64)\n    b = np.zeros(1, dtype=np.float64)\n    \n    # Store losses\n    losses = []\n    \n    for _ in range(iterations):\n        # Compute sigmoid\n        p = np.sigmoid(a.dot(X) + b)\n        \n        # Compute average gradients\n        gradient_a = np.mean(p, axis=0)\n        gradient_b = np.mean(1 - p, axis=0)\n        \n        # Update parameters\n        a -= learning_rate * gradient_a\n        b -= learning_rate * gradient_b\n        \n        # Compute current loss\n        current_loss = -np.mean(np.log(p + 1e-15) + np.log(1 - p + 1e-15) * (1 - y))\n        losses.append(round(current_loss, 4))\n    \n    return (a.tolist(), b.tolist(), losses)\n```\n\n### Explanation\n- **Initialization**: The parameters \\( a \\) and \\( b \\) are initialized to zero. These parameters define the linear transformation and the bias term in the logistic regression model.\n- **Sigmoid Function**: The predictions \\( p \\) are computed using the sigmoid function, which converts the linear transformation into probabilities.\n- **Gradient Computation**: The gradients with respect to \\( a \\) and \\( b \\) are computed as the average of the predictions and the average of \\( 1 - p \\), respectively.\n- **Parameter Update**: The parameters are updated using the gradient descent formula, which adjusts the coefficients based on the learning rate and the computed gradients.\n- **Loss Calculation**: The loss is computed using the BCE formula, ensuring numerical stability by adding a small epsilon value to avoid log(0) errors.\n- **Loss Collection**: The loss value for each iteration is recorded and rounded to four decimal places before being returned along with the optimized parameters.\n\nThis approach ensures that the model is trained effectively using gradient descent, optimizing the parameters to minimize the BCE loss over the given iterations."}
{"task_id": 107, "completion_id": 0, "completion": "To solve this problem, we need to implement masked self-attention, a variation of the attention mechanism used in sequence modeling tasks such as text generation. The goal is to compute the attention scores while ignoring certain positions specified by a mask.\n\n### Approach\nThe approach involves two main functions: `compute_qkv` and `masked_attention`.\n\n1. **compute_qkv Function**:\n   - This function computes the query (Q), key (K), and value (V) matrices from the input matrix X using given weight matrices W_q, W_k, and W_v. Each of these weight matrices is applied to X through matrix multiplication to obtain the respective Q, K, and V matrices.\n\n2. **masked_attention Function**:\n   - This function computes the masked self-attention using the previously computed Q, K, and V matrices, along with a mask matrix. The steps involved are:\n     - Compute the attention scores by taking the dot product of Q and the transpose of K.\n     - Apply the mask to zero out the scores where the mask is zero.\n     - Normalize the scores using the softmax function to get the attention weights.\n     - Compute the final output by multiplying the normalized scores with the value matrix V.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef compute_qkv(X: np.ndarray, W_q: np.ndarray, W_k: np.ndarray, W_v: np.ndarray):\n    \"\"\"\n    Compute Query (Q), Key (K), and Value (V) matrices.\n    \"\"\"\n    Q = np.dot(X, W_q)\n    K = np.dot(X, W_k)\n    V = np.dot(X, W_v)\n    return Q, K, V\n\ndef masked_attention(Q: np.ndarray, K: np.ndarray, V: np.ndarray, mask: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute masked self-attention.\n    \"\"\"\n    # Compute attention scores\n    scores = np.dot(Q, K.T)\n    # Apply mask\n    scores = scores * mask\n    # Apply softmax\n    scores = scores / np.sum(scores, axis=1, keepdims=True)\n    # Compute output\n    output = np.dot(scores, V)\n    return output.tolist()\n```\n\n### Explanation\n- **compute_qkv Function**:\n  - This function takes an input matrix X and three weight matrices W_q, W_k, and W_v. It computes Q, K, and V by performing matrix multiplications of X with each weight matrix respectively. This is a standard linear transformation used in the attention mechanism.\n\n- **masked_attention Function**:\n  - This function first computes the attention scores by multiplying the query matrix Q with the transpose of the key matrix K. This results in a matrix where each element represents the similarity score between the corresponding positions in Q and K.\n  - The mask is then applied to this score matrix to zero out the positions that should be ignored (masked positions).\n  - The scores are normalized using the softmax function along the second axis to ensure that the sum of the scores for each row equals 1, forming a probability distribution.\n  - Finally, the normalized scores are multiplied by the value matrix V to produce the output, which is returned as a list of lists for compatibility with certain applications.\n\nThis approach ensures that the model can focus on relevant parts of the input sequence while ignoring the masked positions, effectively implementing a self-attention mechanism with masking."}
{"task_id": 108, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the disorder in a basket of apples based on their colors. Each apple's color is represented by an integer, and the disorder should be 0 if all apples are the same color. The disorder should increase as the variety of colors increases.\n\n### Approach\nThe approach to solve this problem involves using the concept of entropy from information theory. Entropy measures the uncertainty or randomness in a system, which fits well with our requirement to measure disorder. Here's the detailed approach:\n\n1. **Count Frequencies**: First, we count the frequency of each color in the list of apples.\n2. **Calculate Probabilities**: Convert these frequencies into probabilities by dividing each frequency by the total number of apples.\n3. **Compute Entropy**: Use the formula for entropy, which is the sum of the probabilities multiplied by the logarithm base 2 of the reciprocal of each probability. This gives a measure of disorder where more distinct colors result in higher entropy.\n\n### Solution Code\n```python\nimport math\n\ndef disorder(apples: list) -> float:\n    \"\"\"\n    Calculates a measure of disorder in a basket of apples based on their colors.\n    \"\"\"\n    if not apples:\n        return 0.0  # Return 0 if the basket is empty\n    \n    # Count the frequency of each color\n    color_counts = {}\n    for apple in apples:\n        color_counts[apple] = color_counts.get(apple, 0) + 1\n    \n    total = len(apples)\n    entropy = 0.0\n    \n    for color, count in color_counts.items():\n        probability = count / total\n        entropy += probability * math.log(1 / probability, 2)\n    \n    # Round to the nearest 4th decimal\n    return round(entropy, 4)\n```\n\n### Explanation\n1. **Count Frequencies**: We use a dictionary to count how many times each color appears in the list of apples.\n2. **Calculate Probabilities**: For each color, we determine its probability by dividing its frequency by the total number of apples.\n3. **Compute Entropy**: For each color, we compute the term `p * log2(1/p)`, where `p` is the probability of that color. Summing these terms gives the entropy, which serves as our measure of disorder. The entropy is rounded to four decimal places before returning.\n\nThis approach ensures that the disorder is 0 when all apples are the same color and increases with the variety of colors, fulfilling the problem requirements efficiently."}
{"task_id": 109, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that performs Layer Normalization on an input tensor. Layer Normalization is a technique used to normalize the data across the feature dimension for each sequence, then apply scaling and shifting parameters.\n\n### Approach\nThe approach involves the following steps:\n1. **Compute Mean and Variance**: For each sequence in the input tensor, compute the mean and variance across the feature dimension. This helps in normalizing each feature within the sequence.\n2. **Normalize Features**: Normalize each feature by subtracting the mean and dividing by the standard deviation (sqrt of variance). This step ensures that each feature is centered and scaled appropriately.\n3. **Apply Scaling and Shifting**: After normalization, scale each feature using the provided gamma parameters and shift the result using the beta parameters.\n4. **Round and Convert**: Round the resulting normalized values to 5 decimal places and convert the tensor to a list for the final output.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef layer_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, epsilon: float = 1e-5):\n    # Compute mean and variance across the feature dimension\n    mean = X.mean(axis=2)\n    variance = X.var(axis=2)\n    \n    # Compute the square root of variance plus a small epsilon to avoid division by zero\n    sqrt_variance = np.sqrt(variance + epsilon)\n    \n    # Normalize the data\n    normalized = (X - mean) / sqrt_variance\n    \n    # Apply scaling and shifting\n    normalized = normalized * gamma\n    normalized = normalized + beta\n    \n    # Round to 5 decimal places and convert to list\n    normalized = np.round(normalized, 5).tolist()\n    \n    return normalized\n```\n\n### Explanation\n1. **Compute Mean and Variance**: The function first calculates the mean and variance of the features across each sequence. This is done using `np.mean` and `np.var` along the feature dimension (axis=2).\n2. **Normalize Features**: Each feature is normalized by subtracting the mean and dividing by the standard deviation. This centers the data and scales it to have zero mean and unit variance.\n3. **Apply Scaling and Shifting**: The normalized features are then scaled by the gamma parameters and shifted by the beta parameters. This step adjusts the range of the normalized values as required.\n4. **Round and Convert**: The resulting tensor is rounded to 5 decimal places and converted into a list to meet the problem's output requirements.\n\nThis approach ensures that each sequence is normalized and adjusted appropriately, providing a stable output for further processing."}
{"task_id": 110, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to evaluate the quality of a machine translation using the METEOR score. The METEOR score is a metric that combines unigram matches, precision, recall, F-means, and a penalty for word order fragmentation. This score helps in understanding how well the candidate translation matches the reference translation in terms of content and order.\n\n### Approach\nThe approach to compute the METEOR score involves the following steps:\n\n1. **Convert to Lowercase**: Convert both the reference and candidate translations to lowercase to ensure case insensitivity.\n2. **Count Words**: Use a counter to count the occurrences of each word in both the reference and candidate translations.\n3. **Unigram Matches**: Calculate the number of words that are common between the reference and candidate translations.\n4. **Precision and Recall**: Compute precision as the ratio of correct unigrams in the candidate to the total unigrams in the candidate. Compute recall as the ratio of correct unigrams in the candidate to the total unigrams in the reference.\n5. **F-Means**: Calculate the F-means score, which is a weighted harmonic mean of precision and recall, using the given weights alpha and beta.\n6. **Position Matches**: Count the number of words that are in the same position in both the reference and candidate translations. This helps in determining the penalty for word order fragmentation.\n7. **Penalty Calculation**: Apply a penalty based on the number of position mismatches, using the given weight gamma.\n8. **Compute METEOR Score**: Multiply the F-means score by the penalty to get the final METEOR score, which is then rounded to three decimal places.\n\n### Solution Code\n```python\nimport numpy as np\nfrom collections import Counter\n\ndef meteor_score(reference, candidate, alpha=0.9, beta=3, gamma=0.5):\n    ref_lower = reference.lower()\n    cand_lower = candidate.lower()\n\n    ref_counts = Counter(ref_lower.split())\n    cand_counts = Counter(cand_lower.split())\n\n    common_words = ref_counts.keys() & cand_counts.keys()\n    unigram_matches = sum(ref_counts[word] for word in common_words)\n\n    tr = len(ref_counts)\n    tc = len(cand_counts)\n\n    if tc == 0:\n        precision = 0.0\n    else:\n        precision = unigram_matches / tc\n\n    if tr == 0:\n        recall = 0.0\n    else:\n        recall = unigram_matches / tr\n\n    f_mean = (alpha * precision + beta * recall) / (alpha + beta)\n\n    ref_words = ref_lower.split()\n    cand_words = cand_lower.split()\n\n    k = 0\n    for i in range(len(ref_words)):\n        if ref_words[i] != cand_words[i]:\n            k += 1\n\n    penalty = gamma ** k\n\n    meteor = f_mean * penalty\n\n    return round(meteor, 3)\n```\n\n### Explanation\n- **Lowercase Conversion**: This ensures that word comparisons are case-insensitive.\n- **Word Counting**: Using `Counter` from the `collections` module, we count the occurrences of each word in both translations.\n- **Unigram Matches**: By finding the intersection of word counts from both translations, we determine the number of common words, which helps in calculating precision and recall.\n- **Precision and Recall**: These metrics measure how well the candidate translation matches the reference in terms of content.\n- **F-Means**: This combines precision and recall into a single score, providing a balanced view of both metrics.\n- **Position Matches**: This step checks how many words are in the same position in both translations, which is crucial for assessing the order of words.\n- **Penalty Calculation**: This step introduces a penalty for translations where words are out of order, ensuring that the METEOR score reflects both content and order accuracy.\n- **Final Score**: The METEOR score is computed by multiplying the F-means score with the penalty and rounding it to three decimal places for precision."}
{"task_id": 111, "completion_id": 0, "completion": "To solve this problem, we need to compute the Pointwise Mutual Information (PMI) given the joint occurrence counts of two events, their individual counts, and the total number of samples. PMI measures how much the actual joint occurrence of events differs from what we would expect by chance.\n\n### Approach\n1. **Understand PMI Formula**: The PMI for two events A and B is calculated using the formula:\n   \\[\n   PMI(A; B) = \\log_2\\left(\\frac{P(A \\cap B)}{P(A) \\times P(B)}\\right)\n   \\]\n   where \\(P(A \\cap B)\\) is the probability of both A and B occurring, \\(P(A)\\) is the probability of A, and \\(P(B)\\) is the probability of B.\n\n2. **Marginal Counts**: Compute the marginal counts for each event. The marginal count for event X is the sum of joint counts for that row, and similarly for event Y.\n\n3. **Expected Count Calculation**: For each pair of events (i, j), compute the expected count as the product of their marginal counts divided by the total number of samples.\n\n4. **PMI Calculation**: For each pair (i, j), compute the ratio of the observed joint count to the expected count. Take the logarithm base 2 of this ratio to get the PMI for that pair. Sum these PMIs across all pairs to get the total PMI.\n\n### Solution Code\n```python\nimport numpy as np\nimport math\n\ndef compute_pmi(joint_counts, total_counts_x, total_counts_y, total_samples):\n    # Compute marginal counts for X and Y\n    marg_x = np.sum(joint_counts, axis=1)\n    marg_y = np.sum(joint_counts, axis=0)\n    \n    sum_pmi = 0.0\n    \n    for i in range(len(marg_x)):\n        for j in range(len(marg_y)):\n            observed = joint_counts[i][j]\n            if observed == 0:\n                continue  # PMI is 0 if no occurrences\n            # Calculate the expected count\n            expected = (marg_x[i] * marg_y[j]) / total_samples\n            # Compute the ratio\n            ratio = (observed * total_samples) / (marg_x[i] * marg_y[j])\n            # Calculate PMI for this pair\n            pm = math.log(ratio, 2)\n            sum_pmi += pm\n    \n    # Round to 3 decimal places\n    return round(sum_pmi, 3)\n```\n\n### Explanation\n1. **Marginal Counts**: The function first computes the marginal counts for each event by summing the joint counts across the respective dimensions.\n2. **Loop Through Pairs**: For each pair of events (i, j), it checks if the observed count is zero. If so, it skips the calculation for that pair as PMI is zero.\n3. **Expected Count**: The expected count for each pair is calculated using the marginal counts and the total number of samples.\n4. **PMI Calculation**: The ratio of observed to expected counts is computed, and the logarithm base 2 of this ratio gives the PMI for the pair. This value is accumulated for all pairs.\n5. **Return Result**: The total PMI is rounded to three decimal places and returned.\n\nThis approach efficiently computes the PMI by leveraging numpy for marginal sums and handles edge cases where observed counts are zero, ensuring accurate and reliable results."}
{"task_id": 112, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that performs Min-Max normalization on a list of integers. Min-Max normalization scales all values to the range [0, 1], ensuring that all features contribute equally to a model.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n\n1. **Check for Empty List**: If the input list is empty, return an empty list immediately.\n2. **Find Min and Max Values**: Determine the minimum and maximum values in the list. If all values are the same, return a list of zeros.\n3. **Normalize Values**: For each value in the list, compute the normalized value using the formula \\((value - min) / (max - min)\\).\n4. **Round Values**: Round each normalized value to 4 decimal places and return the result.\n\n### Solution Code\n```python\ndef min_max(x: list[int]) -> list[float]:\n    if not x:\n        return []\n    min_x = min(x)\n    max_x = max(x)\n    if min_x == max_x:\n        return [0.0 for _ in x]\n    normalized = [(val - min_x) / (max_x - min_x) for val in x]\n    return [round(num, 4) for num in normalized]\n```\n\n### Explanation\n1. **Check for Empty List**: The function first checks if the input list is empty and returns an empty list if true.\n2. **Find Min and Max Values**: The minimum and maximum values of the list are found using the `min()` and `max()` functions. If the minimum and maximum values are the same, it means all elements in the list are identical, and the function returns a list of zeros.\n3. **Normalize Values**: For each value in the list, the function calculates the normalized value by subtracting the minimum value and dividing by the range (max - min). This ensures that the smallest value becomes 0 and the largest becomes 1.\n4. **Round Values**: Each normalized value is rounded to 4 decimal places to meet the problem's requirements, and the resulting list is returned.\n\nThis approach ensures that all feature values are scaled to a common range, making them suitable for use in models that are sensitive to input scale."}
{"task_id": 113, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a simple residual block using NumPy. The block processes a 1D input array through two weight layers, applies ReLU activations, and adds the original input via a shortcut connection before the final ReLU activation.\n\n### Approach\nThe residual block is designed to process the input through two weight layers, apply ReLU activations, and include a shortcut connection from the original input to the output of the first layer. Here's a step-by-step breakdown of the approach:\n\n1. **First Weight Layer**: Multiply the input array by the first weight matrix to transform the input into a higher-dimensional space.\n2. **First ReLU Activation**: Apply the ReLU function to the output of the first weight layer.\n3. **Shortcut Connection**: Add the original input array to the output of the first ReLU activation to create a shortcut.\n4. **Second ReLU Activation**: Apply the ReLU function to the result of the shortcut addition.\n5. **Second Weight Layer**: Multiply the output of the second ReLU activation by the second weight matrix to produce the final output.\n6. **Rounding and Conversion**: Round the final output to 4 decimal places and convert it to a list.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef residual_block(x: np.ndarray, w1: np.ndarray, w2: np.ndarray):\n    # Compute the first layer output\n    z1 = x.dot(w1)\n    # Apply the first ReLU activation\n    a1 = np.relu(z1)\n    # Add the original input via shortcut connection\n    a1_plus_x = a1 + x\n    # Apply the second ReLU activation\n    a2 = np.relu(a1_plus_x)\n    # Compute the final output using the second weight layer\n    z2 = a2.dot(w2)\n    # Round the output to 4 decimal places and convert to a list\n    return np.round(z2, 4).tolist()\n```\n\n### Explanation\n- **First Weight Layer**: The input array `x` is multiplied by the first weight matrix `w1`, transforming the input into a higher-dimensional space.\n- **First ReLU Activation**: The output of the first weight layer is passed through the ReLU function to introduce non-linearity.\n- **Shortcut Connection**: The original input `x` is added to the output of the first ReLU activation, creating a shortcut that bypasses the first layer.\n- **Second ReLU Activation**: The result of the shortcut addition is passed through another ReLU function.\n- **Second Weight Layer**: The output of the second ReLU activation is multiplied by the second weight matrix `w2` to produce the final output.\n- **Rounding and Conversion**: The final output is rounded to 4 decimal places and converted into a list for the result.\n\nThis approach ensures that the residual block processes the input through two layers, includes a shortcut connection, and applies ReLU activations appropriately, resulting in a robust transformation of the input data."}
{"task_id": 114, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that performs Global Average Pooling on a 3D NumPy array representing feature maps from a convolutional layer. The function should take an input of shape (height, width, channels) and return a 1D array of shape (channels,), where each element is the average of all values in the corresponding feature map.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n1. **Understand the Problem**: Global Average Pooling reduces each feature map to a single value by taking the average of all its elements. The input is a 3D array with shape (height, width, channels), and the output should be a 1D array where each element corresponds to the average of each feature map across the entire image.\n2. **Use NumPy Functions**: Utilize NumPy's built-in functions to efficiently compute the average. Specifically, we use the `np.mean` function to compute the mean along the first two axes (height and width) of the 3D array, which effectively gives us the average for each channel.\n3. **Return the Result**: The result of the mean computation is a 1D array where each element corresponds to the average of each feature map.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef global_avg_pool(x: np.ndarray):\n    return np.mean(x, axis=(0, 1))\n```\n\n### Explanation\n- **Function Definition**: The function `global_avg_pool` takes a NumPy array `x` as input, which is expected to be a 3D array of shape (height, width, channels).\n- **Compute Mean**: The `np.mean` function is used with `axis=(0, 1)` to compute the mean across the first two dimensions (height and width) of the array. This effectively reduces each feature map (each channel) to a single average value.\n- **Return Result**: The result is a 1D array of shape (channels,), where each element is the average of the corresponding feature map across the entire image.\n\nThis approach efficiently computes the global average pooling using NumPy's optimized functions, ensuring that the solution is both concise and performant."}
{"task_id": 115, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a function that performs Batch Normalization on a 4D NumPy array representing a batch of feature maps in the BCHW format (batch, channels, height, width). The function should normalize the input across the batch and spatial dimensions for each channel, then apply scale (gamma) and shift (beta) parameters. Use the provided epsilon value to ensure numerical stability.\n\n### Approach\nThe approach to solve this problem involves the following steps:\n\n1. **Compute Mean and Variance for Each Channel**: For each channel, compute the mean and variance across all batch samples and all spatial positions (height and width). This is done by reducing the dimensions along the batch and spatial axes for each channel.\n\n2. **Normalize the Input**: For each element in the input array, normalize it using the computed mean and variance. This involves subtracting the mean, scaling by the inverse of the variance (plus epsilon to avoid division by zero), then applying the scale factor (gamma) and shift (beta).\n\n3. **Return the Result**: Convert the result to a list of values, rounded to four decimal places.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef batch_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, epsilon: float = 1e-5):\n    # Compute mean and variance for each channel\n    mu = []\n    sigma_sq = []\n    for c in range(X.shape[1]):\n        channel_data = X[:, c, :, :]\n        mu_c = np.mean(channel_data, axis=(0, 2, 3))\n        sigma_c = np.var(channel_data, axis=(0, 2, 3))\n        mu.append(mu_c)\n        sigma_sq.append(sigma_c)\n    mu = np.array(mu)\n    sigma_sq = np.array(sigma_sq)\n    \n    # Compute normalized values\n    normalized = (X - mu[:, np.newaxis, np.newaxis]) / (sigma_sq[:, np.newaxis, np.newaxis] + epsilon)\n    \n    # Apply gamma and beta\n    y = normalized * gamma[:, np.newaxis, np.newaxis] + beta[:, np.newaxis, np.newaxis]\n    \n    # Return as a list rounded to 4 decimal places\n    return y.tolist()\n```\n\n### Explanation\n1. **Compute Mean and Variance**: The function first computes the mean (`mu`) and variance (`sigma_sq`) for each channel. This is done by iterating over each channel, reducing the batch and spatial dimensions, and computing the mean and variance for each channel.\n\n2. **Normalize the Input**: The input array is normalized by subtracting the mean, scaling by the inverse of the variance (with epsilon added to avoid division by zero), then applying the scale factor (gamma) and shift (beta).\n\n3. **Return the Result**: The result is converted to a list of values, each rounded to four decimal places, to meet the problem's requirements.\n\nThis approach ensures that each channel is normalized correctly across all batch samples and spatial positions, providing stable and efficient batch normalization."}
{"task_id": 116, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the derivative of a polynomial term of the form \\( c \\times x^n \\) at a given point \\( x \\). The function should return the value of the derivative, rounded to four decimal places.\n\n### Approach\nThe approach to solve this problem involves applying the power rule of differentiation, which states that the derivative of \\( x^n \\) is \\( n \\times x^{(n-1)} \\). Here are the steps involved:\n\n1. **Compute the New Coefficient**: Multiply the given coefficient \\( c \\) by the exponent \\( n \\). This gives the new coefficient for the derivative term.\n2. **Compute the New Exponent**: Subtract 1 from the exponent \\( n \\) to get the new power of \\( x \\).\n3. **Evaluate the Derivative at Point \\( x \\)**: Raise \\( x \\) to the new exponent and multiply it by the new coefficient.\n4. **Round the Result**: Return the result rounded to four decimal places.\n\nThis approach ensures that we correctly compute the derivative for any given polynomial term, including cases where the exponent is zero or a negative number.\n\n### Solution Code\n```python\ndef poly_term_derivative(c: float, x: float, n: float) -> float:\n    derivative_coeff = c * n\n    new_exponent = n - 1\n    derivative_value = derivative_coeff * (x ** new_exponent)\n    return round(derivative_value, 4)\n```\n\n### Explanation\n- **Compute the New Coefficient**: The coefficient for the derivative term is calculated as \\( c \\times n \\).\n- **Compute the New Exponent**: The exponent for the derivative term is \\( n - 1 \\).\n- **Evaluate the Derivative**: The derivative is evaluated by raising \\( x \\) to the new exponent and multiplying it by the new coefficient.\n- **Round the Result**: The result is rounded to four decimal places to meet the problem's requirements.\n\nThis solution efficiently handles all edge cases, including when the exponent is zero or a negative number, ensuring accurate and reliable results."}
{"task_id": 117, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute an orthonormal basis for the subspace spanned by a list of 2D vectors using the Gram-Schmidt process. The function should take a list of 2D vectors and a tolerance value to determine linear independence, returning a list of orthonormal vectors (unit length and orthogonal to each other) that span the same subspace.\n\n### Approach\nThe Gram-Schmidt process is a method to orthogonalize a set of linearly independent vectors. Here's a step-by-step breakdown of the approach:\n\n1. **Check for Empty Input**: If the input list of vectors is empty, return an empty list immediately.\n2. **Initialize Basis and Result Lists**: Create two lists, `basis` to store the orthonormal vectors (as numpy arrays) and `result` to store the rounded vectors (as lists of floats).\n3. **Iterate Over Each Vector**: For each vector in the input list:\n   - **Subtract Projections**: Project the current vector onto each vector in the current basis and subtract these projections from the current vector.\n   - **Normalize the Result**: Compute the norm of the resulting vector. If the norm is below the specified tolerance, skip this vector.\n   - **Round and Convert**: Normalize the vector to get a unit vector, round it to 4 decimal places, convert it to a list, and add it to the result list.\n   - **Update Basis**: Add the normalized unit vector (as a numpy array) to the basis list.\n4. **Return the Result**: After processing all vectors, return the result list containing the orthonormal vectors.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef orthonormal_basis(vectors: list[list[float]], tol: float = 1e-10):\n    if not vectors:\n        return []\n    \n    basis = []  # List to hold the orthonormal basis vectors (numpy arrays)\n    result = []  # List to hold the rounded vectors\n    \n    for vector in vectors:\n        current = vector.copy()\n        for bv in basis:\n            proj = np.dot(bv, current)\n            current -= proj * bv\n        norm = np.linalg.norm(current)\n        if norm < tol:\n            continue\n        current_unit = current / norm\n        current_unit_rounded = np.round(current_unit, 4).tolist()\n        result.append(current_unit_rounded)\n        basis.append(current_unit)\n    \n    return result\n```\n\n### Explanation\n- **Gram-Schmidt Process**: This process transforms a set of linearly independent vectors into an orthogonal set. Each vector is orthogonalized by subtracting projections onto the previously orthogonalized vectors.\n- **Tolerance Check**: The function checks if the norm of the resulting vector is below the specified tolerance to determine if the vector is linearly dependent on the current basis.\n- **Rounding and Conversion**: Each orthonormal vector is rounded to 4 decimal places and converted to a list to meet the problem's requirements.\n- **Efficiency**: The algorithm efficiently processes each vector, ensuring that only linearly independent vectors contribute to the basis, and handles both 2D and cases with more vectors by limiting the basis to 2 vectors at most.\n\nThis approach ensures that the resulting vectors are orthonormal and span the subspace defined by the input vectors, with each vector rounded to 4 decimal places for precision."}
{"task_id": 118, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to compute the cross product of two 3-dimensional vectors. The cross product of two vectors results in a third vector that is perpendicular to both of the original vectors and follows the right-hand rule. This concept is fundamental in various fields such as physics, engineering, and computer graphics.\n\n### Approach\nThe cross product of two vectors \\( \\mathbf{a} \\) and \\( \\mathbf{b} \\) in three-dimensional space can be computed using the determinant of a matrix formed by the unit vectors \\( \\mathbf{i}, \\mathbf{j}, \\mathbf{k} \\) and the components of the vectors \\( \\mathbf{a} \\) and \\( \\mathbf{b} \\). The formula for the cross product \\( \\mathbf{c} \\) is derived as follows:\n\n1. Extract the components of vectors \\( \\mathbf{a} \\) and \\( \\mathbf{b} \\).\n2. Compute each component of the resulting vector \\( \\mathbf{c} \\) using the following formulas:\n   - \\( c_1 = a_2 \\cdot b_3 - a_3 \\cdot b_2 \\)\n   - \\( c_2 = a_3 \\cdot b_1 - a_1 \\cdot b_3 \\)\n   - \\( c_3 = a_1 \\cdot b_2 - a_2 \\cdot b_1 \\)\n3. Round each component of the resulting vector to four decimal places.\n4. Convert the resulting vector from a numpy array to a list and return it.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef cross_product(a, b):\n    a1, a2, a3 = a[0], a[1], a[2]\n    b1, b2, b3 = b[0], b[1], b[2]\n    c1 = a2 * b3 - a3 * b2\n    c2 = a3 * b1 - a1 * b3\n    c3 = a1 * b2 - a2 * b1\n    result = np.array([c1, c2, c3])\n    rounded = np.round(result, 4)\n    return rounded.tolist()\n```\n\n### Explanation\n1. **Extracting Components**: The components of vectors \\( \\mathbf{a} \\) and \\( \\mathbf{b} \\) are extracted into variables \\( a_1, a_2, a_3 \\) and \\( b_1, b_2, b_3 \\) respectively.\n2. **Computing Cross Product Components**: Using the formulas derived from the determinant method, each component of the resulting vector \\( \\mathbf{c} \\) is computed.\n3. **Rounding and Conversion**: The resulting vector components are rounded to four decimal places and converted into a list for the final output.\n\nThis approach ensures that the cross product is computed efficiently and accurately, adhering to the mathematical definition and returning the result in the required format."}
{"task_id": 119, "completion_id": 0, "completion": "\n\nTo solve a system of linear equations using Cramer's Rule, we need to determine if the system has a unique solution. If the determinant of the coefficient matrix is zero, the system does not have a unique solution, and we return -1. Otherwise, we compute the solution using Cramer's Rule.\n\n### Approach\n1. **Check Determinant**: Calculate the determinant of the coefficient matrix \\( A \\). If the determinant is zero, return -1 as the system does not have a unique solution.\n2. **Compute Solution**: For each column \\( j \\) in \\( A \\), create a new matrix by replacing the \\( j \\)-th column of \\( A \\) with the \\( j \\)-th column of the constant vector \\( b \\). Compute the determinant of this new matrix and divide it by the determinant of \\( A \\) to get the corresponding element of the solution vector \\( x \\).\n3. **Round Results**: Round each element of the solution vector to the nearest 4th decimal place.\n4. **Return Result**: Convert the solution vector to a list and return it.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef cramers_rule(A, b):\n    det_A = np.linalg.det(A)\n    if det_A == 0:\n        return -1\n    n = len(A)\n    x = []\n    for j in range(n):\n        new_A = np.copy(A)\n        new_A[:, j] = b[:, j]\n        det_j = np.linalg.det(new_A)\n        x_j = det_j / det_A\n        x.append(x_j)\n    x = np.round(x, 4)\n    return x.tolist()\n```\n\n### Explanation\n1. **Determinant Check**: The function first computes the determinant of matrix \\( A \\). If the determinant is zero, it returns -1, indicating no unique solution.\n2. **Matrix Replacement**: For each column \\( j \\), a new matrix is created by replacing the \\( j \\)-th column of \\( A \\) with the \\( j \\)-th column of \\( b \\).\n3. **Determinant Calculation**: The determinant of each modified matrix is computed, and each element of the solution vector \\( x \\) is found by dividing this determinant by the determinant of \\( A \\).\n4. **Rounding and Returning**: The solution vector is rounded to four decimal places and converted to a list before being returned.\n\nThis approach ensures that we accurately solve the system of linear equations using Cramer's Rule, handling both the case of a unique solution and the case where no unique solution exists."}
{"task_id": 120, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the Bhattacharyya distance between two discrete probability distributions. The Bhattacharyya distance is a measure of similarity between two distributions and is particularly useful in information theory. The function should handle cases where the inputs are empty or have different lengths by returning 0.0.\n\n### Approach\n1. **Check for Empty Inputs**: If either of the input lists is empty, return 0.0 immediately.\n2. **Check for Different Lengths**: If the lengths of the two lists are different, return 0.0 as the distributions cannot be compared.\n3. **Compute the Bhattacharyya Distance**: For each corresponding pair of probabilities in the two lists, compute the square root of their product and sum these values. This sum is the Bhattacharyya distance.\n4. **Round the Result**: The result is rounded to four decimal places before returning.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef bhattacharyya_distance(p: list[float], q: list[float]) -> float:\n    if not p or not q:\n        return 0.0\n    if len(p) != len(q):\n        return 0.0\n    total = 0.0\n    for pi, qi in zip(p, q):\n        total += np.sqrt(pi * qi)\n    return round(total, 4)\n```\n\n### Explanation\n- **Empty Check**: The function first checks if either input list is empty. If so, it returns 0.0 because an empty distribution cannot be compared.\n- **Length Check**: The function then checks if the lengths of the two lists are different. If they are, it returns 0.0 as the distributions cannot be aligned for comparison.\n- **Bhattacharyya Calculation**: For each pair of probabilities from the two lists, the function computes the product, takes the square root of this product, and accumulates the sum of these values.\n- **Rounding**: The accumulated sum is rounded to four decimal places to meet the problem's requirements.\n\nThis approach ensures that the function handles edge cases gracefully and efficiently computes the Bhattacharyya distance for valid inputs."}
{"task_id": 121, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to write a function that computes the element-wise sum of two vectors (lists). The function should return a new list representing the resulting sum if the vectors have the same length, or -1 if they do not.\n\n### Approach\n1. **Check Vector Lengths**: First, we check if the lengths of the two input lists are equal. If they are not, we return -1 because vectors can only be summed element-wise if they have the same number of elements.\n2. **Element-wise Summation**: If the lengths are the same, we proceed to compute the element-wise sum. We use a list comprehension to iterate through each corresponding pair of elements from the two lists, sum them, and collect the results into a new list.\n3. **Return Result**: The resulting list of sums is returned.\n\nThis approach ensures that we handle both valid and invalid cases efficiently. The function is designed to be concise and leverages Python's list comprehension for clarity and brevity.\n\n### Solution Code\n```python\ndef vector_sum(a: list[int|float], b: list[int|float]) -> list[int|float]:\n    if len(a) != len(b):\n        return -1\n    return [a[i] + b[i] for i in range(len(a))]\n```\n\n### Explanation\n- **Check Lengths**: The function first checks if the lengths of the two input lists `a` and `b` are the same. If they are not, it returns -1.\n- **List Comprehension**: If the lengths are the same, the function uses a list comprehension to iterate over each index, sum the corresponding elements from `a` and `b`, and create a new list of these sums.\n- **Return Result**: The resulting list of sums is returned as the output.\n\nThis solution efficiently handles both valid and invalid cases, ensuring that the function behaves correctly for all possible inputs."}
{"task_id": 122, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the policy gradient estimator using the REINFORCE algorithm. The policy is parameterized by a 2D NumPy array `theta` of shape `(num_states, num_actions)`. For each state, the policy is computed using softmax over `theta[s, :]`. Given a list of episodes, each consisting of a list of (state, action, reward) tuples, we compute the average gradient of the log-policy multiplied by the return at each time step.\n\n### Approach\n1. **Initialize Variables**: We start by initializing a variable to accumulate the total gradient and a counter for the number of samples.\n2. **Process Each Episode**: For each episode, we reverse the list of steps to process from the last step to the first.\n3. **Compute Return**: For each step in the reversed episode, we compute the return by discounting future rewards with a discount factor `gamma`.\n4. **Log Probability and Gradient**: For each step, we compute the log probability of the action taken using the current policy parameters. We then accumulate the gradient by multiplying the log probability with the return.\n5. **Average Gradient**: After processing all episodes, we compute the average gradient by dividing the total gradient by the number of samples.\n6. **Return Result**: The result is rounded to four decimal places and converted to a list before being returned.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef compute_policy_gradient(theta: np.ndarray, episodes: list[list[tuple[int, int, float]]]) -> list:\n    gamma = 0.99  # Discount factor\n    total_gradient = 0.0\n    num_samples = 0\n    \n    for episode in episodes:\n        steps = episode\n        reversed_steps = steps[::-1]\n        return_val = 0.0\n        \n        for state, action, reward in reversed_steps:\n            return_val = reward + gamma * return_val\n            p = np.softmax(theta[state, action])\n            log_p = np.log(p)\n            total_gradient += log_p * return_val\n            num_samples += 1\n    \n    if num_samples == 0:\n        average = 0.0\n    else:\n        average = total_gradient / num_samples\n    \n    average = round(average, 4)\n    return average.tolist()\n```\n\n### Explanation\n- **Initialization**: We initialize `total_gradient` to accumulate the gradients and `num_samples` to count the number of steps processed.\n- **Episode Processing**: Each episode is processed in reverse order to compute the return values correctly.\n- **Return Calculation**: For each step, the return is updated by adding the current reward to the discounted future returns.\n- **Log Probability**: The log probability of the action is computed using the current policy parameters, which are given by `theta`.\n- **Gradient Accumulation**: The gradient for each step is accumulated by multiplying the log probability with the return value.\n- **Average Calculation**: The total gradient is averaged over all samples and rounded to four decimal places before being returned as a list.\n\nThis approach efficiently computes the policy gradient using the REINFORCE algorithm, providing a clear and concise solution to the problem."}
{"task_id": 123, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to calculate the computational efficiency of a MoE (Mixture-of-Experts) layer compared to a dense layer. The goal is to determine the percentage of floating-point operations (FLOPs) saved by using MoE instead of a dense layer.\n\n### Approach\n1. **Understanding the Problem**: \n   - A MoE layer distributes the input across multiple experts, where only a subset of these experts (determined by the sparsity parameter) are active for each input.\n   - A dense layer, on the other hand, uses all experts for every input.\n   - We need to compute the FLOPs for both layers and determine the savings percentage when using MoE.\n\n2. **FLOP Calculation**:\n   - For a MoE layer, the FLOPs are calculated as the sum of the operations for the active experts. Each active expert contributes operations for both the input and output processing.\n   - For a dense layer, all experts are active, so the FLOPs are calculated considering all experts.\n\n3. **Savings Calculation**:\n   - The savings are computed as the difference between the FLOPs of the dense layer and the MoE layer, divided by the FLOPs of the dense layer, multiplied by 100 to get a percentage.\n\n### Solution Code\n```python\ndef compute_efficiency(n_experts, k_active, d_in, d_out):\n    moe_flops = k_active * (d_in + d_out)\n    dense_flops = n_experts * (d_in + d_out)\n    if dense_flops == 0:\n        return 0.0  # Prevent division by zero, though it's unlikely given valid inputs\n    savings = ((dense_flops - moe_flops) / dense_flops) * 100\n    return round(savings, 1)\n```\n\n### Explanation\n- **MoE FLOPs Calculation**: The FLOPs for the MoE layer are computed as `k_active * (d_in + d_out)`, where `k_active` is the number of active experts, and `d_in` and `d_out` are the input and output dimensions respectively.\n- **Dense FLOPs Calculation**: The FLOPs for the dense layer are computed as `n_experts * (d_in + d_out)`, where `n_experts` is the total number of experts.\n- **Savings Calculation**: The savings are calculated by taking the difference between the dense layer's FLOPs and the MoE layer's FLOPs, dividing by the dense layer's FLOPs, and converting it to a percentage. The result is then rounded to one decimal place.\n\nThis approach efficiently computes the computational savings of using MoE over a dense layer, providing a clear and concise solution to the problem."}
{"task_id": 124, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Noisy Top-K Gating mechanism used in Mixture-of-Experts (MoE) models. This mechanism helps in determining the contribution of each expert in the model by adding noise to the gating probabilities and then selecting the top-K gates based on a sparsity constraint.\n\n### Approach\nThe approach involves the following steps:\n1. **Compute Initial Gating Probabilities**: Using the input matrix `X` and the weight matrix `W_g`, compute the initial gating probabilities by taking the softmax of the product of these matrices.\n2. **Add Noise**: Add the pre-sampled noise matrix `W_noise` to the initial gating probabilities.\n3. **Apply Sparsity Constraint**: For each row of the resulting matrix, sort the elements in descending order, select the top-K elements, normalize these elements to ensure their sum is 1, and set the remaining elements to zero. This ensures that exactly K gates are active for each input.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef noisy_topk_gating(\n    X: np.ndarray,\n    W_g: np.ndarray,\n    W_noise: np.ndarray,\n    N: np.ndarray,\n    k: int\n) -> list:\n    # Compute initial gates\n    gates = np.softmax(X @ W_g)\n    \n    # Add noise\n    gates_with_noise = gates + W_noise\n    \n    # Process each row to apply sparsity\n    final_gates = []\n    for i in range(gates_with_noise.shape[0]):\n        row = gates_with_noise[i]\n        # Sort in descending order\n        sorted_row = np.sort(row, reverse=True)\n        # Take top k elements\n        topk = sorted_row[:k]\n        # Compute sum of top k\n        sum_topk = np.sum(topk)\n        if sum_topk == 0:\n            # All zeros, set to zero\n            final_row = np.zeros_like(topk)\n        else:\n            final_row = topk / sum_topk\n        final_gates.append(final_row)\n    \n    # Reshape and convert to list\n    final_gates = np.array(final_gates)\n    final_gates = final_gates.reshape(-1)\n    # Round to nearest 4th decimal\n    rounded = np.round(final_gates, 4)\n    return rounded.tolist()\n```\n\n### Explanation\n1. **Initial Gating Probabilities**: The initial gating probabilities are computed using the softmax function on the product of the input matrix `X` and the weight matrix `W_g`. This gives a matrix where each row represents the probability of each expert being the most relevant for the corresponding input feature.\n2. **Adding Noise**: The pre-sampled noise matrix `W_noise` is added to the initial gating probabilities. This introduces noise, preventing the gates from being too similar and improving the model's generalization.\n3. **Applying Sparsity Constraint**: For each row in the matrix after adding noise, the elements are sorted in descending order. The top-K elements are selected, normalized by their sum, and the remaining elements are set to zero. This ensures that exactly K gates are active for each input, adhering to the sparsity constraint.\n\nThis approach ensures that the model benefits from the noise added to the gates while maintaining the required sparsity, leading to improved performance and generalization."}
{"task_id": 125, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement a Sparse Mixture of Experts (MoE) layer using softmax gating and top-k routing. The goal is to compute the final output by selecting the top-k experts per token, applying their transformations, and aggregating the results weighted by the normalized gating probabilities.\n\n### Approach\n1. **Compute Gating Scores**: For each token, compute the gating scores using the gating weight matrix and the input tensor.\n2. **Compute Gating Probabilities**: Normalize the gating scores using the softmax function to get the probabilities for each expert.\n3. **Select Top-K Experts**: For each token, identify the top-k experts based on their gating probabilities.\n4. **Compute Expert Outputs**: For each selected expert, compute their output using their respective weight matrix.\n5. **Aggregate Outputs**: Sum the outputs of the selected experts, each multiplied by their respective gating probabilities.\n6. **Round Results**: Round the aggregated output to the nearest 4th decimal place.\n7. **Return Results**: Convert the results into a list of lists, each representing the output for a token.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef moe(x: np.ndarray, We: np.ndarray, Wg: np.ndarray, n_experts: int, top_k: int):\n    # Compute the gating scores\n    scores = Wg @ x\n    # Compute the probabilities\n    probs = np.softmax(scores, axis=1)\n    # Initialize the output list\n    output = []\n    # Number of tokens in the sequence\n    seq_len = x.shape[1]\n    # Iterate over each token\n    for i in range(seq_len):\n        # Get the scores for the current token\n        token_scores = scores[:, i]\n        # Find the indices of the top-k experts\n        sorted_indices = np.argsort(-token_scores, axis=0)[:top_k]\n        # Calculate the output for the current token\n        sum_output = 0\n        for j in sorted_indices:\n            # Compute the expert's output\n            expert_output = We[j] @ x[i]\n            # Multiply by the corresponding probability\n            prob = probs[j][i]\n            sum_output += expert_output * prob\n        # Round the output to 4 decimal places\n        sum_output = np.round(sum_output, 4)\n        output.append(sum_output)\n    # Convert the output to a list of lists\n    return output.tolist()\n```\n\n### Explanation\n- **Gating Scores and Probabilities**: The gating scores are computed by multiplying the gating weight matrix with the input tensor. These scores are then normalized using the softmax function to get the probabilities for each expert.\n- **Top-K Selection**: For each token, the experts are sorted based on their gating probabilities, and the top-k experts are selected.\n- **Expert Outputs and Aggregation**: For each selected expert, their output is computed using their weight matrix. These outputs are then aggregated by summing them up, each weighted by their respective probabilities.\n- **Rounding and Returning Results**: The aggregated output is rounded to four decimal places and returned as a list of lists, each representing the output for a token.\n\nThis approach efficiently combines the contributions of the top-k experts for each token, ensuring that the final output is a weighted sum of their transformations, providing a robust and efficient solution to the problem."}
{"task_id": 126, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement group normalization on a 4D input tensor with shape (B, C, H, W). Group normalization involves normalizing each group of channels across the batch dimension, then applying a learned scale (gamma) and shift (beta) to each channel.\n\n### Approach\n1. **Reshape the Input Tensor**: Convert the input tensor from shape (B, C, H, W) to (B, H, W, C) to facilitate processing each group of channels.\n2. **Group the Channels**: Divide the channels into `num_groups`, each of size `C // num_groups`.\n3. **Compute Mean and Variance for Each Group**: For each group, compute the mean and variance across the batch and spatial dimensions (B, H, W).\n4. **Normalize Each Channel**: For each channel in the group, normalize it using the group's mean and variance, then apply the learned scale (gamma) and shift (beta).\n5. **Reshape Back to Original Shape**: After processing, reshape the tensor back to the original shape (B, C, H, W) and convert it to a list of numbers, rounded to the nearest 4th decimal.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef group_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, num_groups: int, epsilon: float = 1e-5):\n    # Get the shape of the input tensor\n    B, C, H, W = X.shape\n    \n    # Make a copy of the input tensor to avoid modifying the original\n    X_copy = X.copy()\n    \n    # Reshape the tensor to (B, H, W, C) for easier processing\n    X_copy = X_copy.reshape(B, H, W, C)\n    \n    group_size = C // num_groups\n    \n    # Iterate over each group of channels\n    for i in range(num_groups):\n        # Slice the current group of channels\n        start = i * group_size\n        end = start + group_size\n        group = X_copy[:, :, :, start:end]\n        \n        # Compute the mean across B, H, W dimensions\n        mean = np.mean(group, axis=(0, 1, 2))\n        \n        # Compute the variance across B, H, W dimensions\n        var = np.mean((group - mean)**2, axis=(0, 1, 2))\n        \n        # Normalize, scale, and shift each channel in the group\n        for j in range(group_size):\n            # Normalize the channel\n            normalized = (group[j] - mean[j]) / (np.sqrt(var[j]) + epsilon)\n            \n            # Apply scaling and shifting\n            scaled = normalized * gamma[j] + beta[j]\n            \n            # Update the corresponding position in the copy\n            X_copy[:, :, :, start + j] = scaled\n    \n    # Reshape the tensor back to the original shape (B, C, H, W)\n    X_normalized = X_copy.reshape(B, C, H, W)\n    \n    # Round to the nearest 4th decimal\n    X_normalized = np.round(X_normalized, 4)\n    \n    # Convert the tensor to a list\n    return X_normalized.tolist()\n```\n\n### Explanation\n1. **Reshaping**: The input tensor is reshaped to (B, H, W, C) to facilitate processing each group of channels.\n2. **Group Processing**: Each group of channels is processed by computing the mean and variance across the batch and spatial dimensions. This ensures that each group is normalized independently.\n3. **Normalization and Scaling**: Each channel in the group is normalized using the group's mean and variance, then scaled and shifted using the provided gamma and beta values.\n4. **Reshaping Back**: After processing, the tensor is reshaped back to the original shape (B, C, H, W) and converted to a list of numbers, ensuring the results are rounded to the nearest 4th decimal for precision.\n\nThis approach ensures that each group of channels is normalized and scaled appropriately, leading to more stable features during training and inference."}
{"task_id": 127, "completion_id": 0, "completion": "To solve this problem, we need to find the x-value where the function \\( f(x) = x^4 - 3x^3 + 2 \\) reaches its minimum value. This can be efficiently achieved using the gradient descent algorithm, which iteratively adjusts the x-value to move towards the minimum of the function.\n\n### Approach\n1. **Problem Analysis**: The function \\( f(x) = x^4 - 3x^3 + 2 \\) is a quartic function, which is known to have a single global minimum. The first derivative \\( f'(x) = 4x^3 - 9x^2 \\) helps in determining the critical points, and the second derivative \\( f''(x) = 12x^2 - 18x \\) confirms the nature of these critical points. The critical point at \\( x = 2.25 \\) is identified as the global minimum.\n\n2. **Algorithm Selection**: We use the gradient descent algorithm, which is an iterative optimization algorithm that adjusts the model's parameters to minimize the error. The update rule is \\( x_{n+1} = x_n - \\text{learning\\_rate} \\times f'(x_n) \\).\n\n3. **Stopping Condition**: The algorithm stops when the change in x-value is below a specified tolerance (1e-6) or when the maximum number of iterations (10000) is reached.\n\n4. **Implementation**: The function initializes with the given starting x-value and iteratively updates it using the gradient descent rule. The process continues until the stopping condition is met, ensuring convergence to the minimum value.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef find_treasure(start_x: float, learning_rate: float = 0.1, tolerance: float = 1e-6, max_iters: int = 10000) -> float:\n    x = start_x\n    for _ in range(max_iters):\n        f_prime = 4 * x**3 - 9 * x**2\n        step = learning_rate * f_prime\n        x -= step\n        if abs(step) < tolerance:\n            break\n    return round(x, 4)\n```\n\n### Explanation\n- **Initialization**: The function starts with the given initial x-value.\n- **Iteration**: For each iteration, the derivative of the function is computed to determine the gradient. The x-value is then updated by subtracting the product of the gradient and the learning rate.\n- **Stopping Condition**: The loop breaks if the change in x-value (step) is smaller than the tolerance, indicating convergence to the minimum.\n- **Return**: The function returns the x-value rounded to four decimal places after the loop completes.\n\nThis approach ensures that we efficiently find the minimum value of the function using gradient descent, providing an accurate result within the specified constraints."}
{"task_id": 128, "completion_id": 0, "completion": "\n\nTo solve this problem, we need to implement the Dynamic Tanh (DyT) function, which is a normalization-free transformation inspired by the Tanh function. This function is designed to replace layer normalization in Transformer architectures while preserving squashing behavior and enabling stable training.\n\n### Approach\nThe Dynamic Tanh (DyT) function is defined as:\n\\[ y = (x \\cdot \\gamma + \\beta) \\cdot (1 - \\alpha \\cdot (1 - \\tanh(\\frac{x}{\\gamma}))) \\]\nwhere:\n- \\( x \\) is the input numpy array.\n- \\( \\alpha \\), \\( \\gamma \\), and \\( \\beta \\) are the given parameters.\n\nThe function works as follows:\n1. Compute the hyperbolic tangent (tanh) of \\( \\frac{x}{\\gamma} \\) for each element in the input array.\n2. Calculate the scaling factor using the formula \\( 1 - \\alpha \\cdot (1 - \\tanh(\\frac{x}{\\gamma})) \\).\n3. Multiply the scaled factor by the result of \\( (x \\cdot \\gamma + \\beta) \\) to get the output.\n4. Round the resulting values to four decimal places and convert the numpy array to a list of floats.\n\n### Solution Code\n```python\nimport numpy as np\n\ndef dynamic_tanh(x: np.ndarray, alpha: float, gamma: float, beta: float) -> list[float]:\n    tanh_x = np.tanh(x / gamma)\n    y = (x * gamma + beta) * (1 - alpha * (1 - tanh_x))\n    y = np.round(y, 4).tolist()\n    return y\n```\n\n### Explanation\n- **Input Handling**: The function takes a numpy array `x` and three scalar parameters `alpha`, `gamma`, and `beta`.\n- **Tanh Calculation**: The hyperbolic tangent of \\( \\frac{x}{\\gamma} \\) is computed for each element in `x`.\n- **Scaling Factor**: The scaling factor is derived from the expression \\( 1 - \\alpha \\cdot (1 - \\tanh(\\frac{x}{\\gamma})) \\), which adjusts the output range based on the provided parameters.\n- **Output Transformation**: The scaled factor is multiplied by \\( (x \\cdot \\gamma + \\beta) \\) to transform the input values.\n- **Rounding and Conversion**: The resulting values are rounded to four decimal places and converted into a list of floats for the final output.\n\nThis approach ensures that the function mimics the behavior of the standard Tanh function while providing the benefits of a normalization-free transformation, making it suitable for use in Transformer architectures."}
