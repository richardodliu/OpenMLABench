{"task_id": 1, "completion_id": 0, "solution": ""}
{"task_id": 2, "completion_id": 0, "solution": ""}
{"task_id": 3, "completion_id": 0, "solution": ""}
{"task_id": 4, "completion_id": 0, "solution": ""}
{"task_id": 5, "completion_id": 0, "solution": ""}
{"task_id": 6, "completion_id": 0, "solution": ""}
{"task_id": 7, "completion_id": 0, "solution": ""}
{"task_id": 8, "completion_id": 0, "solution": ""}
{"task_id": 9, "completion_id": 0, "solution": ""}
{"task_id": 10, "completion_id": 0, "solution": ""}
{"task_id": 11, "completion_id": 0, "solution": ""}
{"task_id": 12, "completion_id": 0, "solution": ""}
{"task_id": 13, "completion_id": 0, "solution": ""}
{"task_id": 14, "completion_id": 0, "solution": ""}
{"task_id": 15, "completion_id": 0, "solution": ""}
{"task_id": 16, "completion_id": 0, "solution": ""}
{"task_id": 17, "completion_id": 0, "solution": ""}
{"task_id": 18, "completion_id": 0, "solution": ""}
{"task_id": 19, "completion_id": 0, "solution": ""}
{"task_id": 20, "completion_id": 0, "solution": "import math\nfrom collections import Counter\ndef learn_decision_tree(examples: list[dict], attributes: list[str], target_attr: str) -> dict:\n\n    def entropy(class_counts: Counter) -> float:\n        total_count = sum(class_counts.values())\n        if total_count == 0:\n            return 0\n        return -sum((count / total_count * math.log2(count / total_count) for count in class_counts.values()))\n\n    def information_gain(examples: list[dict], attribute: str, target_attr: str) -> float:\n        class_counts = Counter((example[target_attr] for example in examples))\n        base_entropy = entropy(class_counts)\n        weighted_entropy = 0\n        for value in set((example[attribute] for example in examples)):\n            subset = [example for example in examples if example[attribute] == value]\n            subset_entropy = entropy(Counter((example[target_attr] for example in subset)))\n            weighted_entropy += len(subset) / len(examples) * subset_entropy\n        return base_entropy - weighted_entropy\n\n    def choose_best_attribute(examples: list[dict], attributes: list[str], target_attr: str) -> str:\n        best_attribute = None\n        max_gain = -1\n        for attribute in attributes:\n            gain = information_gain(examples, attribute, target_attr)\n            if gain > max_gain:\n                max_gain = gain\n                best_attribute = attribute\n        return best_attribute\n\n    def majority_value(examples: list[dict], target_attr: str) -> str:\n        return Counter((example[target_attr] for example in examples)).most_common(1)[0][0]\n    if not examples:\n        return {}\n    target_values = [example[target_attr] for example in examples]\n    if len(set(target_values)) == 1:\n        return target_values[0]\n    if not attributes:\n        return majority_value(examples, target_attr)\n    best_attribute = choose_best_attribute(examples, attributes, target_attr)\n    tree = {best_attribute: {}}\n    for value in set((example[best_attribute] for example in examples)):\n        subset = [example for example in examples if example[best_attribute] == value]\n        remaining_attributes = [attr for attr in attributes if attr != best_attribute]\n        subtree = learn_decision_tree(subset, remaining_attributes, target_attr)\n        tree[best_attribute][value] = subtree\n    return tree"}
{"task_id": 21, "completion_id": 0, "solution": ""}
{"task_id": 22, "completion_id": 0, "solution": ""}
{"task_id": 23, "completion_id": 0, "solution": ""}
{"task_id": 24, "completion_id": 0, "solution": ""}
{"task_id": 25, "completion_id": 0, "solution": ""}
{"task_id": 26, "completion_id": 0, "solution": ""}
{"task_id": 27, "completion_id": 0, "solution": ""}
{"task_id": 28, "completion_id": 0, "solution": ""}
{"task_id": 29, "completion_id": 0, "solution": ""}
{"task_id": 30, "completion_id": 0, "solution": ""}
{"task_id": 31, "completion_id": 0, "solution": ""}
{"task_id": 32, "completion_id": 0, "solution": ""}
{"task_id": 33, "completion_id": 0, "solution": ""}
{"task_id": 34, "completion_id": 0, "solution": ""}
{"task_id": 35, "completion_id": 0, "solution": ""}
{"task_id": 36, "completion_id": 0, "solution": ""}
{"task_id": 37, "completion_id": 0, "solution": ""}
{"task_id": 38, "completion_id": 0, "solution": ""}
{"task_id": 39, "completion_id": 0, "solution": ""}
{"task_id": 40, "completion_id": 0, "solution": "import numpy as np\nimport copy\nimport math\nclass Layer(object):\n\n    def set_input_shape(self, shape):\n        self.input_shape = shape\n\n    def layer_name(self):\n        return self.__class__.__name__\n\n    def parameters(self):\n        return 0\n\n    def forward_pass(self, X, training):\n        raise NotImplementedError()\n\n    def backward_pass(self, accum_grad):\n        raise NotImplementedError()\n\n    def output_shape(self):\n        raise NotImplementedError()\nclass Dense(Layer):\n\n    def __init__(self, n_units, input_shape=None):\n        self.layer_input = None\n        self.input_shape = input_shape\n        self.n_units = n_units\n        self.trainable = True\n        self.W = None\n        self.w0 = None\n        self.W_opt = None\n        self.w0_opt = None\n\n    def initialize(self, optimizer):\n        self.W = np.random.uniform(-1 / math.sqrt(self.input_shape[0]), 1 / math.sqrt(self.input_shape[0]), (self.input_shape[0], self.n_units))\n        self.w0 = np.zeros((1, self.n_units))\n        self.W_opt = copy.deepcopy(optimizer)\n        self.w0_opt = copy.deepcopy(optimizer)\n\n    def parameters(self):\n        return np.prod(self.W.shape) + np.prod(self.w0.shape)\n\n    def forward_pass(self, X, training=True):\n        self.layer_input = X\n        return np.dot(X, self.W) + self.w0\n\n    def backward_pass(self, accum_grad):\n        if self.trainable:\n            grad_w = np.dot(self.layer_input.T, accum_grad)\n            grad_w0 = np.sum(accum_grad, axis=0, keepdims=True)\n            self.W = self.W_opt.update(self.W, grad_w)\n            self.w0 = self.w0_opt.update(self.w0, grad_w0)\n        input_layer_grad = np.dot(accum_grad, self.W.T)\n        return input_layer_grad\n\n    def output_shape(self):\n        return (self.n_units,)"}
{"task_id": 41, "completion_id": 0, "solution": ""}
{"task_id": 42, "completion_id": 0, "solution": ""}
{"task_id": 43, "completion_id": 0, "solution": ""}
{"task_id": 44, "completion_id": 0, "solution": ""}
{"task_id": 45, "completion_id": 0, "solution": ""}
{"task_id": 46, "completion_id": 0, "solution": ""}
{"task_id": 47, "completion_id": 0, "solution": ""}
{"task_id": 48, "completion_id": 0, "solution": ""}
{"task_id": 49, "completion_id": 0, "solution": ""}
{"task_id": 50, "completion_id": 0, "solution": ""}
{"task_id": 51, "completion_id": 0, "solution": ""}
{"task_id": 52, "completion_id": 0, "solution": ""}
{"task_id": 53, "completion_id": 0, "solution": ""}
{"task_id": 54, "completion_id": 0, "solution": ""}
{"task_id": 55, "completion_id": 0, "solution": "import numpy as np\ndef translate_object(points, tx, ty):\n    translation_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])\n    homogeneous_points = np.array([[x, y, 1] for (x, y) in points])\n    translated_homogeneous_points = np.dot(homogeneous_points, translation_matrix.T)\n    translated_points = translated_homogeneous_points[:, :2]\n    return translated_points.tolist()\npoints = [[1, 2], [3, 4], [5, 6]]\ntx = 2\nty = 3\ntranslated_points = translate_object(points, tx, ty)"}
{"task_id": 56, "completion_id": 0, "solution": ""}
{"task_id": 57, "completion_id": 0, "solution": ""}
{"task_id": 58, "completion_id": 0, "solution": ""}
{"task_id": 59, "completion_id": 0, "solution": ""}
{"task_id": 60, "completion_id": 0, "solution": ""}
{"task_id": 61, "completion_id": 0, "solution": ""}
{"task_id": 62, "completion_id": 0, "solution": ""}
{"task_id": 63, "completion_id": 0, "solution": ""}
{"task_id": 64, "completion_id": 0, "solution": ""}
{"task_id": 65, "completion_id": 0, "solution": ""}
{"task_id": 66, "completion_id": 0, "solution": ""}
{"task_id": 67, "completion_id": 0, "solution": ""}
{"task_id": 68, "completion_id": 0, "solution": ""}
{"task_id": 69, "completion_id": 0, "solution": ""}
{"task_id": 70, "completion_id": 0, "solution": ""}
{"task_id": 71, "completion_id": 0, "solution": ""}
{"task_id": 72, "completion_id": 0, "solution": ""}
{"task_id": 73, "completion_id": 0, "solution": ""}
{"task_id": 74, "completion_id": 0, "solution": ""}
{"task_id": 75, "completion_id": 0, "solution": ""}
{"task_id": 76, "completion_id": 0, "solution": ""}
{"task_id": 77, "completion_id": 0, "solution": ""}
{"task_id": 78, "completion_id": 0, "solution": ""}
{"task_id": 79, "completion_id": 0, "solution": ""}
{"task_id": 80, "completion_id": 0, "solution": ""}
{"task_id": 81, "completion_id": 0, "solution": ""}
{"task_id": 82, "completion_id": 0, "solution": ""}
{"task_id": 83, "completion_id": 0, "solution": ""}
{"task_id": 84, "completion_id": 0, "solution": ""}
{"task_id": 85, "completion_id": 0, "solution": ""}
{"task_id": 86, "completion_id": 0, "solution": ""}
{"task_id": 87, "completion_id": 0, "solution": ""}
{"task_id": 88, "completion_id": 0, "solution": "import numpy as np\ndef load_encoder_hparams_and_params(model_size: str='124M', models_dir: str='models'):\n\n    class DummyBPE:\n\n        def __init__(self):\n            self.encoder_dict = {'hello': 1, 'world': 2, '<UNK>': 0}\n\n        def encode(self, text: str):\n            tokens = text.strip().split()\n            return [self.encoder_dict.get(token, self.encoder_dict['<UNK>']) for token in tokens]\n\n        def decode(self, token_ids: list):\n            reversed_dict = {v: k for (k, v) in self.encoder_dict.items()}\n            return ' '.join([reversed_dict.get(tok_id, '<UNK>') for tok_id in token_ids])\n    hparams = {'n_ctx': 1024, 'n_head': 12}\n    params = {'wte': np.random.rand(3, 10), 'wpe': np.random.rand(1024, 10), 'blocks': [], 'ln_f': {'g': np.ones(10), 'b': np.zeros(10)}}\n    encoder = DummyBPE()\n    return (encoder, hparams, params)\ndef layer_norm(x, g, b, eps: float=1e-05):\n    mean = np.mean(x, axis=-1, keepdims=True)\n    variance = np.var(x, axis=-1, keepdims=True)\n    return g * (x - mean) / np.sqrt(variance + eps) + b\ndef feed_forward(x, params):\n    hidden = np.tanh(np.matmul(x, params['c_fc']))\n    output = np.matmul(hidden, params['c_proj'])\n    return output\ndef multi_head_attention(x, params, n_head):\n    (B, T, C) = x.shape\n    q = np.matmul(x, params['q_proj'])\n    k = np.matmul(x, params['k_proj'])\n    v = np.matmul(x, params['v_proj'])\n    q = q.reshape(B, T, n_head, C // n_head).transpose(0, 2, 1, 3)\n    k = k.reshape(B, T, n_head, C // n_head).transpose(0, 2, 1, 3)\n    v = v.reshape(B, T, n_head, C // n_head).transpose(0, 2, 1, 3)\n    att = np.matmul(q, k.transpose(0, 1, 3, 2)) * (1.0 / np.sqrt(k.shape[-1]))\n    att = np.exp(att - np.max(att, axis=-1, keepdims=True))\n    att = att / np.sum(att, axis=-1, keepdims=True)\n    y = np.matmul(att, v).transpose(0, 2, 1, 3).reshape(B, T, C)\n    y = np.matmul(y, params['out_proj'])\n    return y\ndef gen_text(prompt: str, n_tokens_to_generate: int=40):\n    (encoder, hparams, params) = load_encoder_hparams_and_params()\n    n_ctx = hparams['n_ctx']\n    n_head = hparams['n_head']\n    params['blocks'].append({'attn': {'q_proj': np.random.rand(10, 10), 'k_proj': np.random.rand(10, 10), 'v_proj': np.random.rand(10, 10), 'out_proj': np.random.rand(10, 10)}, 'ln_1': {'g': np.ones(10), 'b': np.zeros(10)}, 'mlp': {'c_fc': np.random.rand(10, 20), 'c_proj': np.random.rand(20, 10)}, 'ln_2': {'g': np.ones(10), 'b': np.zeros(10)}})\n    input_ids = encoder.encode(prompt)\n    input_ids = np.array(input_ids)[:n_ctx]\n    for _ in range(n_tokens_to_generate):\n        if len(input_ids) >= n_ctx:\n            input_ids = input_ids[-n_ctx:]\n        token_embeddings = params['wte'][input_ids]\n        positions = np.arange(len(input_ids))\n        positional_embeddings = params['wpe'][positions]\n        x = token_embeddings + positional_embeddings\n        for block in params['blocks']:\n            attn_output = multi_head_attention(x, block['attn'], n_head)\n            x = x + attn_output\n            x = layer_norm(x, block['ln_1']['g'], block['ln_1']['b'])\n            mlp_output = feed_forward(x, block['mlp'])\n            x = x + mlp_output\n            x = layer_norm(x, block['ln_2']['g'], block['ln_2']['b'])\n        x = layer_norm(x, params['ln_f']['g'], params['ln_f']['b'])\n        logits = np.matmul(x[-1], params['wte'].T)\n        next_token_id = np.argmax(logits, axis=-1)\n        input_ids = np.append(input_ids, next_token_id)\n    generated_text = encoder.decode(input_ids)\n    return generated_text"}
{"task_id": 89, "completion_id": 0, "solution": ""}
{"task_id": 90, "completion_id": 0, "solution": ""}
{"task_id": 91, "completion_id": 0, "solution": ""}
{"task_id": 92, "completion_id": 0, "solution": ""}
{"task_id": 93, "completion_id": 0, "solution": ""}
{"task_id": 94, "completion_id": 0, "solution": ""}
{"task_id": 95, "completion_id": 0, "solution": ""}
{"task_id": 96, "completion_id": 0, "solution": ""}
{"task_id": 97, "completion_id": 0, "solution": ""}
{"task_id": 98, "completion_id": 0, "solution": ""}
{"task_id": 99, "completion_id": 0, "solution": ""}
{"task_id": 100, "completion_id": 0, "solution": ""}
{"task_id": 101, "completion_id": 0, "solution": ""}
{"task_id": 102, "completion_id": 0, "solution": ""}
{"task_id": 103, "completion_id": 0, "solution": ""}
{"task_id": 104, "completion_id": 0, "solution": ""}
{"task_id": 105, "completion_id": 0, "solution": ""}
{"task_id": 106, "completion_id": 0, "solution": ""}
{"task_id": 107, "completion_id": 0, "solution": ""}
{"task_id": 108, "completion_id": 0, "solution": ""}
{"task_id": 109, "completion_id": 0, "solution": ""}
{"task_id": 110, "completion_id": 0, "solution": ""}
{"task_id": 111, "completion_id": 0, "solution": ""}
{"task_id": 112, "completion_id": 0, "solution": ""}
{"task_id": 113, "completion_id": 0, "solution": ""}
{"task_id": 114, "completion_id": 0, "solution": ""}
{"task_id": 115, "completion_id": 0, "solution": ""}
{"task_id": 116, "completion_id": 0, "solution": ""}
{"task_id": 117, "completion_id": 0, "solution": ""}
{"task_id": 118, "completion_id": 0, "solution": ""}
{"task_id": 119, "completion_id": 0, "solution": ""}
{"task_id": 120, "completion_id": 0, "solution": ""}
{"task_id": 121, "completion_id": 0, "solution": ""}
{"task_id": 122, "completion_id": 0, "solution": ""}
{"task_id": 123, "completion_id": 0, "solution": ""}
{"task_id": 124, "completion_id": 0, "solution": ""}
{"task_id": 125, "completion_id": 0, "solution": ""}
{"task_id": 126, "completion_id": 0, "solution": ""}
{"task_id": 127, "completion_id": 0, "solution": "import numpy as np\ndef find_treasure(start_x: float, learning_rate: float=0.1, tolerance: float=1e-06, max_iters: int=10000) -> float:\n\n    def f(x):\n        return x ** 4 - 3 * x ** 3 + 2\n\n    def df(x):\n        return 4 * x ** 3 - 9 * x ** 2\n    x = start_x\n    for _ in range(max_iters):\n        gradient = df(x)\n        new_x = x - learning_rate * gradient\n        if abs(new_x - x) < tolerance:\n            break\n        x = new_x\n    return round(x, 4)"}
{"task_id": 128, "completion_id": 0, "solution": ""}
