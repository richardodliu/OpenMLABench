{"task_id": 1, "completion_id": 0, "solution": ""}
{"task_id": 2, "completion_id": 0, "solution": ""}
{"task_id": 3, "completion_id": 0, "solution": ""}
{"task_id": 4, "completion_id": 0, "solution": ""}
{"task_id": 5, "completion_id": 0, "solution": ""}
{"task_id": 6, "completion_id": 0, "solution": ""}
{"task_id": 7, "completion_id": 0, "solution": ""}
{"task_id": 8, "completion_id": 0, "solution": ""}
{"task_id": 9, "completion_id": 0, "solution": ""}
{"task_id": 10, "completion_id": 0, "solution": ""}
{"task_id": 11, "completion_id": 0, "solution": ""}
{"task_id": 12, "completion_id": 0, "solution": "import numpy as np\ndef svd_2x2_singular_values(A: np.ndarray) -> tuple:\n    if A.shape != (2, 2):\n        raise ValueError('Input matrix must be 2x2.')\n    B = np.dot(A.T, A)\n    v1 = np.array([1.0, 0.0])\n    v2 = np.array([0.0, 1.0])\n    tol = 1e-10\n    max_iter = 1000\n    for _ in range(max_iter):\n        v1_new = np.dot(B, v1)\n        v1_new /= np.linalg.norm(v1_new)\n        if np.linalg.norm(v1_new - v1) < tol:\n            break\n        v1 = v1_new\n    B_deflated = B - np.outer(v1, v1) * np.dot(v1, np.dot(B, v1)) / np.dot(v1, v1)\n    for _ in range(max_iter):\n        v2_new = np.dot(B_deflated, v2)\n        v2_new /= np.linalg.norm(v2_new)\n        if np.linalg.norm(v2_new - v2) < tol:\n            break\n        v2 = v2_new\n    sigma1_squared = np.dot(v1, np.dot(B, v1))\n    sigma2_squared = np.dot(v2, np.dot(B, v2))\n    sigma1 = np.sqrt(sigma1_squared)\n    sigma2 = np.sqrt(sigma2_squared)\n    return (round(sigma1, 4), round(sigma2, 4))\nA = np.array([[1.0, 2.0], [3.0, 4.0]])"}
{"task_id": 13, "completion_id": 0, "solution": ""}
{"task_id": 14, "completion_id": 0, "solution": ""}
{"task_id": 15, "completion_id": 0, "solution": ""}
{"task_id": 16, "completion_id": 0, "solution": ""}
{"task_id": 17, "completion_id": 0, "solution": "import numpy as np\ndef k_means_clustering(points: list[tuple[float, float]], k: int, initial_centroids: list[tuple[float, float]], max_iterations: int) -> list[tuple[float, float]]:\n    points = np.array(points)\n    centroids = np.array(initial_centroids)\n    for _ in range(max_iterations):\n        distances = np.sqrt(((points - centroids[:, np.newaxis]) ** 2).sum(axis=2))\n        labels = np.argmin(distances, axis=0)\n        new_centroids = np.array([points[labels == i].mean(axis=0) for i in range(k)])\n        if np.all(centroids == new_centroids):\n            break\n        centroids = new_centroids\n    final_centroids = np.round(centroids, 4).tolist()\n    return final_centroids\npoints = [(1.0, 2.0), (1.5, 1.8), (5.0, 8.0), (8.0, 8.0), (1.0, 0.6), (9.0, 11.0)]\nk = 2\ninitial_centroids = [(1.0, 2.0), (8.0, 8.0)]\nmax_iterations = 100\nfinal_centroids = k_means_clustering(points, k, initial_centroids, max_iterations)"}
{"task_id": 18, "completion_id": 0, "solution": ""}
{"task_id": 19, "completion_id": 0, "solution": ""}
{"task_id": 20, "completion_id": 0, "solution": ""}
{"task_id": 21, "completion_id": 0, "solution": ""}
{"task_id": 22, "completion_id": 0, "solution": ""}
{"task_id": 23, "completion_id": 0, "solution": ""}
{"task_id": 24, "completion_id": 0, "solution": ""}
{"task_id": 25, "completion_id": 0, "solution": ""}
{"task_id": 26, "completion_id": 0, "solution": ""}
{"task_id": 27, "completion_id": 0, "solution": ""}
{"task_id": 28, "completion_id": 0, "solution": ""}
{"task_id": 29, "completion_id": 0, "solution": ""}
{"task_id": 30, "completion_id": 0, "solution": ""}
{"task_id": 31, "completion_id": 0, "solution": ""}
{"task_id": 32, "completion_id": 0, "solution": ""}
{"task_id": 33, "completion_id": 0, "solution": ""}
{"task_id": 34, "completion_id": 0, "solution": ""}
{"task_id": 35, "completion_id": 0, "solution": ""}
{"task_id": 36, "completion_id": 0, "solution": ""}
{"task_id": 37, "completion_id": 0, "solution": ""}
{"task_id": 38, "completion_id": 0, "solution": ""}
{"task_id": 39, "completion_id": 0, "solution": ""}
{"task_id": 40, "completion_id": 0, "solution": ""}
{"task_id": 41, "completion_id": 0, "solution": ""}
{"task_id": 42, "completion_id": 0, "solution": ""}
{"task_id": 43, "completion_id": 0, "solution": ""}
{"task_id": 44, "completion_id": 0, "solution": ""}
{"task_id": 45, "completion_id": 0, "solution": ""}
{"task_id": 46, "completion_id": 0, "solution": ""}
{"task_id": 47, "completion_id": 0, "solution": ""}
{"task_id": 48, "completion_id": 0, "solution": ""}
{"task_id": 49, "completion_id": 0, "solution": ""}
{"task_id": 50, "completion_id": 0, "solution": ""}
{"task_id": 51, "completion_id": 0, "solution": ""}
{"task_id": 52, "completion_id": 0, "solution": ""}
{"task_id": 53, "completion_id": 0, "solution": ""}
{"task_id": 54, "completion_id": 0, "solution": ""}
{"task_id": 55, "completion_id": 0, "solution": ""}
{"task_id": 56, "completion_id": 0, "solution": ""}
{"task_id": 57, "completion_id": 0, "solution": ""}
{"task_id": 58, "completion_id": 0, "solution": ""}
{"task_id": 59, "completion_id": 0, "solution": ""}
{"task_id": 60, "completion_id": 0, "solution": ""}
{"task_id": 61, "completion_id": 0, "solution": ""}
{"task_id": 62, "completion_id": 0, "solution": "import numpy as np\nclass SimpleRNN:\n\n    def __init__(self, input_size, hidden_size, output_size):\n        \"\"\"\n        Initializes the RNN with random weights and zero biases.\n        \"\"\"\n        self.hidden_size = hidden_size\n        self.W_xh = np.random.randn(hidden_size, input_size) * 0.01\n        self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.01\n        self.W_hy = np.random.randn(output_size, hidden_size) * 0.01\n        self.b_h = np.zeros((hidden_size, 1))\n        self.b_y = np.zeros((output_size, 1))\n\n    def forward(self, input_sequence):\n        \"\"\"\n        Forward pass through the RNN for a given sequence of inputs.\n        \"\"\"\n        h_prev = np.zeros((self.hidden_size, 1))\n        outputs = []\n        last_inputs = []\n        last_hiddens = []\n        for x in input_sequence:\n            x = x.reshape(-1, 1)\n            h_curr = np.tanh(np.dot(self.W_xh, x) + np.dot(self.W_hh, h_prev) + self.b_h)\n            y_curr = np.dot(self.W_hy, h_curr) + self.b_y\n            outputs.append(y_curr)\n            last_inputs.append(x)\n            last_hiddens.append(h_curr)\n            h_prev = h_curr\n        return (outputs, last_inputs, last_hiddens)\n\n    def backward(self, input_sequence, expected_output, outputs, last_inputs, last_hiddens, learning_rate):\n        \"\"\"\n        Backward pass through the RNN to update weights using BPTT.\n        \"\"\"\n        dW_xh = np.zeros_like(self.W_xh)\n        dW_hh = np.zeros_like(self.W_hh)\n        dW_hy = np.zeros_like(self.W_hy)\n        db_h = np.zeros_like(self.b_h)\n        db_y = np.zeros_like(self.b_y)\n        dh_next = np.zeros_like(last_hiddens[0])\n        for t in reversed(range(len(input_sequence))):\n            dy = outputs[t] - expected_output[t].reshape(-1, 1)\n            dW_hy += np.dot(dy, last_hiddens[t].T)\n            db_y += dy\n            dh = np.dot(self.W_hy.T, dy) + dh_next\n            dh_raw = (1 - last_hiddens[t] * last_hiddens[t]) * dh\n            db_h += dh_raw\n            dW_xh += np.dot(dh_raw, last_inputs[t].T)\n            dW_hh += np.dot(dh_raw, last_hiddens[t - 1].T) if t > 0 else np.zeros_like(dW_hh)\n            dh_next = np.dot(self.W_hh.T, dh_raw)\n        self.W_xh -= learning_rate * dW_xh\n        self.W_hh -= learning_rate * dW_hh\n        self.W_hy -= learning_rate * dW_hy\n        self.b_h -= learning_rate * db_h\n        self.b_y -= learning_rate * db_y\n\n    def train(self, input_sequence, expected_output, num_iterations, learning_rate):\n        \"\"\"\n        Trains the RNN on a given sequence.\n        \"\"\"\n        for iteration in range(num_iterations):\n            (outputs, last_inputs, last_hiddens) = self.forward(input_sequence)\n            self.backward(input_sequence, expected_output, outputs, last_inputs, last_hiddens, learning_rate)\n            loss = 0.5 * np.sum((np.array(outputs) - np.array(expected_output)) ** 2)\n            if iteration % 100 == 0:\n                print(f'Iteration {iteration}, Loss: {loss}')"}
{"task_id": 63, "completion_id": 0, "solution": ""}
{"task_id": 64, "completion_id": 0, "solution": ""}
{"task_id": 65, "completion_id": 0, "solution": ""}
{"task_id": 66, "completion_id": 0, "solution": ""}
{"task_id": 67, "completion_id": 0, "solution": ""}
{"task_id": 68, "completion_id": 0, "solution": ""}
{"task_id": 69, "completion_id": 0, "solution": ""}
{"task_id": 70, "completion_id": 0, "solution": ""}
{"task_id": 71, "completion_id": 0, "solution": ""}
{"task_id": 72, "completion_id": 0, "solution": ""}
{"task_id": 73, "completion_id": 0, "solution": ""}
{"task_id": 74, "completion_id": 0, "solution": ""}
{"task_id": 75, "completion_id": 0, "solution": ""}
{"task_id": 76, "completion_id": 0, "solution": ""}
{"task_id": 77, "completion_id": 0, "solution": ""}
{"task_id": 78, "completion_id": 0, "solution": "import numpy as np\nfrom scipy import stats\ndef descriptive_statistics(data):\n    data = np.array(data)\n    mean = np.mean(data)\n    median = np.median(data)\n    mode_result = stats.mode(data)\n    mode = mode_result.mode[0] if mode_result.count[0] > 1 else None\n    variance = np.var(data, ddof=0)\n    std_dev = np.std(data, ddof=0)\n    percentile_25 = np.percentile(data, 25)\n    percentile_50 = np.percentile(data, 50)\n    percentile_75 = np.percentile(data, 75)\n    iqr = percentile_75 - percentile_25\n    result = {'mean': round(mean, 4), 'median': round(median, 4), 'mode': round(mode, 4) if mode is not None else mode, 'variance': round(variance, 4), 'standard_deviation': round(std_dev, 4), '25th_percentile': round(percentile_25, 4), '50th_percentile': round(percentile_50, 4), '75th_percentile': round(percentile_75, 4), 'interquartile_range': round(iqr, 4)}\n    return result\ndata = [10, 20, 30, 40, 50, 50, 60, 70, 80, 90, 100]"}
{"task_id": 79, "completion_id": 0, "solution": ""}
{"task_id": 80, "completion_id": 0, "solution": ""}
{"task_id": 81, "completion_id": 0, "solution": ""}
{"task_id": 82, "completion_id": 0, "solution": ""}
{"task_id": 83, "completion_id": 0, "solution": ""}
{"task_id": 84, "completion_id": 0, "solution": ""}
{"task_id": 85, "completion_id": 0, "solution": ""}
{"task_id": 86, "completion_id": 0, "solution": ""}
{"task_id": 87, "completion_id": 0, "solution": ""}
{"task_id": 88, "completion_id": 0, "solution": ""}
{"task_id": 89, "completion_id": 0, "solution": "import numpy as np\ndef pattern_weaver(n, crystal_values, dimension):\n\n    def softmax(values):\n        exp_values = np.exp(values - np.max(values))\n        return exp_values / np.sum(exp_values)\n    np.random.seed(0)\n    weights = np.random.rand(dimension, dimension)\n    crystal_values = np.array(crystal_values).reshape(n, 1)\n    embedded_values = np.dot(crystal_values, np.ones((1, dimension)))\n    scores = np.dot(embedded_values, weights)\n    attention_scores = softmax(scores)\n    weighted_patterns = np.sum(attention_scores * crystal_values, axis=0)\n    return [round(value, 4) for value in weighted_patterns]\nn = 5\ncrystal_values = [10, 20, 30, 40, 50]\ndimension = 3"}
{"task_id": 90, "completion_id": 0, "solution": ""}
{"task_id": 91, "completion_id": 0, "solution": ""}
{"task_id": 92, "completion_id": 0, "solution": ""}
{"task_id": 93, "completion_id": 0, "solution": ""}
{"task_id": 94, "completion_id": 0, "solution": ""}
{"task_id": 95, "completion_id": 0, "solution": ""}
{"task_id": 96, "completion_id": 0, "solution": ""}
{"task_id": 97, "completion_id": 0, "solution": ""}
{"task_id": 98, "completion_id": 0, "solution": ""}
{"task_id": 99, "completion_id": 0, "solution": ""}
{"task_id": 100, "completion_id": 0, "solution": ""}
{"task_id": 101, "completion_id": 0, "solution": ""}
{"task_id": 102, "completion_id": 0, "solution": ""}
{"task_id": 103, "completion_id": 0, "solution": ""}
{"task_id": 104, "completion_id": 0, "solution": ""}
{"task_id": 105, "completion_id": 0, "solution": ""}
{"task_id": 106, "completion_id": 0, "solution": ""}
{"task_id": 107, "completion_id": 0, "solution": ""}
{"task_id": 108, "completion_id": 0, "solution": ""}
{"task_id": 109, "completion_id": 0, "solution": ""}
{"task_id": 110, "completion_id": 0, "solution": ""}
{"task_id": 111, "completion_id": 0, "solution": ""}
{"task_id": 112, "completion_id": 0, "solution": ""}
{"task_id": 113, "completion_id": 0, "solution": ""}
{"task_id": 114, "completion_id": 0, "solution": ""}
{"task_id": 115, "completion_id": 0, "solution": ""}
{"task_id": 116, "completion_id": 0, "solution": ""}
{"task_id": 117, "completion_id": 0, "solution": ""}
{"task_id": 118, "completion_id": 0, "solution": ""}
{"task_id": 119, "completion_id": 0, "solution": ""}
{"task_id": 120, "completion_id": 0, "solution": ""}
{"task_id": 121, "completion_id": 0, "solution": ""}
{"task_id": 122, "completion_id": 0, "solution": ""}
{"task_id": 123, "completion_id": 0, "solution": ""}
{"task_id": 124, "completion_id": 0, "solution": ""}
{"task_id": 125, "completion_id": 0, "solution": ""}
{"task_id": 126, "completion_id": 0, "solution": ""}
{"task_id": 127, "completion_id": 0, "solution": "import numpy as np\ndef find_treasure(start_x: float, learning_rate: float=0.1, tolerance: float=1e-06, max_iters: int=10000) -> float:\n\n    def f(x):\n        return x ** 4 - 3 * x ** 3 + 2\n\n    def f_prime(x):\n        return 4 * x ** 3 - 9 * x ** 2\n    current_x = start_x\n    for i in range(max_iters):\n        gradient = f_prime(current_x)\n        new_x = current_x - learning_rate * gradient\n        if abs(new_x - current_x) < tolerance:\n            break\n        current_x = new_x\n    return round(current_x, 4)"}
{"task_id": 128, "completion_id": 0, "solution": ""}
